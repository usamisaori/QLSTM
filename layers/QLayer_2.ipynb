{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6581af8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94243045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fff0ae78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyqpanda import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "455c7f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a618a3a",
   "metadata": {},
   "source": [
    "# 1. Prepare Dadaset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c64faba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/datasets/sumanthvrao/daily-climate-time-series-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de627766",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './../data/DailyDelhiClimateTrain.csv'\n",
    "test_path = './../data/DailyDelhiClimateTest.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d0827fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [1,2,3,4]\n",
    "\n",
    "train = pd.read_csv(train_path, usecols=cols, engine=\"python\")\n",
    "test = pd.read_csv(test_path, usecols=cols, engine=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c3039c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train)=1462\n",
      "len(test)=114\n"
     ]
    }
   ],
   "source": [
    "print(f'len(train)={len(train)}')\n",
    "print(f'len(test)={len(test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b941db2e",
   "metadata": {},
   "source": [
    "## 1.1 Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e59fddc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove outliers num: 9\n"
     ]
    }
   ],
   "source": [
    "unnormal_num = 0\n",
    "for i in range(len(train)):\n",
    "    mp = train.iloc[i][3]\n",
    "    if mp > 1200 or mp < 950:\n",
    "        unnormal_num += 1\n",
    "        train.iloc[i][3] = train.iloc[i + 1][3]\n",
    "print(f'remove outliers num: {unnormal_num}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fefec4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.iloc[0][3] = test.iloc[1][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6035297e",
   "metadata": {},
   "source": [
    "## 1.2 Transfer data to LSTM representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a1277fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "884bc13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(data, window_size, predict_size):\n",
    "    scaler = StandardScaler()\n",
    "    data = scaler.fit_transform(np.array(data).reshape(-1, 1))\n",
    "    \n",
    "    data_in = []\n",
    "    data_out = []\n",
    "    \n",
    "    for i in range(data.shape[0] - window_size - predict_size):\n",
    "        data_in.append(data[i:i + window_size].reshape(1, window_size)[0])\n",
    "        data_out.append(data[i + window_size:i + window_size + predict_size].reshape(1, predict_size)[0])\n",
    "        \n",
    "    data_in = np.array(data_in).reshape(-1, window_size)\n",
    "    data_out = np.array(data_out).reshape(-1, predict_size)\n",
    "    \n",
    "    data_process = {'datain': data_in, 'dataout': data_out}\n",
    "    \n",
    "    return data_process, scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6517fe60",
   "metadata": {},
   "source": [
    "## 1.3 prepare train/test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d333c7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_size = 4\n",
    "window_size = features_size * 3 # features num * time steps\n",
    "predict_size = features_size # features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ef548b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_processed, train_scaler = data_process(train, window_size, predict_size)\n",
    "X_train, y_train = train_processed['datain'], train_processed['dataout']\n",
    "\n",
    "test_processed, test_scaler = data_process(test, window_size, predict_size)\n",
    "X_test, y_test = test_processed['datain'], test_processed['dataout']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f779325c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
    "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
    "\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dda516d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as Data\n",
    "\n",
    "train_data = Data.TensorDataset(X_train, y_train)\n",
    "test_data = Data.TensorDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cb132c",
   "metadata": {},
   "source": [
    "# 2. Quantum Enhanced LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d517f5f3",
   "metadata": {},
   "source": [
    "## 2.1 initiate quantum environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ffc85d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InitQMachine:\n",
    "    def __init__(self, qubitsCount, cbitsCount = 0, machineType = QMachineType.CPU):\n",
    "        self.machine = init_quantum_machine(machineType)\n",
    "        \n",
    "        self.qubits = self.machine.qAlloc_many(qubitsCount)\n",
    "        self.cbits = self.machine.cAlloc_many(cbitsCount)\n",
    "        \n",
    "        print(f'Init Quantum Machine with qubits:[{qubitsCount}] / cbits:[{cbitsCount}] Successfully')\n",
    "    \n",
    "    def __del__(self):\n",
    "        destroy_quantum_machine(self.machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "741a6a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Quantum Machine with qubits:[4] / cbits:[0] Successfully\n"
     ]
    }
   ],
   "source": [
    "# maximum qubits size\n",
    "ctx = InitQMachine(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a39cf3",
   "metadata": {},
   "source": [
    "## 2.2 Quantum Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63b029d",
   "metadata": {},
   "source": [
    "### 2.2.1 Quantum layer base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5570e76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from torch.nn import Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f9cfd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumLayerBase(nn.Module):\n",
    "    def __init__(self, input_size, output_size, *, n_qubits, n_layers = 1, ctx = None):\n",
    "        super(QuantumLayerBase, self).__init__()\n",
    "        \n",
    "        self.data = None # need to input during forward\n",
    "    \n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size # hidden size, not n_qubits\n",
    "        \n",
    "        # quantum infos\n",
    "        self.n_qubits = n_qubits\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.ctx = ctx\n",
    "        self.qubits = ctx.qubits\n",
    "        self.machine = ctx.machine\n",
    "        \n",
    "        # convert quantum input/output to match classical computation\n",
    "        self.qin = nn.Linear(self.input_size, self.n_qubits)\n",
    "        self.qout = nn.Linear(self.n_qubits, self.output_size)\n",
    "        \n",
    "    @property\n",
    "    def circuit(self):\n",
    "        raise NotImplementedError('Should init circuit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94c5bbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure(self):\n",
    "    HamiZ = [ PauliOperator({f'Z{i}': 1}) for i in range(len(self.qubits)) ]\n",
    "    res = [ eval(qop(self.circuit, Hami, self.machine, self.qubits))[0,0] for Hami in HamiZ ]\n",
    "    \n",
    "    return Parameter(Tensor(res[:self.n_qubits]))\n",
    "\n",
    "QuantumLayerBase.measure = measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4341341c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, inputs):\n",
    "    y_t = self.qin(Parameter(inputs))\n",
    "    self.data = y_t[0]\n",
    "    \n",
    "    return self.qout(self.measure())\n",
    "\n",
    "QuantumLayerBase.forward = forward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4f794b",
   "metadata": {},
   "source": [
    "### 2.2.2 Quantum layer design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b98a8984",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumLayer(QuantumLayerBase):\n",
    "    def __init__(self, input_size, output_size, *, n_qubits, degree = 1, n_layers = 1, ctx = None):\n",
    "        super(QuantumLayer, self).__init__(input_size, output_size, \n",
    "                                         n_qubits = n_qubits, n_layers = n_layers, ctx = ctx)\n",
    "        \n",
    "        self.degree = degree\n",
    "        self.angles = Parameter(torch.rand(n_layers + 1, degree, self.n_qubits))\n",
    "        \n",
    "    @property\n",
    "    def qparameters_size(self):\n",
    "        return self.angles.flatten().size()[0]\n",
    "        \n",
    "    @property\n",
    "    def circuit(self):\n",
    "        if self.data == None:\n",
    "            raise ValueError('Need to feed a input data!')\n",
    "        \n",
    "        n = self.n_qubits\n",
    "        q = self.qubits\n",
    "        x = self.data\n",
    "        p = self.angles\n",
    "        degree = self.degree\n",
    "        \n",
    "        h = VariationalQuantumGate_H\n",
    "        ry = VariationalQuantumGate_RY\n",
    "        cz = VariationalQuantumGate_CZ\n",
    "        u = [\n",
    "            None,\n",
    "            VariationalQuantumGate_U1,\n",
    "            VariationalQuantumGate_U2,\n",
    "            VariationalQuantumGate_U3\n",
    "        ]\n",
    "        \n",
    "        # init variational quantum circuit\n",
    "        vqc = VariationalQuantumCircuit()\n",
    "\n",
    "        # encoding layer\n",
    "        [ vqc.insert( h(q[i]) ) for i in range(n) ]\n",
    "        [ vqc.insert( ry(q[i], var(x[i] * torch.pi / 2)) ) for i in range(n) ]\n",
    "        \n",
    "        # variational layer\n",
    "        [ vqc.insert( u[degree](q[i], *[ var(p[0][d][i]) for d in range(degree) ]) ) \n",
    "                 for i in range(n) ]\n",
    "        \n",
    "        for layer in range(self.n_layers):\n",
    "            for i in range(n - 1):\n",
    "                vqc.insert(cz(q[i], q[i + 1]))\n",
    "            vqc.insert(cz(q[n - 1], q[0]))\n",
    "            \n",
    "            [ vqc.insert( u[degree](q[i], *[ var(p[layer + 1][d][i]) for d in range(degree) ]) ) \n",
    "                 for i in range(n) ]\n",
    "        \n",
    "        return vqc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3156df",
   "metadata": {},
   "source": [
    "### 2.2.3 Plot Quantum Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd16d64c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyqpanda.pyQPanda.QProg at 0x166a62cba70>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Tensor([[0.1, 0.2, 0.3, 0.4]])\n",
    "layer = QuantumLayer(4, 4, n_qubits=4, n_layers=1, degree=3, ctx=ctx)\n",
    "layer.data = data[0]\n",
    "vqc = layer.circuit\n",
    "prog = create_empty_qprog()\n",
    "prog.insert(vqc.feed())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f82266f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'null'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw_qprog(prog, 'pic', filename=f'pic/layer2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50742459",
   "metadata": {},
   "source": [
    "## 2.3 Quantum-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e53ae0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLSTMBase(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, *, ctx):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.ctx = ctx\n",
    "        \n",
    "    @property\n",
    "    def qparameters_size(self):\n",
    "        num = 0\n",
    "        for attr in dir(self):\n",
    "            if attr.endswith('_circuit'):\n",
    "                num += getattr(self, attr).qparameters_size\n",
    "        return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "582b17af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, inputs, init_states = None):\n",
    "    sequence_size, batch_size, _ = inputs.size()\n",
    "    hidden_sequence = []\n",
    "    \n",
    "    if init_states == None:\n",
    "        h_t, c_t = (\n",
    "            torch.zeros(1, batch_size, self.hidden_size).to(inputs.device),\n",
    "            torch.zeros(1, batch_size, self.hidden_size).to(inputs.device),\n",
    "        )\n",
    "    else:\n",
    "        h_t, c_t = init_states\n",
    "    \n",
    "    return hidden_sequence, (h_t, c_t)\n",
    "\n",
    "QLSTMBase.forward = forward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d6b0af",
   "metadata": {},
   "source": [
    "## - classical quatum enhanced LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "adc8fb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLSTM(QLSTMBase):\n",
    "    def __init__(self, input_size, hidden_size, *, ctx):\n",
    "        super().__init__(input_size, hidden_size, ctx = ctx)\n",
    "    \n",
    "        # input gates\n",
    "        self.input_circuit = QuantumLayer(input_size + hidden_size, hidden_size, \n",
    "                                        n_qubits = 4, degree = 3, ctx = ctx) # 15\n",
    "        # forget gates\n",
    "        self.forget_circuit = QuantumLayer(input_size + hidden_size, hidden_size, \n",
    "                                         n_qubits = 4, degree = 3, ctx = ctx) # 15\n",
    "        # candidate\n",
    "        self.candidate_circuit = QuantumLayer(input_size + hidden_size, hidden_size, \n",
    "                                       n_qubits = 4, degree = 3, ctx = ctx) # 15\n",
    "        # output gates\n",
    "        self.output_circuit = QuantumLayer(input_size + hidden_size, hidden_size, \n",
    "                                         n_qubits = 4, degree = 3, ctx = ctx) # 15\n",
    "        \n",
    "    def forward(self, inputs, init_states = None):\n",
    "        hidden_sequence, (h_t, c_t) = super(QLSTM, self).forward(inputs, init_states)\n",
    "\n",
    "        for t in range(inputs.size()[0]):\n",
    "            x_t = inputs[t, :, :]\n",
    "            v_t = torch.cat((h_t[0], x_t), dim = 1)\n",
    "\n",
    "            # input gates\n",
    "            i_t = torch.sigmoid(self.input_circuit(v_t))\n",
    "            # forget gates\n",
    "            f_t = torch.sigmoid(self.forget_circuit(v_t))\n",
    "            # candidate for cell state update\n",
    "            g_t = torch.tanh(self.candidate_circuit(v_t))\n",
    "            c_t = (f_t * c_t) + (i_t * g_t)\n",
    "\n",
    "            # output gates\n",
    "            o_t = torch.sigmoid(self.output_circuit(v_t))\n",
    "            # update output ht\n",
    "            h_t = o_t * (torch.tanh(c_t))\n",
    "\n",
    "            hidden_sequence.append(h_t)\n",
    "\n",
    "        # reshape hidden_seq p/ retornar\n",
    "        #\n",
    "        # [tensor([[[0.0444, ...]]] => tensor([[[0.0444, ...]]]\n",
    "        # \n",
    "        hidden_sequence = torch.cat(hidden_sequence, dim = 0)\n",
    "\n",
    "        return hidden_sequence, (h_t, c_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28836475",
   "metadata": {},
   "source": [
    "## 2.4 Stacked QLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9ec06c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "class StackedQLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, *, num_layers = 1, ctx = None, mode = 'classical'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.qlstms = nn.Sequential(OrderedDict([\n",
    "            (f'QLSTM {i + 1}', QLSTM(input_size if i == 0 else hidden_size , hidden_size, ctx = ctx)) \n",
    "                for i in range(num_layers)\n",
    "        ]))\n",
    "\n",
    "    def forward(self, inputs, parameters = None):\n",
    "        outputs = None\n",
    "        \n",
    "        for i, qlstm in enumerate(self.qlstms):\n",
    "            if i != 0:\n",
    "                inputs = outputs\n",
    "            \n",
    "            outputs, parameters = qlstm(inputs, parameters)\n",
    "        \n",
    "        return outputs, parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0389535c",
   "metadata": {},
   "source": [
    "# 3. Quantum Model and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "413150bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_output, *, num_layers = 1, ctx = None, mode = 'classical'):\n",
    "        super(QModel, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.qlstm = StackedQLSTM(input_size, hidden_size, \n",
    "                                  num_layers = num_layers, ctx = ctx, mode = mode)\n",
    "        self.predict = nn.Linear(hidden_size, num_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(0)\n",
    "        \n",
    "        # sequence lenth , batch_size, features length\n",
    "        # \n",
    "        h0 = torch.zeros(1, x.size(1), self.hidden_size)\n",
    "        c0 = torch.zeros(1, x.size(1), self.hidden_size)\n",
    "        \n",
    "        out, _ = self.qlstm(x, (h0, c0))\n",
    "        out = self.predict(out[0])\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111aebe4",
   "metadata": {},
   "source": [
    "## 3.1 train QModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bc1d1439",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import RandomSampler\n",
    "\n",
    "def train_model(model, datas, batch_size, *, loss_func, optimizer, epoch = 50):\n",
    "    losses = []\n",
    "    sampler = RandomSampler(datas, num_samples = batch_size)\n",
    "    \n",
    "    for step in range(epoch):\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for index in sampler:\n",
    "            batch_x, batch_y = datas[index][0], datas[index][1]\n",
    "            b_x = batch_x.unsqueeze(0)\n",
    "            b_y = batch_y.unsqueeze(0)\n",
    "            \n",
    "            output = model(b_x)\n",
    "\n",
    "            loss = loss_func(output, b_y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        print(f'Epoch {step + 1}/{epoch}: Loss: {train_loss / batch_size}')\n",
    "        losses.append(train_loss / batch_size)\n",
    "    \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef07934f",
   "metadata": {},
   "source": [
    "## 3.2 Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "57e9b387",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "def MAE_naive(actuals, predicteds):\n",
    "    n = len(actuals)\n",
    "    err = 0.0\n",
    "    \n",
    "    for i in range(1, n):\n",
    "        err += np.abs(actuals[i] - actuals[i - 1])\n",
    "    return err / (n - 1)\n",
    "\n",
    "def calculate_accuarcy(model, X_test, y_test, scaler=test_scaler):\n",
    "    n = len(X_test)\n",
    "    \n",
    "    actuals = []\n",
    "    predicteds = []\n",
    "    \n",
    "    for i in range(0, n, predict_size):\n",
    "        actual = scaler.inverse_transform(y_test[i:i+1].data)\n",
    "        actuals.append(np.array(actual[0]))\n",
    "        predicted = scaler.inverse_transform(model(X_test[i:i+1]).data)\n",
    "        predicteds.append(np.array(predicted[0]))\n",
    "    \n",
    "    actuals = np.array(actuals)\n",
    "    predicteds = np.array(predicteds)\n",
    "    \n",
    "    mae = mean_absolute_error(actuals, predicteds)\n",
    "    mase = mae / MAE_naive(actuals.flatten(), predicteds.flatten())\n",
    "    mape = mean_absolute_percentage_error(actuals, predicteds)\n",
    "    mse = mean_squared_error(actuals, predicteds)\n",
    "    rmse = mse ** 0.5\n",
    "    \n",
    "    return np.array([(1 - mase) * 100, rmse, mse, mae, mape])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6407f969",
   "metadata": {},
   "source": [
    "## 3.3 Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "305c9471",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_size = 4\n",
    "window_size = features_size * 3 # \n",
    "predict_size = features_size # features\n",
    "\n",
    "input_size = window_size\n",
    "num_output = predict_size\n",
    "\n",
    "hidden_size = 32\n",
    "num_layers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "79660b22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training epoch: 1\n",
      "Epoch 1/200: Loss: 1.0071428060531615\n",
      "Epoch 2/200: Loss: 0.9636303097009659\n",
      "Epoch 3/200: Loss: 1.0449674546718597\n",
      "Epoch 4/200: Loss: 1.007233190536499\n",
      "Epoch 5/200: Loss: 1.026509341597557\n",
      "Epoch 6/200: Loss: 0.9678881078958511\n",
      "Epoch 7/200: Loss: 0.9599214315414428\n",
      "Epoch 8/200: Loss: 0.9792125314474106\n",
      "Epoch 9/200: Loss: 0.9608184963464736\n",
      "Epoch 10/200: Loss: 0.943603390455246\n",
      "Epoch 11/200: Loss: 0.9173219919204711\n",
      "Epoch 12/200: Loss: 0.9313246309757233\n",
      "Epoch 13/200: Loss: 0.9157268345355988\n",
      "Epoch 14/200: Loss: 0.8935758650302887\n",
      "Epoch 15/200: Loss: 0.8797374784946441\n",
      "Epoch 16/200: Loss: 0.8550695538520813\n",
      "Epoch 17/200: Loss: 0.7922266542911529\n",
      "Epoch 18/200: Loss: 0.7883871495723724\n",
      "Epoch 19/200: Loss: 0.734552139043808\n",
      "Epoch 20/200: Loss: 0.7250767886638642\n",
      "Epoch 21/200: Loss: 0.660784849524498\n",
      "Epoch 22/200: Loss: 0.7006742566823959\n",
      "Epoch 23/200: Loss: 0.6759411081671715\n",
      "Epoch 24/200: Loss: 0.625003182888031\n",
      "Epoch 25/200: Loss: 0.561445240676403\n",
      "Epoch 26/200: Loss: 0.5705149874091149\n",
      "Epoch 27/200: Loss: 0.5028928637504577\n",
      "Epoch 28/200: Loss: 0.48608430922031404\n",
      "Epoch 29/200: Loss: 0.5399204954504967\n",
      "Epoch 30/200: Loss: 0.45191391557455063\n",
      "Epoch 31/200: Loss: 0.34956617951393126\n",
      "Epoch 32/200: Loss: 0.46723504066467286\n",
      "Epoch 33/200: Loss: 0.3971219450235367\n",
      "Epoch 34/200: Loss: 0.38095556050539015\n",
      "Epoch 35/200: Loss: 0.3374880425632\n",
      "Epoch 36/200: Loss: 0.33038275167346\n",
      "Epoch 37/200: Loss: 0.28794058337807654\n",
      "Epoch 38/200: Loss: 0.32502190992236135\n",
      "Epoch 39/200: Loss: 0.36011582165956496\n",
      "Epoch 40/200: Loss: 0.28797894194722173\n",
      "Epoch 41/200: Loss: 0.33464512676000596\n",
      "Epoch 42/200: Loss: 0.2597548499703407\n",
      "Epoch 43/200: Loss: 0.25197627022862434\n",
      "Epoch 44/200: Loss: 0.230638637393713\n",
      "Epoch 45/200: Loss: 0.20774255581200124\n",
      "Epoch 46/200: Loss: 0.174972465634346\n",
      "Epoch 47/200: Loss: 0.2168922457844019\n",
      "Epoch 48/200: Loss: 0.23534803204238414\n",
      "Epoch 49/200: Loss: 0.20213972069323063\n",
      "Epoch 50/200: Loss: 0.22028120830655099\n",
      "Epoch 51/200: Loss: 0.17468971824273466\n",
      "Epoch 52/200: Loss: 0.193614864628762\n",
      "Epoch 53/200: Loss: 0.19361606873571874\n",
      "Epoch 54/200: Loss: 0.13766767214983702\n",
      "Epoch 55/200: Loss: 0.22207897007465363\n",
      "Epoch 56/200: Loss: 0.1259817672893405\n",
      "Epoch 57/200: Loss: 0.1383504734840244\n",
      "Epoch 58/200: Loss: 0.11975502441637217\n",
      "Epoch 59/200: Loss: 0.11751427659764886\n",
      "Epoch 60/200: Loss: 0.11663934048265219\n",
      "Epoch 61/200: Loss: 0.09582885999698192\n",
      "Epoch 62/200: Loss: 0.07340411515906453\n",
      "Epoch 63/200: Loss: 0.11233817823231221\n",
      "Epoch 64/200: Loss: 0.13123449869453907\n",
      "Epoch 65/200: Loss: 0.08326080583501608\n",
      "Epoch 66/200: Loss: 0.08512231975328177\n",
      "Epoch 67/200: Loss: 0.07830559681169688\n",
      "Epoch 68/200: Loss: 0.06020208119880408\n",
      "Epoch 69/200: Loss: 0.057853221287950875\n",
      "Epoch 70/200: Loss: 0.04554215045645833\n",
      "Epoch 71/200: Loss: 0.046643901825882496\n",
      "Epoch 72/200: Loss: 0.042749249981716274\n",
      "Epoch 73/200: Loss: 0.031006750714732335\n",
      "Epoch 74/200: Loss: 0.03581741275265813\n",
      "Epoch 75/200: Loss: 0.023670531646348535\n",
      "Epoch 76/200: Loss: 0.01725852065719664\n",
      "Epoch 77/200: Loss: 0.019023388164350764\n",
      "Epoch 78/200: Loss: 0.023720430111279712\n",
      "Epoch 79/200: Loss: 0.02016267513972707\n",
      "Epoch 80/200: Loss: 0.01258737783646211\n",
      "Epoch 81/200: Loss: 0.01313083084387472\n",
      "Epoch 82/200: Loss: 0.009213298893882893\n",
      "Epoch 83/200: Loss: 0.005625110096298158\n",
      "Epoch 84/200: Loss: 0.005713945758179762\n",
      "Epoch 85/200: Loss: 0.007257945733726956\n",
      "Epoch 86/200: Loss: 0.006701470628468087\n",
      "Epoch 87/200: Loss: 0.0050509684515418485\n",
      "Epoch 88/200: Loss: 0.005777807327103801\n",
      "Epoch 89/200: Loss: 0.002584632499201689\n",
      "Epoch 90/200: Loss: 0.002546620367502328\n",
      "Epoch 91/200: Loss: 0.0023902785760583356\n",
      "Epoch 92/200: Loss: 0.0016273141884084908\n",
      "Epoch 93/200: Loss: 0.0017982631929044147\n",
      "Epoch 94/200: Loss: 0.0011655518203042448\n",
      "Epoch 95/200: Loss: 0.0007915808651887346\n",
      "Epoch 96/200: Loss: 0.0008086398286195617\n",
      "Epoch 97/200: Loss: 0.0013772747057373635\n",
      "Epoch 98/200: Loss: 0.0010835478955414147\n",
      "Epoch 99/200: Loss: 0.0008253374219748366\n",
      "Epoch 100/200: Loss: 0.0005766382684669225\n",
      "Epoch 101/200: Loss: 0.0009574464871548116\n",
      "Epoch 102/200: Loss: 0.0009183882211800665\n",
      "Epoch 103/200: Loss: 0.0008023381011298625\n",
      "Epoch 104/200: Loss: 0.0008306756433739792\n",
      "Epoch 105/200: Loss: 0.0007299626278836513\n",
      "Epoch 106/200: Loss: 0.0005615294781819103\n",
      "Epoch 107/200: Loss: 0.0005315566188073717\n",
      "Epoch 108/200: Loss: 0.0007327895111302496\n",
      "Epoch 109/200: Loss: 0.00040285930190293585\n",
      "Epoch 110/200: Loss: 0.0007435912000801181\n",
      "Epoch 111/200: Loss: 0.0004990365687717712\n",
      "Epoch 112/200: Loss: 0.0004483495114982361\n",
      "Epoch 113/200: Loss: 0.0006366645913658431\n",
      "Epoch 114/200: Loss: 0.0005356498582841596\n",
      "Epoch 115/200: Loss: 0.0007076562855218071\n",
      "Epoch 116/200: Loss: 0.0006635195422859397\n",
      "Epoch 117/200: Loss: 0.0006669434419563913\n",
      "Epoch 118/200: Loss: 0.0008872989787050755\n",
      "Epoch 119/200: Loss: 0.0007198875460744603\n",
      "Epoch 120/200: Loss: 0.000583363784244284\n",
      "Epoch 121/200: Loss: 0.0005508132562681567\n",
      "Epoch 122/200: Loss: 0.0006050733787560603\n",
      "Epoch 123/200: Loss: 0.00036394320050021635\n",
      "Epoch 124/200: Loss: 0.00038046684876462676\n",
      "Epoch 125/200: Loss: 0.0008559256088119582\n",
      "Epoch 126/200: Loss: 0.0005596533472271403\n",
      "Epoch 127/200: Loss: 0.0005525490061700112\n",
      "Epoch 128/200: Loss: 0.0005048170898589888\n",
      "Epoch 129/200: Loss: 0.0005369061102101114\n",
      "Epoch 130/200: Loss: 0.0007224860124551924\n",
      "Epoch 131/200: Loss: 0.0005251245976978681\n",
      "Epoch 132/200: Loss: 0.0005505484636159963\n",
      "Epoch 133/200: Loss: 0.0004300021944800392\n",
      "Epoch 134/200: Loss: 0.000642280690590269\n",
      "Epoch 135/200: Loss: 0.0006041783406544709\n",
      "Epoch 136/200: Loss: 0.000937547157627705\n",
      "Epoch 137/200: Loss: 0.0005545934376641526\n",
      "Epoch 138/200: Loss: 0.0007897945768490899\n",
      "Epoch 139/200: Loss: 0.0006169345560920192\n",
      "Epoch 140/200: Loss: 0.0008516040217728005\n",
      "Epoch 141/200: Loss: 0.0006262502114623203\n",
      "Epoch 142/200: Loss: 0.0006439449908612005\n",
      "Epoch 143/200: Loss: 0.0007251768223795807\n",
      "Epoch 144/200: Loss: 0.000837828410021757\n",
      "Epoch 145/200: Loss: 0.00036245027076802215\n",
      "Epoch 146/200: Loss: 0.0004926682934183191\n",
      "Epoch 147/200: Loss: 0.0007007242089457577\n",
      "Epoch 148/200: Loss: 0.0009659696097514825\n",
      "Epoch 149/200: Loss: 0.00047519682593701875\n",
      "Epoch 150/200: Loss: 0.0006248835154110566\n",
      "Epoch 151/200: Loss: 0.0010811628810188268\n",
      "Epoch 152/200: Loss: 0.0007021557967163972\n",
      "Epoch 153/200: Loss: 0.0005224513335519987\n",
      "Epoch 154/200: Loss: 0.0005722903087644227\n",
      "Epoch 155/200: Loss: 0.000704251748175011\n",
      "Epoch 156/200: Loss: 0.00035281141736049905\n",
      "Epoch 157/200: Loss: 0.000698692391597433\n",
      "Epoch 158/200: Loss: 0.0007532789943070384\n",
      "Epoch 159/200: Loss: 0.0004513630049132189\n",
      "Epoch 160/200: Loss: 0.000494563705251494\n",
      "Epoch 161/200: Loss: 0.0005359171436793986\n",
      "Epoch 162/200: Loss: 0.0005556293286645087\n",
      "Epoch 163/200: Loss: 0.0006117729333709576\n",
      "Epoch 164/200: Loss: 0.0003832881802736665\n",
      "Epoch 165/200: Loss: 0.0007474610967619811\n",
      "Epoch 166/200: Loss: 0.0007832123133994173\n",
      "Epoch 167/200: Loss: 0.0005786553905636538\n",
      "Epoch 168/200: Loss: 0.0005307714063746971\n",
      "Epoch 169/200: Loss: 0.0006345906226215448\n",
      "Epoch 170/200: Loss: 0.0006537732850119937\n",
      "Epoch 171/200: Loss: 0.0008513990327628562\n",
      "Epoch 172/200: Loss: 0.0007145737901737448\n",
      "Epoch 173/200: Loss: 0.000730624306743266\n",
      "Epoch 174/200: Loss: 0.000502648824294738\n",
      "Epoch 175/200: Loss: 0.0006909026120411\n",
      "Epoch 176/200: Loss: 0.0004907011408249673\n",
      "Epoch 177/200: Loss: 0.0007879388977016788\n",
      "Epoch 178/200: Loss: 0.0007155037929351237\n",
      "Epoch 179/200: Loss: 0.0005630478568491526\n",
      "Epoch 180/200: Loss: 0.0007132659113267437\n",
      "Epoch 181/200: Loss: 0.0005154913921842308\n",
      "Epoch 182/200: Loss: 0.0007280518329935148\n",
      "Epoch 183/200: Loss: 0.0008168120079062646\n",
      "Epoch 184/200: Loss: 0.0006786100948374951\n",
      "Epoch 185/200: Loss: 0.0005765531888755504\n",
      "Epoch 186/200: Loss: 0.0007175225564424181\n",
      "Epoch 187/200: Loss: 0.0009905122709824355\n",
      "Epoch 188/200: Loss: 0.0006088846066631959\n",
      "Epoch 189/200: Loss: 0.0006183272445923649\n",
      "Epoch 190/200: Loss: 0.0007619534289915464\n",
      "Epoch 191/200: Loss: 0.00075242819802952\n",
      "Epoch 192/200: Loss: 0.00039853322432463755\n",
      "Epoch 193/200: Loss: 0.0003988331876826123\n",
      "Epoch 194/200: Loss: 0.0005002040499675787\n",
      "Epoch 195/200: Loss: 0.0004216845745759201\n",
      "Epoch 196/200: Loss: 0.0005623443546937778\n",
      "Epoch 197/200: Loss: 0.000738557952172414\n",
      "Epoch 198/200: Loss: 0.0006422444858344533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199/200: Loss: 0.0006617562416067812\n",
      "Epoch 200/200: Loss: 0.0006283891823841258\n",
      "time costs: 882.3609175682068\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "accuarcies = []\n",
    "times = []\n",
    "\n",
    "for i in range(1):\n",
    "    print(f'training epoch: {i + 1}')\n",
    "    qmodel = QModel(input_size, hidden_size, num_output, \n",
    "                num_layers = num_layers, ctx = ctx, mode='classical')\n",
    "    optimizer = torch.optim.Adam(qmodel.parameters(), lr = 0.001)\n",
    "    loss_func = nn.MSELoss()\n",
    "    start = time.time()\n",
    "    losses = train_model(qmodel, train_data, batch_size=20,          \n",
    "                   loss_func = loss_func, optimizer = optimizer, epoch = 200)\n",
    "    end = time.time()\n",
    "\n",
    "    print(f'time costs: {end - start}')\n",
    "    times.append(end - start)\n",
    "    \n",
    "    acc = calculate_accuarcy(qmodel, X_test, y_test)[0]\n",
    "    accuarcies.append(acc)\n",
    "    \n",
    "    with open(f'loss/layer2/loss_layer2_{i + 1}.pkl', 'wb') as pkl_file:\n",
    "        pickle.dump(losses, pkl_file)\n",
    "    torch.save(qmodel.state_dict(), f\"model/layer2/model_layer2_{i+1}.pt\")\n",
    "    \n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6ac9c597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x166dfe0ec10>]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(losses, color=\"#FF6666\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d3343ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantum paramers: 96\n"
     ]
    }
   ],
   "source": [
    "print(f'quantum paramers: {QLSTM(1, 1, ctx = ctx).qparameters_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f77b43e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[98.27944412838421]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuarcies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4037ab75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.72478899241493"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0.94371223\n",
    "# \n",
    "# [tensor(0.6388),\n",
    "#  tensor(0.9699),\n",
    "#  tensor(0.9795),\n",
    "#  tensor(0.9805),\n",
    "#  tensor(0.9833),\n",
    "#  tensor(0.9587),\n",
    "#  tensor(0.9836),\n",
    "#  tensor(0.9782),\n",
    "#  tensor(0.9843),\n",
    "#  tensor(0.9803)]\n",
    "np.mean(accuarcies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5dfec15c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "597.4574043512345"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 597.4574043512345\n",
    "np.mean(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60eb24b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
