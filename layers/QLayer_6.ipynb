{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6581af8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94243045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fff0ae78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyqpanda import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "455c7f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a618a3a",
   "metadata": {},
   "source": [
    "# 1. Prepare Dadaset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c64faba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/datasets/sumanthvrao/daily-climate-time-series-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de627766",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './../data/DailyDelhiClimateTrain.csv'\n",
    "test_path = './../data/DailyDelhiClimateTest.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d0827fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [1,2,3,4]\n",
    "\n",
    "train = pd.read_csv(train_path, usecols=cols, engine=\"python\")\n",
    "test = pd.read_csv(test_path, usecols=cols, engine=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c3039c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train)=1462\n",
      "len(test)=114\n"
     ]
    }
   ],
   "source": [
    "print(f'len(train)={len(train)}')\n",
    "print(f'len(test)={len(test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b941db2e",
   "metadata": {},
   "source": [
    "## 1.1 Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e59fddc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove outliers num: 9\n"
     ]
    }
   ],
   "source": [
    "unnormal_num = 0\n",
    "for i in range(len(train)):\n",
    "    mp = train.iloc[i][3]\n",
    "    if mp > 1200 or mp < 950:\n",
    "        unnormal_num += 1\n",
    "        train.iloc[i][3] = train.iloc[i + 1][3]\n",
    "print(f'remove outliers num: {unnormal_num}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fefec4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.iloc[0][3] = test.iloc[1][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6035297e",
   "metadata": {},
   "source": [
    "## 1.2 Transfer data to LSTM representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a1277fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "884bc13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(data, window_size, predict_size):\n",
    "    scaler = StandardScaler()\n",
    "    data = scaler.fit_transform(np.array(data).reshape(-1, 1))\n",
    "    \n",
    "    data_in = []\n",
    "    data_out = []\n",
    "    \n",
    "    for i in range(data.shape[0] - window_size - predict_size):\n",
    "        data_in.append(data[i:i + window_size].reshape(1, window_size)[0])\n",
    "        data_out.append(data[i + window_size:i + window_size + predict_size].reshape(1, predict_size)[0])\n",
    "        \n",
    "    data_in = np.array(data_in).reshape(-1, window_size)\n",
    "    data_out = np.array(data_out).reshape(-1, predict_size)\n",
    "    \n",
    "    data_process = {'datain': data_in, 'dataout': data_out}\n",
    "    \n",
    "    return data_process, scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6517fe60",
   "metadata": {},
   "source": [
    "## 1.3 prepare train/test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d333c7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_size = 4\n",
    "window_size = features_size * 3 # features num * time steps\n",
    "predict_size = features_size # features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ef548b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_processed, train_scaler = data_process(train, window_size, predict_size)\n",
    "X_train, y_train = train_processed['datain'], train_processed['dataout']\n",
    "\n",
    "test_processed, test_scaler = data_process(test, window_size, predict_size)\n",
    "X_test, y_test = test_processed['datain'], test_processed['dataout']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f779325c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
    "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
    "\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dda516d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as Data\n",
    "\n",
    "train_data = Data.TensorDataset(X_train, y_train)\n",
    "test_data = Data.TensorDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cb132c",
   "metadata": {},
   "source": [
    "# 2. Quantum Enhanced LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d517f5f3",
   "metadata": {},
   "source": [
    "## 2.1 initiate quantum environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ffc85d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InitQMachine:\n",
    "    def __init__(self, qubitsCount, cbitsCount = 0, machineType = QMachineType.CPU):\n",
    "        self.machine = init_quantum_machine(machineType)\n",
    "        \n",
    "        self.qubits = self.machine.qAlloc_many(qubitsCount)\n",
    "        self.cbits = self.machine.cAlloc_many(cbitsCount)\n",
    "        \n",
    "        print(f'Init Quantum Machine with qubits:[{qubitsCount}] / cbits:[{cbitsCount}] Successfully')\n",
    "    \n",
    "    def __del__(self):\n",
    "        destroy_quantum_machine(self.machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "741a6a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Quantum Machine with qubits:[4] / cbits:[0] Successfully\n"
     ]
    }
   ],
   "source": [
    "# maximum qubits size\n",
    "ctx = InitQMachine(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a39cf3",
   "metadata": {},
   "source": [
    "## 2.2 Quantum Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63b029d",
   "metadata": {},
   "source": [
    "### 2.2.1 Quantum layer base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5570e76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from torch.nn import Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f9cfd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumLayerBase(nn.Module):\n",
    "    def __init__(self, input_size, output_size, *, n_qubits, n_layers = 1, ctx = None):\n",
    "        super(QuantumLayerBase, self).__init__()\n",
    "        \n",
    "        self.data = None # need to input during forward\n",
    "    \n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size # hidden size, not n_qubits\n",
    "        \n",
    "        # quantum infos\n",
    "        self.n_qubits = n_qubits\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.ctx = ctx\n",
    "        self.qubits = ctx.qubits\n",
    "        self.machine = ctx.machine\n",
    "        \n",
    "        # convert quantum input/output to match classical computation\n",
    "        self.qin = nn.Linear(self.input_size, self.n_qubits)\n",
    "        self.qout = nn.Linear(self.n_qubits, self.output_size)\n",
    "        \n",
    "    @property\n",
    "    def circuit(self):\n",
    "        raise NotImplementedError('Should init circuit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94c5bbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure(self):\n",
    "    HamiZ = [ PauliOperator({f'Z{i}': 1}) for i in range(len(self.qubits)) ]\n",
    "    res = [ eval(qop(self.circuit, Hami, self.machine, self.qubits))[0,0] for Hami in HamiZ ]\n",
    "    \n",
    "    return Parameter(Tensor(res[:self.n_qubits]))\n",
    "\n",
    "QuantumLayerBase.measure = measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4341341c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, inputs):\n",
    "    y_t = self.qin(Parameter(inputs))\n",
    "    self.data = y_t[0]\n",
    "    \n",
    "    return self.qout(self.measure())\n",
    "\n",
    "QuantumLayerBase.forward = forward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4f794b",
   "metadata": {},
   "source": [
    "### 2.2.2 Quantum layer design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b98a8984",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumLayer(QuantumLayerBase):\n",
    "    def __init__(self, input_size, output_size, *, n_qubits, degree = 1, n_layers = 1, ctx = None):\n",
    "        super(QuantumLayer, self).__init__(input_size, output_size, \n",
    "                                         n_qubits = n_qubits, n_layers = n_layers, ctx = ctx)\n",
    "        \n",
    "        self.degree = degree\n",
    "        self.angles = Parameter(torch.rand(n_layers, degree, self.n_qubits))\n",
    "        \n",
    "    @property\n",
    "    def qparameters_size(self):\n",
    "        return self.angles.flatten().size()[0]\n",
    "        \n",
    "    @property\n",
    "    def circuit(self):\n",
    "        if self.data == None:\n",
    "            raise ValueError('Need to feed a input data!')\n",
    "        \n",
    "        n = self.n_qubits\n",
    "        q = self.qubits\n",
    "        x = self.data\n",
    "        p = self.angles\n",
    "        degree = self.degree\n",
    "        \n",
    "        h = VariationalQuantumGate_H\n",
    "        ry = VariationalQuantumGate_RY\n",
    "        cx = VariationalQuantumGate_CNOT\n",
    "        \n",
    "        # init variational quantum circuit\n",
    "        vqc = VariationalQuantumCircuit()\n",
    "\n",
    "        # encoding layer\n",
    "        [ vqc.insert( h(q[i]) ) for i in range(n) ]\n",
    "        [ vqc.insert( ry(q[i], var(x[i] * torch.pi / 2)) ) for i in range(n) ]\n",
    "        \n",
    "        # variational layer\n",
    "        [ vqc.insert( ry(q[i], var(p[0][0][i]) )) for i in range(n) ]\n",
    "        \n",
    "        vqc.insert(cx(q[0], q[1]))\n",
    "        vqc.insert(cx(q[2], q[3]))\n",
    "        vqc.insert(cx(q[1], q[2]))\n",
    "        \n",
    "        return vqc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766692de",
   "metadata": {},
   "source": [
    "### 2.2.3 Plot Quantum Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88ff286b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyqpanda.pyQPanda.QProg at 0x1672faf1530>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Tensor([[0.1, 0.2, 0.3, 0.4]])\n",
    "layer = QuantumLayer(4, 4, n_qubits=4, n_layers=1, degree=3, ctx=ctx)\n",
    "layer.data = data[0]\n",
    "vqc = layer.circuit\n",
    "prog = create_empty_qprog()\n",
    "prog.insert(vqc.feed())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2fd364d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'null'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw_qprog(prog, 'pic', filename=f'pic/layer6')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50742459",
   "metadata": {},
   "source": [
    "## 2.3 Quantum-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e53ae0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLSTMBase(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, *, ctx):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.ctx = ctx\n",
    "        \n",
    "    @property\n",
    "    def qparameters_size(self):\n",
    "        num = 0\n",
    "        for attr in dir(self):\n",
    "            if attr.endswith('_circuit'):\n",
    "                num += getattr(self, attr).qparameters_size\n",
    "        return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "582b17af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, inputs, init_states = None):\n",
    "    sequence_size, batch_size, _ = inputs.size()\n",
    "    hidden_sequence = []\n",
    "    \n",
    "    if init_states == None:\n",
    "        h_t, c_t = (\n",
    "            torch.zeros(1, batch_size, self.hidden_size).to(inputs.device),\n",
    "            torch.zeros(1, batch_size, self.hidden_size).to(inputs.device),\n",
    "        )\n",
    "    else:\n",
    "        h_t, c_t = init_states\n",
    "    \n",
    "    return hidden_sequence, (h_t, c_t)\n",
    "\n",
    "QLSTMBase.forward = forward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d6b0af",
   "metadata": {},
   "source": [
    "## - classical quatum enhanced LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "adc8fb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLSTM(QLSTMBase):\n",
    "    def __init__(self, input_size, hidden_size, *, ctx):\n",
    "        super().__init__(input_size, hidden_size, ctx = ctx)\n",
    "    \n",
    "        # input gates\n",
    "        self.input_circuit = QuantumLayer(input_size + hidden_size, hidden_size, \n",
    "                                        n_qubits = 4, ctx = ctx) # 15\n",
    "        # forget gates\n",
    "        self.forget_circuit = QuantumLayer(input_size + hidden_size, hidden_size, \n",
    "                                         n_qubits = 4, ctx = ctx) # 15\n",
    "        # candidate\n",
    "        self.candidate_circuit = QuantumLayer(input_size + hidden_size, hidden_size, \n",
    "                                       n_qubits = 4, ctx = ctx) # 15\n",
    "        # output gates\n",
    "        self.output_circuit = QuantumLayer(input_size + hidden_size, hidden_size, \n",
    "                                         n_qubits = 4, ctx = ctx) # 15\n",
    "        \n",
    "    def forward(self, inputs, init_states = None):\n",
    "        hidden_sequence, (h_t, c_t) = super(QLSTM, self).forward(inputs, init_states)\n",
    "\n",
    "        for t in range(inputs.size()[0]):\n",
    "            x_t = inputs[t, :, :]\n",
    "            v_t = torch.cat((h_t[0], x_t), dim = 1)\n",
    "\n",
    "            # input gates\n",
    "            i_t = torch.sigmoid(self.input_circuit(v_t))\n",
    "            # forget gates\n",
    "            f_t = torch.sigmoid(self.forget_circuit(v_t))\n",
    "            # candidate for cell state update\n",
    "            g_t = torch.tanh(self.candidate_circuit(v_t))\n",
    "            c_t = (f_t * c_t) + (i_t * g_t)\n",
    "\n",
    "            # output gates\n",
    "            o_t = torch.sigmoid(self.output_circuit(v_t))\n",
    "            # update output ht\n",
    "            h_t = o_t * (torch.tanh(c_t))\n",
    "\n",
    "            hidden_sequence.append(h_t)\n",
    "\n",
    "        # reshape hidden_seq p/ retornar\n",
    "        #\n",
    "        # [tensor([[[0.0444, ...]]] => tensor([[[0.0444, ...]]]\n",
    "        # \n",
    "        hidden_sequence = torch.cat(hidden_sequence, dim = 0)\n",
    "\n",
    "        return hidden_sequence, (h_t, c_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28836475",
   "metadata": {},
   "source": [
    "## 2.4 Stacked QLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ec06c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "class StackedQLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, *, num_layers = 1, ctx = None, mode = 'classical'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.qlstms = nn.Sequential(OrderedDict([\n",
    "            (f'QLSTM {i + 1}', QLSTM(input_size if i == 0 else hidden_size , hidden_size, ctx = ctx)) \n",
    "                for i in range(num_layers)\n",
    "        ]))\n",
    "\n",
    "    def forward(self, inputs, parameters = None):\n",
    "        outputs = None\n",
    "        \n",
    "        for i, qlstm in enumerate(self.qlstms):\n",
    "            if i != 0:\n",
    "                inputs = outputs\n",
    "            \n",
    "            outputs, parameters = qlstm(inputs, parameters)\n",
    "        \n",
    "        return outputs, parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0389535c",
   "metadata": {},
   "source": [
    "# 3. Quantum Model and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "413150bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_output, *, num_layers = 1, ctx = None, mode = 'classical'):\n",
    "        super(QModel, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.qlstm = StackedQLSTM(input_size, hidden_size, \n",
    "                                  num_layers = num_layers, ctx = ctx, mode = mode)\n",
    "        self.predict = nn.Linear(hidden_size, num_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(0)\n",
    "        \n",
    "        # sequence lenth , batch_size, features length\n",
    "        # \n",
    "        h0 = torch.zeros(1, x.size(1), self.hidden_size)\n",
    "        c0 = torch.zeros(1, x.size(1), self.hidden_size)\n",
    "        \n",
    "        out, _ = self.qlstm(x, (h0, c0))\n",
    "        out = self.predict(out[0])\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111aebe4",
   "metadata": {},
   "source": [
    "## 3.1 train QModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bc1d1439",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import RandomSampler\n",
    "\n",
    "def train_model(model, datas, batch_size, *, loss_func, optimizer, epoch = 50):\n",
    "    losses = []\n",
    "    sampler = RandomSampler(datas, num_samples = batch_size)\n",
    "    \n",
    "    for step in range(epoch):\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for index in sampler:\n",
    "            batch_x, batch_y = datas[index][0], datas[index][1]\n",
    "            b_x = batch_x.unsqueeze(0)\n",
    "            b_y = batch_y.unsqueeze(0)\n",
    "            \n",
    "            output = model(b_x)\n",
    "\n",
    "            loss = loss_func(output, b_y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        print(f'Epoch {step + 1}/{epoch}: Loss: {train_loss / batch_size}')\n",
    "        losses.append(train_loss / batch_size)\n",
    "    \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef07934f",
   "metadata": {},
   "source": [
    "## 3.2 Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57e9b387",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "def MAE_naive(actuals, predicteds):\n",
    "    n = len(actuals)\n",
    "    err = 0.0\n",
    "    \n",
    "    for i in range(1, n):\n",
    "        err += np.abs(actuals[i] - actuals[i - 1])\n",
    "    return err / (n - 1)\n",
    "\n",
    "def calculate_accuarcy(model, X_test, y_test, scaler=test_scaler):\n",
    "    n = len(X_test)\n",
    "    \n",
    "    actuals = []\n",
    "    predicteds = []\n",
    "    \n",
    "    for i in range(0, n, predict_size):\n",
    "        actual = scaler.inverse_transform(y_test[i:i+1].data)\n",
    "        actuals.append(np.array(actual[0]))\n",
    "        predicted = scaler.inverse_transform(model(X_test[i:i+1]).data)\n",
    "        predicteds.append(np.array(predicted[0]))\n",
    "    \n",
    "    actuals = np.array(actuals)\n",
    "    predicteds = np.array(predicteds)\n",
    "    \n",
    "    mae = mean_absolute_error(actuals, predicteds)\n",
    "    mase = mae / MAE_naive(actuals.flatten(), predicteds.flatten())\n",
    "    mape = mean_absolute_percentage_error(actuals, predicteds)\n",
    "    mse = mean_squared_error(actuals, predicteds)\n",
    "    rmse = mse ** 0.5\n",
    "    \n",
    "    return np.array([(1 - mase) * 100, rmse, mse, mae, mape])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6407f969",
   "metadata": {},
   "source": [
    "## 3.3 Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "305c9471",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_size = 4\n",
    "window_size = features_size * 3 # \n",
    "predict_size = features_size # features\n",
    "\n",
    "input_size = window_size\n",
    "num_output = predict_size\n",
    "\n",
    "hidden_size = 32\n",
    "num_layers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "50472565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training epoch: 1\n",
      "Epoch 1/200: Loss: 1.0170694768428803\n",
      "Epoch 2/200: Loss: 0.9943442583084107\n",
      "Epoch 3/200: Loss: 0.9863501489162445\n",
      "Epoch 4/200: Loss: 0.9697589129209518\n",
      "Epoch 5/200: Loss: 0.9687036126852036\n",
      "Epoch 6/200: Loss: 0.9876512259244918\n",
      "Epoch 7/200: Loss: 0.97669777572155\n",
      "Epoch 8/200: Loss: 0.9664420515298844\n",
      "Epoch 9/200: Loss: 0.9363575994968414\n",
      "Epoch 10/200: Loss: 0.9513701170682907\n",
      "Epoch 11/200: Loss: 0.9547044903039932\n",
      "Epoch 12/200: Loss: 0.9305862098932266\n",
      "Epoch 13/200: Loss: 0.8771763145923615\n",
      "Epoch 14/200: Loss: 0.9029681950807571\n",
      "Epoch 15/200: Loss: 0.8965591341257095\n",
      "Epoch 16/200: Loss: 0.9238628149032593\n",
      "Epoch 17/200: Loss: 0.8674261748790741\n",
      "Epoch 18/200: Loss: 0.8434236824512482\n",
      "Epoch 19/200: Loss: 0.8263620465993882\n",
      "Epoch 20/200: Loss: 0.8064547806978226\n",
      "Epoch 21/200: Loss: 0.8155294954776764\n",
      "Epoch 22/200: Loss: 0.7916770815849304\n",
      "Epoch 23/200: Loss: 0.7607294589281082\n",
      "Epoch 24/200: Loss: 0.7149068892002106\n",
      "Epoch 25/200: Loss: 0.736694073677063\n",
      "Epoch 26/200: Loss: 0.7194078624248504\n",
      "Epoch 27/200: Loss: 0.6594485834240913\n",
      "Epoch 28/200: Loss: 0.7156582280993462\n",
      "Epoch 29/200: Loss: 0.6590166494250298\n",
      "Epoch 30/200: Loss: 0.6467734605073929\n",
      "Epoch 31/200: Loss: 0.6609167471528054\n",
      "Epoch 32/200: Loss: 0.6549388155341148\n",
      "Epoch 33/200: Loss: 0.5470110058784485\n",
      "Epoch 34/200: Loss: 0.6988289520144463\n",
      "Epoch 35/200: Loss: 0.5942287087440491\n",
      "Epoch 36/200: Loss: 0.6553173661231995\n",
      "Epoch 37/200: Loss: 0.5761600360274315\n",
      "Epoch 38/200: Loss: 0.6591442286968231\n",
      "Epoch 39/200: Loss: 0.5915149599313736\n",
      "Epoch 40/200: Loss: 0.6660921096801757\n",
      "Epoch 41/200: Loss: 0.5827212512493134\n",
      "Epoch 42/200: Loss: 0.6736566677689553\n",
      "Epoch 43/200: Loss: 0.6472765669226647\n",
      "Epoch 44/200: Loss: 0.6221549227833748\n",
      "Epoch 45/200: Loss: 0.6772267684340477\n",
      "Epoch 46/200: Loss: 0.6008173808455467\n",
      "Epoch 47/200: Loss: 0.5830767929553986\n",
      "Epoch 48/200: Loss: 0.6094441458582878\n",
      "Epoch 49/200: Loss: 0.6256171628832817\n",
      "Epoch 50/200: Loss: 0.5787941440939903\n",
      "Epoch 51/200: Loss: 0.5815535739064217\n",
      "Epoch 52/200: Loss: 0.5270261511206626\n",
      "Epoch 53/200: Loss: 0.5380783751606941\n",
      "Epoch 54/200: Loss: 0.553477056324482\n",
      "Epoch 55/200: Loss: 0.538200031220913\n",
      "Epoch 56/200: Loss: 0.49378332644701006\n",
      "Epoch 57/200: Loss: 0.560545203089714\n",
      "Epoch 58/200: Loss: 0.507291454076767\n",
      "Epoch 59/200: Loss: 0.5637480705976486\n",
      "Epoch 60/200: Loss: 0.5696416109800339\n",
      "Epoch 61/200: Loss: 0.526773390173912\n",
      "Epoch 62/200: Loss: 0.4667593568563461\n",
      "Epoch 63/200: Loss: 0.5374358296394348\n",
      "Epoch 64/200: Loss: 0.47352212369441987\n",
      "Epoch 65/200: Loss: 0.4348007902503014\n",
      "Epoch 66/200: Loss: 0.4459344193339348\n",
      "Epoch 67/200: Loss: 0.4628292128443718\n",
      "Epoch 68/200: Loss: 0.41953726559877397\n",
      "Epoch 69/200: Loss: 0.4038158133625984\n",
      "Epoch 70/200: Loss: 0.38402732610702517\n",
      "Epoch 71/200: Loss: 0.40950903594493865\n",
      "Epoch 72/200: Loss: 0.39542373865842817\n",
      "Epoch 73/200: Loss: 0.3853374496102333\n",
      "Epoch 74/200: Loss: 0.3979192703962326\n",
      "Epoch 75/200: Loss: 0.38954064846038816\n",
      "Epoch 76/200: Loss: 0.3671344704926014\n",
      "Epoch 77/200: Loss: 0.38284900039434433\n",
      "Epoch 78/200: Loss: 0.32910488098859786\n",
      "Epoch 79/200: Loss: 0.34307130575180056\n",
      "Epoch 80/200: Loss: 0.3430123418569565\n",
      "Epoch 81/200: Loss: 0.30101579502224923\n",
      "Epoch 82/200: Loss: 0.28781361058354377\n",
      "Epoch 83/200: Loss: 0.2978885114192963\n",
      "Epoch 84/200: Loss: 0.2975038878619671\n",
      "Epoch 85/200: Loss: 0.25106112062931063\n",
      "Epoch 86/200: Loss: 0.2533844619989395\n",
      "Epoch 87/200: Loss: 0.2796007454395294\n",
      "Epoch 88/200: Loss: 0.21077547818422318\n",
      "Epoch 89/200: Loss: 0.26454604119062425\n",
      "Epoch 90/200: Loss: 0.2075517348945141\n",
      "Epoch 91/200: Loss: 0.23332880139350892\n",
      "Epoch 92/200: Loss: 0.2217317596077919\n",
      "Epoch 93/200: Loss: 0.20735513046383858\n",
      "Epoch 94/200: Loss: 0.20344016551971436\n",
      "Epoch 95/200: Loss: 0.19050140753388406\n",
      "Epoch 96/200: Loss: 0.17752787470817566\n",
      "Epoch 97/200: Loss: 0.17634900361299516\n",
      "Epoch 98/200: Loss: 0.14383931681513787\n",
      "Epoch 99/200: Loss: 0.17090680450201035\n",
      "Epoch 100/200: Loss: 0.1467245563864708\n",
      "Epoch 101/200: Loss: 0.166375482827425\n",
      "Epoch 102/200: Loss: 0.13994685597717763\n",
      "Epoch 103/200: Loss: 0.1276819959282875\n",
      "Epoch 104/200: Loss: 0.12295448128134012\n",
      "Epoch 105/200: Loss: 0.12109419330954552\n",
      "Epoch 106/200: Loss: 0.11276872530579567\n",
      "Epoch 107/200: Loss: 0.0966988168656826\n",
      "Epoch 108/200: Loss: 0.09622622150927782\n",
      "Epoch 109/200: Loss: 0.08325682617723942\n",
      "Epoch 110/200: Loss: 0.07822024999186397\n",
      "Epoch 111/200: Loss: 0.06990214493125677\n",
      "Epoch 112/200: Loss: 0.07807055925950408\n",
      "Epoch 113/200: Loss: 0.07128112260252237\n",
      "Epoch 114/200: Loss: 0.06585926311090588\n",
      "Epoch 115/200: Loss: 0.06811842694878578\n",
      "Epoch 116/200: Loss: 0.04977231258526445\n",
      "Epoch 117/200: Loss: 0.04325708830729127\n",
      "Epoch 118/200: Loss: 0.056493199057877065\n",
      "Epoch 119/200: Loss: 0.04301754953339696\n",
      "Epoch 120/200: Loss: 0.05034944335930049\n",
      "Epoch 121/200: Loss: 0.046723883412778375\n",
      "Epoch 122/200: Loss: 0.03200313716661185\n",
      "Epoch 123/200: Loss: 0.05465644388459623\n",
      "Epoch 124/200: Loss: 0.03246366488747299\n",
      "Epoch 125/200: Loss: 0.033699228800833224\n",
      "Epoch 126/200: Loss: 0.028386706905439495\n",
      "Epoch 127/200: Loss: 0.0221920364536345\n",
      "Epoch 128/200: Loss: 0.0261146827833727\n",
      "Epoch 129/200: Loss: 0.01732891850406304\n",
      "Epoch 130/200: Loss: 0.02855448176851496\n",
      "Epoch 131/200: Loss: 0.017445665696868673\n",
      "Epoch 132/200: Loss: 0.01558103811694309\n",
      "Epoch 133/200: Loss: 0.021085178863722832\n",
      "Epoch 134/200: Loss: 0.020565566583536567\n",
      "Epoch 135/200: Loss: 0.013231868587899953\n",
      "Epoch 136/200: Loss: 0.012987472757231444\n",
      "Epoch 137/200: Loss: 0.010580683266744018\n",
      "Epoch 138/200: Loss: 0.0109928545600269\n",
      "Epoch 139/200: Loss: 0.00840843805053737\n",
      "Epoch 140/200: Loss: 0.006201988333486952\n",
      "Epoch 141/200: Loss: 0.007697327178902924\n",
      "Epoch 142/200: Loss: 0.009176578013284597\n",
      "Epoch 143/200: Loss: 0.00738475426696823\n",
      "Epoch 144/200: Loss: 0.0075886904938670344\n",
      "Epoch 145/200: Loss: 0.010384667135076598\n",
      "Epoch 146/200: Loss: 0.004734727974573616\n",
      "Epoch 147/200: Loss: 0.00550397845072439\n",
      "Epoch 148/200: Loss: 0.00347130257578101\n",
      "Epoch 149/200: Loss: 0.004443955663373344\n",
      "Epoch 150/200: Loss: 0.0025400720223842654\n",
      "Epoch 151/200: Loss: 0.004354979583877139\n",
      "Epoch 152/200: Loss: 0.0040337745289434675\n",
      "Epoch 153/200: Loss: 0.0053447815706022085\n",
      "Epoch 154/200: Loss: 0.00420425280026393\n",
      "Epoch 155/200: Loss: 0.0038382954925509694\n",
      "Epoch 156/200: Loss: 0.0036630633345339446\n",
      "Epoch 157/200: Loss: 0.003571976314560743\n",
      "Epoch 158/200: Loss: 0.002865724573348416\n",
      "Epoch 159/200: Loss: 0.002514307085584733\n",
      "Epoch 160/200: Loss: 0.004477020263948361\n",
      "Epoch 161/200: Loss: 0.0021052360301837326\n",
      "Epoch 162/200: Loss: 0.001190624693845166\n",
      "Epoch 163/200: Loss: 0.0018579558343844837\n",
      "Epoch 164/200: Loss: 0.002775654337165179\n",
      "Epoch 165/200: Loss: 0.0022392481379938543\n",
      "Epoch 166/200: Loss: 0.001057041894637223\n",
      "Epoch 167/200: Loss: 0.0009282566612455412\n",
      "Epoch 168/200: Loss: 0.0014080143816499913\n",
      "Epoch 169/200: Loss: 0.0020250179528375155\n",
      "Epoch 170/200: Loss: 0.0009878337410555104\n",
      "Epoch 171/200: Loss: 0.002537598032358801\n",
      "Epoch 172/200: Loss: 0.004121379852222162\n",
      "Epoch 173/200: Loss: 0.0022241470160224708\n",
      "Epoch 174/200: Loss: 0.0013225704384240088\n",
      "Epoch 175/200: Loss: 0.0019234447292546975\n",
      "Epoch 176/200: Loss: 0.0029919132435679784\n",
      "Epoch 177/200: Loss: 0.0019441155651293228\n",
      "Epoch 178/200: Loss: 0.0010626049192069332\n",
      "Epoch 179/200: Loss: 0.0031166514183496473\n",
      "Epoch 180/200: Loss: 0.0023526046072220195\n",
      "Epoch 181/200: Loss: 0.0012865147926277131\n",
      "Epoch 182/200: Loss: 0.0015258071820426268\n",
      "Epoch 183/200: Loss: 0.0009690164421044756\n",
      "Epoch 184/200: Loss: 0.001858994045142026\n",
      "Epoch 185/200: Loss: 0.003225649259184138\n",
      "Epoch 186/200: Loss: 0.008092175520596356\n",
      "Epoch 187/200: Loss: 0.0010780927211271774\n",
      "Epoch 188/200: Loss: 0.0017589935574505943\n",
      "Epoch 189/200: Loss: 0.0023472911736462264\n",
      "Epoch 190/200: Loss: 0.0034589885312016123\n",
      "Epoch 191/200: Loss: 0.0020578997187840286\n",
      "Epoch 192/200: Loss: 0.0024398246430791916\n",
      "Epoch 193/200: Loss: 0.003248297502977948\n",
      "Epoch 194/200: Loss: 0.0020000203017843886\n",
      "Epoch 195/200: Loss: 0.001648359308455838\n",
      "Epoch 196/200: Loss: 0.0014599180653021905\n",
      "Epoch 197/200: Loss: 0.0009851977081780205\n",
      "Epoch 198/200: Loss: 0.0016571968419157202\n",
      "Epoch 199/200: Loss: 0.001879295699109207\n",
      "Epoch 200/200: Loss: 0.0018980370563440375\n",
      "time costs: 905.4613335132599\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "accuarcies = []\n",
    "times = []\n",
    "\n",
    "for i in range(1):\n",
    "    print(f'training epoch: {i + 1}')\n",
    "    qmodel = QModel(input_size, hidden_size, num_output, \n",
    "                num_layers = num_layers, ctx = ctx, mode='classical')\n",
    "    optimizer = torch.optim.Adam(qmodel.parameters(), lr = 0.001)\n",
    "    loss_func = nn.MSELoss()\n",
    "    start = time.time()\n",
    "    losses = train_model(qmodel, train_data, batch_size=20,          \n",
    "                   loss_func = loss_func, optimizer = optimizer, epoch = 200)\n",
    "    end = time.time()\n",
    "\n",
    "    print(f'time costs: {end - start}')\n",
    "    times.append(end - start)\n",
    "    \n",
    "    acc = calculate_accuarcy(qmodel, X_test, y_test)[0]\n",
    "    accuarcies.append(acc)\n",
    "    \n",
    "    with open(f'loss/layer6/loss_layer6_{i + 1}.pkl', 'wb') as pkl_file:\n",
    "        pickle.dump(losses, pkl_file)\n",
    "    torch.save(qmodel.state_dict(), f\"model/layer6/model_layer6_{i+1}.pt\")\n",
    "    \n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6ac9c597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16739b0cf40>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(losses, color=\"#FF6666\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d3343ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantum paramers: 16\n"
     ]
    }
   ],
   "source": [
    "print(f'quantum paramers: {QLSTM(1, 1, ctx = ctx).qparameters_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "46f6f504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[97.63765791166317]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuarcies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d5af0126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84.95172216442157"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 84.95172216442157\n",
    "# \n",
    "# [97.55765262371202,\n",
    "#  83.32441209282517,\n",
    "#  96.3045084035267,\n",
    "#  56.08851310089852,\n",
    "#  96.46727799998833,\n",
    "#  92.58356227366893,\n",
    "#  88.60902168118207,\n",
    "#  96.38772477862966,\n",
    "#  43.72888332919298,\n",
    "#  98.46566536059125]\n",
    "np.mean(accuarcies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5e317ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "529.8514951467514"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 529.8514951467514\n",
    "np.mean(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4297e213",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abd9cda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
