{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96963d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efc40d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33a08936",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyqpanda import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01c40c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d48811",
   "metadata": {},
   "source": [
    "# 1. Prepare Dadaset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "757bbfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/datasets/sumanthvrao/daily-climate-time-series-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91a53ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './../data/DailyDelhiClimateTrain.csv'\n",
    "test_path = './../data/DailyDelhiClimateTest.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef5a3d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [1,2,3,4]\n",
    "\n",
    "train = pd.read_csv(train_path, usecols=cols, engine=\"python\")\n",
    "test = pd.read_csv(test_path, usecols=cols, engine=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c112f41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train)=1462\n",
      "len(test)=114\n"
     ]
    }
   ],
   "source": [
    "print(f'len(train)={len(train)}')\n",
    "print(f'len(test)={len(test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ca701d",
   "metadata": {},
   "source": [
    "## 1.1 Outlier Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b3dc6f",
   "metadata": {},
   "source": [
    "### 1.1.1 outlier detection for train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d076311",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2a498b82b20>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(range(len(train)), train[\"meanpressure\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6f7435",
   "metadata": {},
   "source": [
    "### - remove outliers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb83d8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove outliers num: 9\n"
     ]
    }
   ],
   "source": [
    "unnormal_num = 0\n",
    "for i in range(len(train)):\n",
    "    mp = train.iloc[i][3]\n",
    "    if mp > 1200 or mp < 950:\n",
    "        unnormal_num += 1\n",
    "        train.iloc[i][3] = train.iloc[i + 1][3]\n",
    "print(f'remove outliers num: {unnormal_num}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c182752f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2a498c7c310>,\n",
       " <matplotlib.lines.Line2D at 0x2a498c7c430>,\n",
       " <matplotlib.lines.Line2D at 0x2a498c7c4f0>,\n",
       " <matplotlib.lines.Line2D at 0x2a498c7c5b0>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2a352d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>meantemp</th>\n",
       "      <td>1462.0</td>\n",
       "      <td>25.495521</td>\n",
       "      <td>7.348103</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>18.857143</td>\n",
       "      <td>27.714286</td>\n",
       "      <td>31.305804</td>\n",
       "      <td>38.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>humidity</th>\n",
       "      <td>1462.0</td>\n",
       "      <td>60.771702</td>\n",
       "      <td>16.769652</td>\n",
       "      <td>13.428571</td>\n",
       "      <td>50.375000</td>\n",
       "      <td>62.625000</td>\n",
       "      <td>72.218750</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wind_speed</th>\n",
       "      <td>1462.0</td>\n",
       "      <td>6.802209</td>\n",
       "      <td>4.561602</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.475000</td>\n",
       "      <td>6.221667</td>\n",
       "      <td>9.238235</td>\n",
       "      <td>42.220000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meanpressure</th>\n",
       "      <td>1462.0</td>\n",
       "      <td>1008.247674</td>\n",
       "      <td>7.437992</td>\n",
       "      <td>991.375000</td>\n",
       "      <td>1001.625000</td>\n",
       "      <td>1008.563492</td>\n",
       "      <td>1014.875000</td>\n",
       "      <td>1023.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count         mean        std         min          25%  \\\n",
       "meantemp      1462.0    25.495521   7.348103    6.000000    18.857143   \n",
       "humidity      1462.0    60.771702  16.769652   13.428571    50.375000   \n",
       "wind_speed    1462.0     6.802209   4.561602    0.000000     3.475000   \n",
       "meanpressure  1462.0  1008.247674   7.437992  991.375000  1001.625000   \n",
       "\n",
       "                      50%          75%          max  \n",
       "meantemp        27.714286    31.305804    38.714286  \n",
       "humidity        62.625000    72.218750   100.000000  \n",
       "wind_speed       6.221667     9.238235    42.220000  \n",
       "meanpressure  1008.563492  1014.875000  1023.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52776605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meantemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>meanpressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>84.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1015.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   meantemp  humidity  wind_speed  meanpressure\n",
       "0      10.0      84.5         0.0   1015.666667"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6e536f",
   "metadata": {},
   "source": [
    "### 1.1.2 outlier detection for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fa0149b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2a498d17e80>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(range(len(test)), test[\"meanpressure\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09b1874",
   "metadata": {},
   "source": [
    "### - remove outliers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d62ae65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.iloc[0][3] = test.iloc[1][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6cf7014f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2a498d761c0>,\n",
       " <matplotlib.lines.Line2D at 0x2a498d762e0>,\n",
       " <matplotlib.lines.Line2D at 0x2a498d763a0>,\n",
       " <matplotlib.lines.Line2D at 0x2a498d76460>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddd4f67",
   "metadata": {},
   "source": [
    "## 1.2 Transfer data to LSTM representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d1fe2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d28fd514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(data, window_size, predict_size):\n",
    "    scaler = StandardScaler()\n",
    "    data = scaler.fit_transform(np.array(data).reshape(-1, 1))\n",
    "    \n",
    "    data_in = []\n",
    "    data_out = []\n",
    "    \n",
    "    for i in range(data.shape[0] - window_size - predict_size):\n",
    "        data_in.append(data[i:i + window_size].reshape(1, window_size)[0])\n",
    "        data_out.append(data[i + window_size:i + window_size + predict_size].reshape(1, predict_size)[0])\n",
    "        \n",
    "    data_in = np.array(data_in).reshape(-1, window_size)\n",
    "    data_out = np.array(data_out).reshape(-1, predict_size)\n",
    "    \n",
    "    data_process = {'datain': data_in, 'dataout': data_out}\n",
    "    \n",
    "    return data_process, scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b642d83",
   "metadata": {},
   "source": [
    "## 1.3 prepare train/test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1b5ca0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_size = 4\n",
    "window_size = features_size * 3 # features num * time steps\n",
    "predict_size = features_size # features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da56bdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_processed, train_scaler = data_process(train, window_size, predict_size)\n",
    "X_train, y_train = train_processed['datain'], train_processed['dataout']\n",
    "\n",
    "test_processed, test_scaler = data_process(test, window_size, predict_size)\n",
    "X_test, y_test = test_processed['datain'], test_processed['dataout']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89c5ab59",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
    "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
    "\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81da8b10",
   "metadata": {},
   "source": [
    "### - data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "881c39bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as Data\n",
    "\n",
    "train_data = Data.TensorDataset(X_train, y_train)\n",
    "test_data = Data.TensorDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "000e5717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of train_data: 5832\n",
      "size of test_data: 440\n"
     ]
    }
   ],
   "source": [
    "print(f'size of train_data: {len(train_data)}')\n",
    "print(f'size of test_data: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd5abd4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.6262, -0.4504, -0.6498,  1.7473, -0.6323, -0.4327, -0.6428,  1.7523,\n",
       "         -0.6329, -0.4445, -0.6389,  1.7543]),\n",
       " tensor([-0.6293, -0.4814, -0.6469,  1.7508]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f77a830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.6067, -0.4426, -0.6376,  1.7437, -0.6006, -0.4629, -0.6372,  1.7437,\n",
       "         -0.6039, -0.4520, -0.6346,  1.7438]),\n",
       " tensor([-0.6001, -0.4797, -0.6333,  1.7377]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99ad9fa",
   "metadata": {},
   "source": [
    "# 2. Quantum Enhanced LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee1c6bb",
   "metadata": {},
   "source": [
    "## 2.1 initiate quantum environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f83f918",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InitQMachine:\n",
    "    def __init__(self, qubitsCount, cbitsCount = 0, machineType = QMachineType.CPU):\n",
    "        self.machine = init_quantum_machine(machineType)\n",
    "        \n",
    "        self.qubits = self.machine.qAlloc_many(qubitsCount)\n",
    "        self.cbits = self.machine.cAlloc_many(cbitsCount)\n",
    "        \n",
    "        print(f'Init Quantum Machine with qubits:[{qubitsCount}] / cbits:[{cbitsCount}] Successfully')\n",
    "    \n",
    "    def __del__(self):\n",
    "        destroy_quantum_machine(self.machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b73cfac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Quantum Machine with qubits:[5] / cbits:[0] Successfully\n"
     ]
    }
   ],
   "source": [
    "# maximum qubits size\n",
    "ctx = InitQMachine(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fd176a",
   "metadata": {},
   "source": [
    "## 2.2 Quantum Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993c3c69",
   "metadata": {},
   "source": [
    "### - Tool Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "467e68dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(prog, filename=''):\n",
    "    dir_path = './images/'\n",
    "    \n",
    "    if filename != '':\n",
    "        draw_qprog(prog, 'pic', filename=f'{dir_path}{filename}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1db12c",
   "metadata": {},
   "source": [
    "### 2.2.1 Quantum Layer Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a9372635",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from torch.nn import Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0ef35c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumLayerBase(nn.Module):\n",
    "    def __init__(self, input_size, output_size, *, n_qubits, n_layers = 1, ctx = None):\n",
    "        super(QuantumLayerBase, self).__init__()\n",
    "        \n",
    "        self.data = None # need to input during forward\n",
    "    \n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size # hidden size, not n_qubits\n",
    "        \n",
    "        # quantum infos\n",
    "        self.n_qubits = n_qubits\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.ctx = ctx\n",
    "        self.qubits = ctx.qubits\n",
    "        self.machine = ctx.machine\n",
    "        \n",
    "        # convert quantum input/output to match classical computation\n",
    "        self.qin = nn.Linear(self.input_size, self.n_qubits)\n",
    "        self.qout = nn.Linear(self.n_qubits, self.output_size)\n",
    "        \n",
    "    @property\n",
    "    def circuit(self):\n",
    "        raise NotImplementedError('Should init circuit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "21d0b1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure(self):\n",
    "    HamiZ = [ PauliOperator({f'Z{i}': 1}) for i in range(len(self.qubits)) ]\n",
    "    res = [ eval(qop(self.circuit, Hami, self.machine, self.qubits))[0,0] for Hami in HamiZ ]\n",
    "    \n",
    "    return Parameter(Tensor(res[:self.n_qubits]))\n",
    "\n",
    "QuantumLayerBase.measure = measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8dd09ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, inputs):\n",
    "    y_t = self.qin(Parameter(inputs))\n",
    "    self.data = y_t[0]\n",
    "    \n",
    "    return self.qout(self.measure())\n",
    "\n",
    "QuantumLayerBase.forward = forward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73293db3",
   "metadata": {},
   "source": [
    "### 2.2.2 Quantum Layer Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "165b7df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_lock = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3f45cef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumLayer(QuantumLayerBase):\n",
    "    def __init__(self, input_size, output_size, *, n_qubits, degree = 1, n_layers = 1, ctx = None, dropout_rate = 0):\n",
    "        super(QuantumLayer, self).__init__(input_size, output_size, \n",
    "                                         n_qubits = n_qubits, n_layers = n_layers, ctx = ctx)\n",
    "        \n",
    "        self.degree = degree\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.angles = Parameter(torch.rand(n_layers + 1, degree, self.n_qubits))\n",
    "        \n",
    "    @property\n",
    "    def qparameters_size(self):\n",
    "        return self.angles.flatten().size()[0]\n",
    "        \n",
    "    @property\n",
    "    def circuit(self):\n",
    "        if self.data == None:\n",
    "            raise ValueError('Need to feed a input data!')\n",
    "        \n",
    "        n = self.n_qubits\n",
    "        q = self.qubits\n",
    "        x = self.data\n",
    "        p = self.angles\n",
    "        degree = self.degree\n",
    "        \n",
    "        # quantum gates - must use small case!\n",
    "        identity = VariationalQuantumGate_I\n",
    "        h = VariationalQuantumGate_H\n",
    "        YGate = VariationalQuantumGate_Y\n",
    "        ry = VariationalQuantumGate_RY\n",
    "        cz = VariationalQuantumGate_CZ\n",
    "        u = [\n",
    "            None,\n",
    "            VariationalQuantumGate_U1,\n",
    "            VariationalQuantumGate_U2,\n",
    "            VariationalQuantumGate_U3\n",
    "        ]\n",
    "        \n",
    "        # init variational quantum circuit\n",
    "        vqc = VariationalQuantumCircuit()\n",
    "\n",
    "        # in order to use each qubits => when n_qubits < len(ctx.qubits)\n",
    "        [ vqc.insert(identity(q[i])) for i in range(len(q)) ]\n",
    "        \n",
    "        [ vqc.insert( h(q[i]) ) for i in range(n) ]\n",
    "        [ vqc.insert( ry(q[i], var(x[i] * torch.pi / 2)) ) for i in range(n) ]\n",
    "        \n",
    "    \n",
    "        for i in range(n):\n",
    "            vqc.insert( u[degree](q[i], *[ var(p[0][d][i]) for d in range(degree) ]) )\n",
    "            if dropout_lock and np.random.rand() <= self.dropout_rate:\n",
    "                vqc.insert( YGate(q[i]) )\n",
    "        \n",
    "        for layer in range(self.n_layers):\n",
    "            for i in range(n - 1):\n",
    "                vqc.insert(cz(q[i], q[i + 1]))\n",
    "            vqc.insert(cz(q[n - 1], q[0]))\n",
    "            \n",
    "            for i in range(n):\n",
    "                vqc.insert( u[degree](q[i], *[ var(p[layer + 1][d][i]) for d in range(degree) ]) )\n",
    "                if dropout_lock and np.random.rand() <= self.dropout_rate:\n",
    "                    vqc.insert( YGate(q[i]) )\n",
    "        \n",
    "        return vqc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e12b97",
   "metadata": {},
   "source": [
    "### 2.2.3 Plot Quantum layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "035d900b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyqpanda.pyQPanda.QProg at 0x2a498d482f0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Tensor([[0.1, 0.2, 0.3, 0.4, 0.5]])\n",
    "layer = QuantumLayer(5, 5, n_qubits=5, n_layers=1, degree=3, dropout_rate=0.3, ctx=ctx)\n",
    "layer.data = data[0]\n",
    "vqc = layer.circuit\n",
    "prog = create_empty_qprog()\n",
    "prog.insert(vqc.feed())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3c217a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'null'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw_qprog(prog, 'pic', filename=f'pic/bit_phase_flip_yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d956e7",
   "metadata": {},
   "source": [
    "## 2.3 Quantum-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0d437f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLSTMBase(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, *, ctx, dropout_rate=0):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.ctx = ctx\n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "    @property\n",
    "    def qparameters_size(self):\n",
    "        num = 0\n",
    "        for attr in dir(self):\n",
    "            if attr.endswith('_circuit'):\n",
    "                num += getattr(self, attr).qparameters_size\n",
    "        return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "be3c3cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, inputs, init_states = None):\n",
    "    sequence_size, batch_size, _ = inputs.size()\n",
    "    hidden_sequence = []\n",
    "    \n",
    "    if init_states == None:\n",
    "        h_t, c_t = (\n",
    "            torch.zeros(1, batch_size, self.hidden_size).to(inputs.device),\n",
    "            torch.zeros(1, batch_size, self.hidden_size).to(inputs.device),\n",
    "        )\n",
    "    else:\n",
    "        h_t, c_t = init_states\n",
    "    \n",
    "    return hidden_sequence, (h_t, c_t)\n",
    "\n",
    "QLSTMBase.forward = forward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce36bcc1",
   "metadata": {},
   "source": [
    "### 2.3.1 classical Quantum-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1539d83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLSTM(QLSTMBase):\n",
    "    def __init__(self, input_size, hidden_size, *, ctx, dropout_rate=0):\n",
    "        super().__init__(input_size, hidden_size, ctx = ctx, dropout_rate = dropout_rate)\n",
    "        \n",
    "        # Parameters: angles\n",
    "        #  => Q * (n + 1) * degree\n",
    "        \n",
    "        # gates names:  qubits  layers  degree\n",
    "        # input gate:     5       2       3\n",
    "        # forget gate:    5       2       3\n",
    "        # candidate:      5       2       3\n",
    "        # output gate:    5       2       3\n",
    "        \n",
    "        # input gates\n",
    "        self.input_circuit = QuantumLayer(input_size + hidden_size, hidden_size, \n",
    "                                        n_qubits = 5, n_layers = 2, degree = 3, ctx = ctx, dropout_rate = dropout_rate) # 45\n",
    "        # forget gates\n",
    "        self.forget_circuit = QuantumLayer(input_size + hidden_size, hidden_size, \n",
    "                                         n_qubits = 5, n_layers = 2, degree = 3, ctx = ctx, dropout_rate = dropout_rate) # 45\n",
    "        # candidate\n",
    "        self.candidate_circuit = QuantumLayer(input_size + hidden_size, hidden_size, \n",
    "                                       n_qubits = 5, n_layers = 2, degree = 3, ctx = ctx, dropout_rate = dropout_rate) # 45\n",
    "        # output gates\n",
    "        self.output_circuit = QuantumLayer(input_size + hidden_size, hidden_size, \n",
    "                                         n_qubits = 5, n_layers = 2, degree = 3, ctx = ctx, dropout_rate = dropout_rate) # 45\n",
    "        \n",
    "    def forward(self, inputs, init_states = None):\n",
    "        hidden_sequence, (h_t, c_t) = super(QLSTM, self).forward(inputs, init_states)\n",
    "\n",
    "        for t in range(inputs.size()[0]):\n",
    "            x_t = inputs[t, :, :]\n",
    "            v_t = torch.cat((h_t[0], x_t), dim = 1)\n",
    "\n",
    "            # input gates\n",
    "            i_t = torch.sigmoid(self.input_circuit(v_t))\n",
    "            # forget gates\n",
    "            f_t = torch.sigmoid(self.forget_circuit(v_t))\n",
    "            # candidate for cell state update\n",
    "            g_t = torch.tanh(self.candidate_circuit(v_t))\n",
    "            c_t = (f_t * c_t) + (i_t * g_t)\n",
    "\n",
    "            # output gates\n",
    "            o_t = torch.sigmoid(self.output_circuit(v_t))\n",
    "            # update output ht\n",
    "            h_t = o_t * (torch.tanh(c_t))\n",
    "\n",
    "            hidden_sequence.append(h_t)\n",
    "\n",
    "        # reshape hidden_seq p/ retornar\n",
    "        #\n",
    "        # [tensor([[[0.0444, ...]]] => tensor([[[0.0444, ...]]]\n",
    "        # \n",
    "        hidden_sequence = torch.cat(hidden_sequence, dim = 0)\n",
    "\n",
    "        return hidden_sequence, (h_t, c_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6caa3435",
   "metadata": {},
   "source": [
    "### 2.3.2 adjusted classical QLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d152d2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdjustedQLSTM(QLSTMBase):\n",
    "    def __init__(self, input_size, hidden_size, *, ctx, dropout_rate = 0):\n",
    "        super().__init__(input_size, hidden_size, ctx = ctx, dropout_rate = dropout_rate)\n",
    "        \n",
    "        # gates names:  qubits  layers  degree\n",
    "        # input gate:     4       2       3\n",
    "        # forget gate:    5       2       3\n",
    "        # candidate:      4       1       3\n",
    "        # output gate:    3       2       2\n",
    "        \n",
    "        # input gates\n",
    "        self.input_circuit = QuantumLayer(input_size + hidden_size, hidden_size, \n",
    "                                        n_qubits = 4, n_layers = 2, degree = 3, ctx = ctx, dropout_rate = dropout_rate) # 36\n",
    "        # forget gates\n",
    "        self.forget_circuit = QuantumLayer(input_size + hidden_size, hidden_size, \n",
    "                                         n_qubits = 5, n_layers = 2, degree = 3, ctx = ctx, dropout_rate = dropout_rate) # 45\n",
    "        # candidate\n",
    "        self.candidate_circuit = QuantumLayer(input_size + hidden_size, hidden_size, \n",
    "                                       n_qubits = 4, n_layers = 1, degree = 3, ctx = ctx, dropout_rate = dropout_rate) # 24\n",
    "        # output gates\n",
    "        self.output_circuit = QuantumLayer(input_size + hidden_size, hidden_size, \n",
    "                                         n_qubits = 3, n_layers = 2, degree = 2, ctx = ctx, dropout_rate = dropout_rate) # 18\n",
    "        \n",
    "    def forward(self, inputs, init_states = None):\n",
    "        hidden_sequence, (h_t, c_t) = super(AdjustedQLSTM, self).forward(inputs, init_states)\n",
    "\n",
    "        for t in range(inputs.size()[0]):\n",
    "            x_t = inputs[t, :, :]\n",
    "            v_t = torch.cat((h_t[0], x_t), dim = 1)\n",
    "\n",
    "            # input gates\n",
    "            i_t = torch.sigmoid(self.input_circuit(v_t))\n",
    "            # forget gates\n",
    "            f_t = torch.sigmoid(self.forget_circuit(v_t))\n",
    "            # candidate for cell state update\n",
    "            g_t = torch.tanh(self.candidate_circuit(v_t))\n",
    "            c_t = (f_t * c_t) + (i_t * g_t)\n",
    "\n",
    "            # output gates\n",
    "            o_t = torch.sigmoid(self.output_circuit(v_t))\n",
    "            # update output ht\n",
    "            h_t = o_t * (torch.tanh(c_t))\n",
    "\n",
    "            hidden_sequence.append(h_t)\n",
    "\n",
    "        hidden_sequence = torch.cat(hidden_sequence, dim = 0)\n",
    "\n",
    "        return hidden_sequence, (h_t, c_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bda938",
   "metadata": {},
   "source": [
    "### 2.3.3 peephole QLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "66ed785c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PeepholeQLSTM(QLSTMBase):\n",
    "    def __init__(self, input_size, hidden_size, *, ctx, dropout_rate = 0):\n",
    "        super().__init__(input_size, hidden_size, ctx = ctx, dropout_rate = dropout_rate)\n",
    "        \n",
    "        # gates names:  qubits  layers  degree\n",
    "        # input gate:     4       2       3\n",
    "        # forget gate:    5       2       3\n",
    "        # candidate:      4       1       3\n",
    "        # output gate:    3       2       2\n",
    "        \n",
    "        # input gates\n",
    "        self.input_circuit = QuantumLayer(input_size + hidden_size, hidden_size, \n",
    "                                        n_qubits = 4, n_layers = 2, degree = 3, ctx = ctx, dropout_rate = dropout_rate) # 36\n",
    "        # forget gates\n",
    "        self.forget_circuit = QuantumLayer(input_size + hidden_size, hidden_size, \n",
    "                                         n_qubits = 5, n_layers = 2, degree = 3, ctx = ctx, dropout_rate = dropout_rate) # 45\n",
    "        # candidate\n",
    "        self.candidate_circuit = QuantumLayer(input_size + hidden_size, hidden_size, \n",
    "                                       n_qubits = 4, n_layers = 1, degree = 3, ctx = ctx, dropout_rate = dropout_rate) # 24\n",
    "        # output gates\n",
    "        self.output_circuit = QuantumLayer(input_size + hidden_size, hidden_size, \n",
    "                                         n_qubits = 3, n_layers = 2, degree = 2, ctx = ctx, dropout_rate = dropout_rate) # 18\n",
    "        \n",
    "    def forward(self, inputs, init_states = None):\n",
    "        hidden_sequence, (h_t, c_t) = super(PeepholeQLSTM, self).forward(inputs, init_states)\n",
    "\n",
    "        for t in range(inputs.size()[0]):\n",
    "            x_t = inputs[t, :, :]\n",
    "            v_t = torch.cat((c_t[0], x_t), dim = 1)\n",
    "            \n",
    "            # input gates\n",
    "            i_t = torch.sigmoid(self.input_circuit(v_t))\n",
    "            # forget gates\n",
    "            f_t = torch.sigmoid(self.forget_circuit(v_t))\n",
    "            # candidate for cell state update\n",
    "            g_t = torch.tanh(self.candidate_circuit(v_t))\n",
    "            c_t = (f_t * c_t) + (i_t * g_t)\n",
    "            \n",
    "            # output gates\n",
    "            o_t = torch.sigmoid(self.output_circuit(v_t))\n",
    "            # update output ht\n",
    "            h_t = o_t * (torch.tanh(c_t))\n",
    "\n",
    "            hidden_sequence.append(h_t)\n",
    "\n",
    "        hidden_sequence = torch.cat(hidden_sequence, dim = 0)\n",
    "\n",
    "        return hidden_sequence, (h_t, c_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e631aeb",
   "metadata": {},
   "source": [
    "### 2.3.4 Coupled Input and Forget gates QLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f77c5ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFGQLSTM(QLSTMBase):\n",
    "    def __init__(self, input_size, hidden_size, *, ctx, dropout_rate = 0):\n",
    "        super().__init__(input_size, hidden_size, ctx = ctx, dropout_rate = dropout_rate)\n",
    "        \n",
    "        # gates names:  qubits  layers  degree\n",
    "        # coupled IF:     5       2       3\n",
    "        # candidate:      4       2       3\n",
    "        # output gate:    3       2       2\n",
    "        \n",
    "        # Coupled Input and Forget gate\n",
    "        self.coupled_IF_circuit = QuantumLayer(input_size + hidden_size, hidden_size, \n",
    "                                         n_qubits = 5, n_layers = 2, degree = 3, ctx = ctx, dropout_rate = dropout_rate) # 30\n",
    "        # candidate for cell state update\n",
    "        self.candidate_circuit = QuantumLayer(input_size + hidden_size, hidden_size, \n",
    "                                       n_qubits = 4, n_layers = 2, degree = 3, ctx = ctx, dropout_rate = dropout_rate) # 24\n",
    "        # output gates\n",
    "        self.output_circuit = QuantumLayer(input_size + hidden_size, hidden_size, \n",
    "                                         n_qubits = 3, n_layers = 2, degree = 2, ctx = ctx, dropout_rate = dropout_rate) # 12\n",
    "        \n",
    "    def forward(self, inputs, init_states = None):\n",
    "        hidden_sequence, (h_t, c_t) = super(CIFGQLSTM, self).forward(inputs, init_states)\n",
    "\n",
    "        for t in range(inputs.size()[0]):\n",
    "            x_t = inputs[t, :, :]\n",
    "            v_t = torch.cat((h_t[0], x_t), dim = 1)\n",
    "            \n",
    "            # coupled input and forget gate\n",
    "            f_t = torch.sigmoid(self.coupled_IF_circuit(v_t))\n",
    "            # candidate for cell state update\n",
    "            g_t = torch.tanh(self.candidate_circuit(v_t))\n",
    "            c_t = (f_t * c_t) + ((1 - f_t) * g_t)\n",
    "            \n",
    "            # output gates\n",
    "            o_t = torch.sigmoid(self.output_circuit(v_t))\n",
    "            # update output ht\n",
    "            h_t = o_t * (torch.tanh(c_t))\n",
    "\n",
    "            hidden_sequence.append(h_t)\n",
    "\n",
    "        hidden_sequence = torch.cat(hidden_sequence, dim = 0)\n",
    "\n",
    "        return hidden_sequence, (h_t, c_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fded5be6",
   "metadata": {},
   "source": [
    "### 2.3.5 Recurrent Gate Units - QGRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "62d3eb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QGRU(QLSTMBase):\n",
    "    def __init__(self, input_size, hidden_size, *, ctx, dropout_rate = 0):\n",
    "        super().__init__(input_size, hidden_size, ctx = ctx, dropout_rate = dropout_rate)\n",
    "        \n",
    "        # gates names:  qubits  layers  degree\n",
    "        # update gate:     5       1       3\n",
    "        # candidate:       4       1       3\n",
    "        # reset gate:      3       1       2\n",
    "        \n",
    "        # update gates\n",
    "        self.update_circuit = QuantumLayer(input_size + hidden_size, hidden_size, \n",
    "                                         n_qubits = 5, n_layers = 1, degree = 3, ctx = ctx, dropout_rate = dropout_rate) # 45\n",
    "        # candidate for hidden state update\n",
    "        self.candidate_circuit = QuantumLayer(input_size + hidden_size, hidden_size, \n",
    "                                       n_qubits = 4, n_layers = 1, degree = 3, ctx = ctx, dropout_rate = dropout_rate) # 36\n",
    "        # reset gates\n",
    "        self.reset_circuit = QuantumLayer(input_size + hidden_size, hidden_size, \n",
    "                                         n_qubits = 3, n_layers = 1, degree = 2, ctx = ctx, dropout_rate = dropout_rate) # 18\n",
    "        \n",
    "    def forward(self, inputs, init_states = None):\n",
    "        hidden_sequence, (h_t, c_t) = super(QGRU, self).forward(inputs, init_states)\n",
    "\n",
    "        for t in range(inputs.size()[0]):\n",
    "            x_t = inputs[t, :, :]\n",
    "            v_t = torch.cat((h_t[0], x_t), dim = 1)\n",
    "            \n",
    "            # update gates\n",
    "            z_t = torch.sigmoid(self.update_circuit(v_t))\n",
    "            # reset gates\n",
    "            r_t = torch.sigmoid(self.reset_circuit(v_t))\n",
    "        \n",
    "            v_hat_t = torch.cat(((r_t * h_t)[0], x_t), dim = 1)\n",
    "            # candidate for hidden state update\n",
    "            g_t = torch.tanh(self.candidate_circuit(v_hat_t))\n",
    "            h_t = (z_t * g_t) + (1 - z_t) * h_t \n",
    "\n",
    "            hidden_sequence.append(h_t)\n",
    "\n",
    "        hidden_sequence = torch.cat(hidden_sequence, dim = 0)\n",
    "\n",
    "        return hidden_sequence, (h_t, c_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63514807",
   "metadata": {},
   "source": [
    "### - QLSTMs Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5ab09833",
   "metadata": {},
   "outputs": [],
   "source": [
    "QLSTMMap = {\n",
    "    'classical': ('QLSTM', QLSTM),\n",
    "    'adjusted': ('QLSTM(adjusted)', AdjustedQLSTM),\n",
    "    'peephole': ('peephole QLSTM', PeepholeQLSTM),\n",
    "    'CIFG': ('CIFG-QLSTM', CIFGQLSTM),\n",
    "    'GRU': ('QGRU', QGRU)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6497332",
   "metadata": {},
   "source": [
    "## 2.4 Stacked QLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2c6cb0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "class StackedQLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, *, num_layers = 1, ctx = None, mode = 'classical', dropout_rate = 0):\n",
    "        super().__init__()\n",
    "        \n",
    "        label, qlstm = QLSTMMap.get(mode)\n",
    "        self.qlstms = nn.Sequential(OrderedDict([\n",
    "            (f'{label} {i + 1}', qlstm(input_size if i == 0 else hidden_size , hidden_size, ctx = ctx, dropout_rate = dropout_rate)) \n",
    "                for i in range(num_layers)\n",
    "        ]))\n",
    "\n",
    "    def forward(self, inputs, parameters = None):\n",
    "        outputs = None\n",
    "        \n",
    "        for i, qlstm in enumerate(self.qlstms):\n",
    "            if i != 0:\n",
    "                inputs = outputs\n",
    "            \n",
    "            outputs, parameters = qlstm(inputs, parameters)\n",
    "        \n",
    "        return outputs, parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dbbb2f",
   "metadata": {},
   "source": [
    "# 3. Quantum Model and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8313baa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_output, *, num_layers = 1, ctx = None, mode = 'classical', dropout_rate = 0):\n",
    "        super(QModel, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.mode = mode\n",
    "        \n",
    "        self.qlstm = StackedQLSTM(input_size, hidden_size, \n",
    "                                  num_layers = num_layers, ctx = ctx, mode = mode, dropout_rate = dropout_rate)\n",
    "        self.predict = nn.Linear(hidden_size, num_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(0)\n",
    "        \n",
    "        # sequence lenth , batch_size, features length\n",
    "        # \n",
    "        h0 = torch.zeros(1, x.size(1), self.hidden_size)\n",
    "        c0 = torch.zeros(1, x.size(1), self.hidden_size)\n",
    "        \n",
    "        out, _ = self.qlstm(x, (h0, c0))\n",
    "        out = self.predict(out[0])\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf519363",
   "metadata": {},
   "source": [
    "## 3.1 train QModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1abf2ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import RandomSampler\n",
    "\n",
    "def train_model(model, datas, batch_size, *, loss_func, optimizer, epoch = 50, early_stop = False):\n",
    "    losses = []\n",
    "    sampler = RandomSampler(datas, num_samples = batch_size)\n",
    "    \n",
    "    last_loss = 0.0\n",
    "    for step in range(epoch):\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for index in sampler:\n",
    "            batch_x, batch_y = datas[index][0], datas[index][1]\n",
    "            b_x = batch_x.unsqueeze(0)\n",
    "            b_y = batch_y.unsqueeze(0)\n",
    "            \n",
    "            output = model(b_x)\n",
    "\n",
    "            loss = loss_func(output, b_y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        loss = train_loss / batch_size\n",
    "        if early_stop and abs(loss - train_loss) < 1e-4:\n",
    "            break\n",
    "            \n",
    "        last_loss = loss\n",
    "        \n",
    "        print(f'Epoch {step + 1}/{epoch}: Loss: {loss}')\n",
    "        losses.append(loss)\n",
    "    \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cdd42a",
   "metadata": {},
   "source": [
    "## 3.2 Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d05e6234",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "def MAE_naive(actuals, predicteds):\n",
    "    n = len(actuals)\n",
    "    err = 0.0\n",
    "    \n",
    "    for i in range(1, n):\n",
    "        err += np.abs(actuals[i] - actuals[i - 1])\n",
    "    return err / (n - 1)\n",
    "\n",
    "def calculate_accuarcy(model, X_test, y_test, scaler=test_scaler):\n",
    "    n = len(X_test)\n",
    "    \n",
    "    actuals = []\n",
    "    predicteds = []\n",
    "    \n",
    "    for i in range(0, n, predict_size):\n",
    "        actual = scaler.inverse_transform(y_test[i:i+1].data)\n",
    "        actuals.append(np.array(actual[0]))\n",
    "        predicted = scaler.inverse_transform(model(X_test[i:i+1]).data)\n",
    "        predicteds.append(np.array(predicted[0]))\n",
    "    \n",
    "    actuals = np.array(actuals)\n",
    "    predicteds = np.array(predicteds)\n",
    "    \n",
    "    mae = mean_absolute_error(actuals, predicteds)\n",
    "    mase = mae / MAE_naive(actuals.flatten(), predicteds.flatten())\n",
    "    mape = mean_absolute_percentage_error(actuals, predicteds)\n",
    "    mse = mean_squared_error(actuals, predicteds)\n",
    "    rmse = mse ** 0.5\n",
    "    \n",
    "    return np.array([(1 - mase) * 100, rmse, mse, mae, mape])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec9e103",
   "metadata": {},
   "source": [
    "## 3.3 Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "38531f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_size = 4\n",
    "window_size = features_size * 3 # \n",
    "predict_size = features_size # features\n",
    "\n",
    "input_size = window_size\n",
    "num_output = predict_size\n",
    "\n",
    "hidden_size = 32\n",
    "num_layers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ead111aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate:\n",
    "# classical: 0.0035\n",
    "# adjusted: 0.0028\n",
    "# peephole: 0.0027\n",
    "# CIFG: 0.004\n",
    "# GRU: 0.0035"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "98bce888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "count: 1\n",
      "selected hidden_size:  32\n",
      "selected num_layers:  2\n",
      "selected dropout_rate:  0.0001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [51], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(qmodel\u001b[38;5;241m.\u001b[39mparameters(), lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0028\u001b[39m)\n\u001b[0;32m     15\u001b[0m loss_func \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()\n\u001b[1;32m---> 17\u001b[0m losses \u001b[38;5;241m=\u001b[39m train_model(qmodel, train_data, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,          \n\u001b[0;32m     18\u001b[0m                loss_func \u001b[38;5;241m=\u001b[39m loss_func, optimizer \u001b[38;5;241m=\u001b[39m optimizer, epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m     19\u001b[0m dropout_lock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     20\u001b[0m score \u001b[38;5;241m=\u001b[39m calculate_accuarcy(qmodel, X_test, y_test)\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "Cell \u001b[1;32mIn [47], line 16\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, datas, batch_size, loss_func, optimizer, epoch, early_stop)\u001b[0m\n\u001b[0;32m     13\u001b[0m b_x \u001b[38;5;241m=\u001b[39m batch_x\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     14\u001b[0m b_y \u001b[38;5;241m=\u001b[39m batch_y\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_func(output, b_y)\n\u001b[0;32m     19\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn [46], line 21\u001b[0m, in \u001b[0;36mQModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     18\u001b[0m h0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m, x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\n\u001b[0;32m     19\u001b[0m c0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m, x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\n\u001b[1;32m---> 21\u001b[0m out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mh0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc0\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(out[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn [45], line 20\u001b[0m, in \u001b[0;36mStackedQLSTM.forward\u001b[1;34m(self, inputs, parameters)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     18\u001b[0m         inputs \u001b[38;5;241m=\u001b[39m outputs\n\u001b[1;32m---> 20\u001b[0m     outputs, parameters \u001b[38;5;241m=\u001b[39m \u001b[43mqlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs, parameters\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn [40], line 32\u001b[0m, in \u001b[0;36mAdjustedQLSTM.forward\u001b[1;34m(self, inputs, init_states)\u001b[0m\n\u001b[0;32m     29\u001b[0m v_t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((h_t[\u001b[38;5;241m0\u001b[39m], x_t), dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# input gates\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m i_t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_circuit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv_t\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# forget gates\u001b[39;00m\n\u001b[0;32m     34\u001b[0m f_t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforget_circuit(v_t))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn [32], line 5\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m      2\u001b[0m y_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqin(Parameter(inputs))\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m y_t[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqout(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeasure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn [31], line 3\u001b[0m, in \u001b[0;36mmeasure\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmeasure\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m      2\u001b[0m     HamiZ \u001b[38;5;241m=\u001b[39m [ PauliOperator({\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZ\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m}) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqubits)) ]\n\u001b[1;32m----> 3\u001b[0m     res \u001b[38;5;241m=\u001b[39m [ \u001b[38;5;28meval\u001b[39m(qop(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcircuit, Hami, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmachine, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqubits))[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m Hami \u001b[38;5;129;01min\u001b[39;00m HamiZ ]\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Parameter(Tensor(res[:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_qubits]))\n",
      "Cell \u001b[1;32mIn [31], line 3\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmeasure\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m      2\u001b[0m     HamiZ \u001b[38;5;241m=\u001b[39m [ PauliOperator({\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZ\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m}) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqubits)) ]\n\u001b[1;32m----> 3\u001b[0m     res \u001b[38;5;241m=\u001b[39m [ \u001b[38;5;28meval\u001b[39m(qop(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcircuit\u001b[49m, Hami, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmachine, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqubits))[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m Hami \u001b[38;5;129;01min\u001b[39;00m HamiZ ]\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Parameter(Tensor(res[:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_qubits]))\n",
      "Cell \u001b[1;32mIn [34], line 59\u001b[0m, in \u001b[0;36mQuantumLayer.circuit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     56\u001b[0m vqc\u001b[38;5;241m.\u001b[39minsert(cz(q[n \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m], q[\u001b[38;5;241m0\u001b[39m]))\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n):\n\u001b[1;32m---> 59\u001b[0m     vqc\u001b[38;5;241m.\u001b[39minsert( u[degree](q[i], \u001b[38;5;241m*\u001b[39m[ var(p[layer \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m][d][i]) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(degree) ]) )\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dropout_lock \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand() \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout_rate:\n\u001b[0;32m     61\u001b[0m         vqc\u001b[38;5;241m.\u001b[39minsert( YGate(q[i]) )\n",
      "Cell \u001b[1;32mIn [34], line 59\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     56\u001b[0m vqc\u001b[38;5;241m.\u001b[39minsert(cz(q[n \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m], q[\u001b[38;5;241m0\u001b[39m]))\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n):\n\u001b[1;32m---> 59\u001b[0m     vqc\u001b[38;5;241m.\u001b[39minsert( u[degree](q[i], \u001b[38;5;241m*\u001b[39m[ \u001b[43mvar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(degree) ]) )\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dropout_lock \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand() \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout_rate:\n\u001b[0;32m     61\u001b[0m         vqc\u001b[38;5;241m.\u001b[39minsert( YGate(q[i]) )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "best_model = None\n",
    "count = 1\n",
    "for dropout_rate in [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.001, 0.002, 0.003, 0.005, 0.01, 0.02, 0.03, 0.05]:\n",
    "    print('-' * 20)\n",
    "    print('count:', count)\n",
    "    print('selected hidden_size: ', hidden_size)\n",
    "    print('selected num_layers: ', num_layers)\n",
    "    print('selected dropout_rate: ', dropout_rate)\n",
    "    count += 1\n",
    "    dropout_lock = True\n",
    "    qmodel = QModel(input_size, hidden_size, num_output, \n",
    "        num_layers = num_layers, ctx = ctx, mode='adjusted', dropout_rate=dropout_rate)\n",
    "    optimizer = torch.optim.AdamW(qmodel.parameters(), lr = 0.0028)\n",
    "    loss_func = nn.MSELoss()\n",
    "\n",
    "    losses = train_model(qmodel, train_data, batch_size=20,          \n",
    "                   loss_func = loss_func, optimizer = optimizer, epoch = 100)\n",
    "    dropout_lock = False\n",
    "    score = calculate_accuarcy(qmodel, X_test, y_test).numpy()\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_model = qmodel\n",
    "        best_parameters = {\n",
    "            'hidden_size': hidden_size,\n",
    "            'num_layers': num_layers,\n",
    "            'dropout_rate': dropout_rate\n",
    "        }\n",
    "    print()\n",
    "\n",
    "print(\"Best score: \", best_score)\n",
    "print(\"Best parameters: \", best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "060fb4c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_size': 32, 'num_layers': 2, 'dropout_rate': 0.0003}"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "61750811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: Loss: 1.0250376045703888\n",
      "Epoch 2/100: Loss: 0.966230520606041\n",
      "Epoch 3/100: Loss: 0.9234540462493896\n",
      "Epoch 4/100: Loss: 0.891375744342804\n",
      "Epoch 5/100: Loss: 0.8499773651361465\n",
      "Epoch 6/100: Loss: 0.7022163972258568\n",
      "Epoch 7/100: Loss: 0.5065360888838768\n",
      "Epoch 8/100: Loss: 0.36441466957330704\n",
      "Epoch 9/100: Loss: 0.3710805647075176\n",
      "Epoch 10/100: Loss: 0.22233361890539527\n",
      "Epoch 11/100: Loss: 0.21845643692649902\n",
      "Epoch 12/100: Loss: 0.20680683394894003\n",
      "Epoch 13/100: Loss: 0.13021797409746796\n",
      "Epoch 14/100: Loss: 0.05119970450177789\n",
      "Epoch 15/100: Loss: 0.04130337482711184\n",
      "Epoch 16/100: Loss: 0.033832282957155256\n",
      "Epoch 17/100: Loss: 0.014098227513022721\n",
      "Epoch 18/100: Loss: 0.009802090951416176\n",
      "Epoch 19/100: Loss: 0.007067456560616847\n",
      "Epoch 20/100: Loss: 0.001178227088530548\n",
      "Epoch 21/100: Loss: 0.0007943715478177183\n",
      "Epoch 22/100: Loss: 0.0009536933335766662\n",
      "Epoch 23/100: Loss: 0.0005138958415045636\n",
      "Epoch 24/100: Loss: 0.0008184995189367328\n",
      "Epoch 25/100: Loss: 0.0005878360887436429\n",
      "Epoch 26/100: Loss: 0.0014852610664092935\n",
      "Epoch 27/100: Loss: 0.00046645131496916294\n",
      "Epoch 28/100: Loss: 0.0007765838079649256\n",
      "Epoch 29/100: Loss: 0.00048720587401476225\n",
      "Epoch 30/100: Loss: 0.0004726416798803257\n",
      "Epoch 31/100: Loss: 0.00045208964727407876\n",
      "Epoch 32/100: Loss: 0.00047877009674266444\n",
      "Epoch 33/100: Loss: 0.0007116581068657979\n",
      "Epoch 34/100: Loss: 0.0005429407206975157\n",
      "Epoch 35/100: Loss: 0.0008374186501896475\n",
      "Epoch 36/100: Loss: 0.0006964046351640718\n",
      "Epoch 37/100: Loss: 0.000504148280742811\n",
      "Epoch 38/100: Loss: 0.0004327056110923877\n",
      "Epoch 39/100: Loss: 0.0006428173399399383\n",
      "Epoch 40/100: Loss: 0.000896544350325712\n",
      "Epoch 41/100: Loss: 0.0007085106445742894\n",
      "Epoch 42/100: Loss: 0.0005417431020759977\n",
      "Epoch 43/100: Loss: 0.0005134108270794969\n",
      "Epoch 44/100: Loss: 0.0005527125194930704\n",
      "Epoch 45/100: Loss: 0.0006178001515763753\n",
      "Epoch 46/100: Loss: 0.0006556654207088286\n",
      "Epoch 47/100: Loss: 0.0006519803459013928\n",
      "Epoch 48/100: Loss: 0.0006453781221352983\n",
      "Epoch 49/100: Loss: 0.0006338660732581047\n",
      "Epoch 50/100: Loss: 0.0006819326721597463\n",
      "Epoch 51/100: Loss: 0.000826022399814974\n",
      "Epoch 52/100: Loss: 0.0005989361141473637\n",
      "Epoch 53/100: Loss: 0.003439040515513625\n",
      "Epoch 54/100: Loss: 0.0012515043308667373\n",
      "Epoch 55/100: Loss: 0.0005304173078911845\n",
      "Epoch 56/100: Loss: 0.00042238522673869737\n",
      "Epoch 57/100: Loss: 0.0009330610062079359\n",
      "Epoch 58/100: Loss: 0.000733704711910832\n",
      "Epoch 59/100: Loss: 0.000704945795587264\n",
      "Epoch 60/100: Loss: 0.0006469348312748479\n",
      "Epoch 61/100: Loss: 0.0007609526051965077\n",
      "Epoch 62/100: Loss: 0.000730459560509189\n",
      "Epoch 63/100: Loss: 0.0006895210473885527\n",
      "Epoch 64/100: Loss: 0.00043566324948187687\n",
      "Epoch 65/100: Loss: 0.05156496064882958\n",
      "Epoch 66/100: Loss: 0.004615855214069597\n",
      "Epoch 67/100: Loss: 0.0013212966092396527\n",
      "Epoch 68/100: Loss: 0.0007661322149942861\n",
      "Epoch 69/100: Loss: 0.0005699761877622223\n",
      "Epoch 70/100: Loss: 0.0004739880943816388\n",
      "Epoch 71/100: Loss: 0.0006014620078531152\n",
      "Epoch 72/100: Loss: 0.00040963460560305975\n",
      "Epoch 73/100: Loss: 0.0005033261819335167\n",
      "Epoch 74/100: Loss: 0.0008775340633292217\n",
      "Epoch 75/100: Loss: 0.00060488796948448\n",
      "Epoch 76/100: Loss: 0.00039284669310291065\n",
      "Epoch 77/100: Loss: 0.00046907370542612623\n",
      "Epoch 78/100: Loss: 0.0005893998313695192\n",
      "Epoch 79/100: Loss: 0.0004295957708563947\n",
      "Epoch 80/100: Loss: 0.0004608498034940567\n",
      "Epoch 81/100: Loss: 0.0006780261337553384\n",
      "Epoch 82/100: Loss: 0.0004712208014097996\n",
      "Epoch 83/100: Loss: 0.006461892112565692\n",
      "Epoch 84/100: Loss: 0.0017684436505078338\n",
      "Epoch 85/100: Loss: 0.0009634643487515859\n",
      "Epoch 86/100: Loss: 0.0007679469577851705\n",
      "Epoch 87/100: Loss: 0.0007678584570385283\n",
      "Epoch 88/100: Loss: 0.0007531715181357867\n",
      "Epoch 89/100: Loss: 0.0011992947487669881\n",
      "Epoch 90/100: Loss: 0.0010159868870687205\n",
      "Epoch 91/100: Loss: 0.0005017490100726718\n",
      "Epoch 92/100: Loss: 0.0007329388959078642\n",
      "Epoch 93/100: Loss: 0.0004391077302443591\n",
      "Epoch 94/100: Loss: 0.0006243032974452944\n",
      "Epoch 95/100: Loss: 0.16348197186234756\n",
      "Epoch 96/100: Loss: 0.03480559491435997\n",
      "Epoch 97/100: Loss: 0.011079037169110961\n",
      "Epoch 98/100: Loss: 0.00196072101171012\n",
      "Epoch 99/100: Loss: 0.0006149388589619775\n",
      "Epoch 100/100: Loss: 0.0007037295701593394\n",
      "time costs: 1292.5800378322601\n",
      "[ 98.40669513  10.72945562 115.12121791   8.25879252   0.27462443]\n",
      "Epoch 1/100: Loss: 0.9768367946147919\n",
      "Epoch 2/100: Loss: 0.9060744225978852\n",
      "Epoch 3/100: Loss: 0.831278583407402\n",
      "Epoch 4/100: Loss: 0.7890323266386986\n",
      "Epoch 5/100: Loss: 0.7292754903435708\n",
      "Epoch 6/100: Loss: 0.5835944771766662\n",
      "Epoch 7/100: Loss: 0.518439307808876\n",
      "Epoch 8/100: Loss: 0.39615157842636106\n",
      "Epoch 9/100: Loss: 0.2797414198517799\n",
      "Epoch 10/100: Loss: 0.19181786179542543\n",
      "Epoch 11/100: Loss: 0.15747967660136056\n",
      "Epoch 12/100: Loss: 0.09649747613439104\n",
      "Epoch 13/100: Loss: 0.06301753151929006\n",
      "Epoch 14/100: Loss: 0.02264430111972615\n",
      "Epoch 15/100: Loss: 0.011144290305674076\n",
      "Epoch 16/100: Loss: 0.004440155075280927\n",
      "Epoch 17/100: Loss: 0.0019161949090630514\n",
      "Epoch 18/100: Loss: 0.0005488916918693576\n",
      "Epoch 19/100: Loss: 0.005698838500347847\n",
      "Epoch 20/100: Loss: 0.001343652728246525\n",
      "Epoch 21/100: Loss: 0.0005138760261615971\n",
      "Epoch 22/100: Loss: 0.000403750439909345\n",
      "Epoch 23/100: Loss: 0.00030798431362200063\n",
      "Epoch 24/100: Loss: 0.0006885597285418044\n",
      "Epoch 25/100: Loss: 0.0005194934710743837\n",
      "Epoch 26/100: Loss: 0.0004107016428861243\n",
      "Epoch 27/100: Loss: 0.0003421188795073249\n",
      "Epoch 28/100: Loss: 0.00046412628707912516\n",
      "Epoch 29/100: Loss: 0.0004046585567266447\n",
      "Epoch 30/100: Loss: 0.0005249817635558429\n",
      "Epoch 31/100: Loss: 0.0007942026299133431\n",
      "Epoch 32/100: Loss: 0.00045191721847004374\n",
      "Epoch 33/100: Loss: 0.00042325825188527233\n",
      "Epoch 34/100: Loss: 0.0004791749433934456\n",
      "Epoch 35/100: Loss: 0.0005710628011001972\n",
      "Epoch 36/100: Loss: 0.00039958991465027793\n",
      "Epoch 37/100: Loss: 0.0332849893522507\n",
      "Epoch 38/100: Loss: 0.016529540499323047\n",
      "Epoch 39/100: Loss: 0.0020674459479778306\n",
      "Epoch 40/100: Loss: 0.0007354085395490983\n",
      "Epoch 41/100: Loss: 0.0005381096907512983\n",
      "Epoch 42/100: Loss: 0.0003901855368894758\n",
      "Epoch 43/100: Loss: 0.0005551141446630936\n",
      "Epoch 44/100: Loss: 0.0004332177461037645\n",
      "Epoch 45/100: Loss: 0.00038756160834054756\n",
      "Epoch 46/100: Loss: 0.000507575822120998\n",
      "Epoch 47/100: Loss: 0.0006329267474939115\n",
      "Epoch 48/100: Loss: 0.0016955543112999294\n",
      "Epoch 49/100: Loss: 0.001028331380803138\n",
      "Epoch 50/100: Loss: 0.0006848101702416898\n",
      "Epoch 51/100: Loss: 0.0004501302433709498\n",
      "Epoch 52/100: Loss: 0.0007915910351584899\n",
      "Epoch 53/100: Loss: 0.0004831017522519687\n",
      "Epoch 54/100: Loss: 0.0005747148108639522\n",
      "Epoch 55/100: Loss: 0.0004054825538332807\n",
      "Epoch 56/100: Loss: 0.0005194638677494367\n",
      "Epoch 57/100: Loss: 0.002092192749114474\n",
      "Epoch 58/100: Loss: 0.002220629843213828\n",
      "Epoch 59/100: Loss: 0.0007246510049299104\n",
      "Epoch 60/100: Loss: 0.0004434526505065151\n",
      "Epoch 61/100: Loss: 0.0010804986559378449\n",
      "Epoch 62/100: Loss: 0.0006583515263628214\n",
      "Epoch 63/100: Loss: 0.0801004148103857\n",
      "Epoch 64/100: Loss: 0.008387407779810018\n",
      "Epoch 65/100: Loss: 0.0011177610795130022\n",
      "Epoch 66/100: Loss: 0.0007205026238807477\n",
      "Epoch 67/100: Loss: 0.0010298300559952623\n",
      "Epoch 68/100: Loss: 0.0006105312939325813\n",
      "Epoch 69/100: Loss: 0.0006384722423717903\n",
      "Epoch 70/100: Loss: 0.0005536392563953996\n",
      "Epoch 71/100: Loss: 0.0004360954713774845\n",
      "Epoch 72/100: Loss: 0.000765602737737936\n",
      "Epoch 73/100: Loss: 0.0005353204120183364\n",
      "Epoch 74/100: Loss: 0.0004193855787889333\n",
      "Epoch 75/100: Loss: 0.0007907644219812937\n",
      "Epoch 76/100: Loss: 0.0006036785649484955\n",
      "Epoch 77/100: Loss: 0.00046257933645392767\n",
      "Epoch 78/100: Loss: 0.0033862423812934138\n",
      "Epoch 79/100: Loss: 0.0006154622631584061\n",
      "Epoch 80/100: Loss: 0.00046481789540848696\n",
      "Epoch 81/100: Loss: 0.0005800345401439699\n",
      "Epoch 82/100: Loss: 0.0005698065144315479\n",
      "Epoch 83/100: Loss: 0.0004987218058886356\n",
      "Epoch 84/100: Loss: 0.00057663229940772\n",
      "Epoch 85/100: Loss: 0.0010292835006112\n",
      "Epoch 86/100: Loss: 0.00044633926877395423\n",
      "Epoch 87/100: Loss: 0.0005320587804817478\n",
      "Epoch 88/100: Loss: 0.0004948433594108792\n",
      "Epoch 89/100: Loss: 0.025136859102349262\n",
      "Epoch 90/100: Loss: 0.005038060816877988\n",
      "Epoch 91/100: Loss: 0.0016494822295499035\n",
      "Epoch 92/100: Loss: 0.0006433303606172558\n",
      "Epoch 93/100: Loss: 0.0005402631624747301\n",
      "Epoch 94/100: Loss: 0.0005250151687505422\n",
      "Epoch 95/100: Loss: 0.0026454602579178755\n",
      "Epoch 96/100: Loss: 0.0016402306297095492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100: Loss: 0.0006552396880579181\n",
      "Epoch 98/100: Loss: 0.011519268235497293\n",
      "Epoch 99/100: Loss: 0.005497352722159121\n",
      "Epoch 100/100: Loss: 0.0009830414201132953\n",
      "time costs: 1154.062637090683\n",
      "[ 98.11320408  12.03478578 144.83606881   9.78008434   0.45018527]\n",
      "Epoch 1/100: Loss: 0.9711028844118118\n",
      "Epoch 2/100: Loss: 0.9487359642982482\n",
      "Epoch 3/100: Loss: 0.9125742048025132\n",
      "Epoch 4/100: Loss: 0.7973777979612351\n",
      "Epoch 5/100: Loss: 0.7623393654823303\n",
      "Epoch 6/100: Loss: 0.6000484645366668\n",
      "Epoch 7/100: Loss: 0.4875093400478363\n",
      "Epoch 8/100: Loss: 0.36871301382780075\n",
      "Epoch 9/100: Loss: 0.2830826908349991\n",
      "Epoch 10/100: Loss: 0.24485187605023384\n",
      "Epoch 11/100: Loss: 0.273492893204093\n",
      "Epoch 12/100: Loss: 0.15898411385715008\n",
      "Epoch 13/100: Loss: 0.1658242790028453\n",
      "Epoch 14/100: Loss: 0.09101335029117763\n",
      "Epoch 15/100: Loss: 0.06028156593674794\n",
      "Epoch 16/100: Loss: 0.05054705179063603\n",
      "Epoch 17/100: Loss: 0.03472886897798162\n",
      "Epoch 18/100: Loss: 0.026957253785803915\n",
      "Epoch 19/100: Loss: 0.017955629658536053\n",
      "Epoch 20/100: Loss: 0.006602997335721739\n",
      "Epoch 21/100: Loss: 0.0037960558227496223\n",
      "Epoch 22/100: Loss: 0.0014786293904762715\n",
      "Epoch 23/100: Loss: 0.0004975262503648991\n",
      "Epoch 24/100: Loss: 0.009571442499145632\n",
      "Epoch 25/100: Loss: 0.000716123904021515\n",
      "Epoch 26/100: Loss: 0.0005463209730805829\n",
      "Epoch 27/100: Loss: 0.0003765414563531522\n",
      "Epoch 28/100: Loss: 0.00031773747346051093\n",
      "Epoch 29/100: Loss: 0.00047428693806068624\n",
      "Epoch 30/100: Loss: 0.000348685485914757\n",
      "Epoch 31/100: Loss: 0.0002850049419066636\n",
      "Epoch 32/100: Loss: 0.0005603115216217703\n",
      "Epoch 33/100: Loss: 0.00034111441891582217\n",
      "Epoch 34/100: Loss: 0.00041111183109023843\n",
      "Epoch 35/100: Loss: 0.0004895506157481577\n",
      "Epoch 36/100: Loss: 0.0004541837537544779\n",
      "Epoch 37/100: Loss: 0.00035813029185192133\n",
      "Epoch 38/100: Loss: 0.00033564264012966307\n",
      "Epoch 39/100: Loss: 0.0002383605682553025\n",
      "Epoch 40/100: Loss: 0.0013285034276123043\n",
      "Epoch 41/100: Loss: 0.0021844040162250166\n",
      "Epoch 42/100: Loss: 0.0004961968006682582\n",
      "Epoch 43/100: Loss: 0.001324167276470689\n",
      "Epoch 44/100: Loss: 0.00029695051489397883\n",
      "Epoch 45/100: Loss: 0.08718776931009416\n",
      "Epoch 46/100: Loss: 0.014531975685531506\n",
      "Epoch 47/100: Loss: 0.001408896908560564\n",
      "Epoch 48/100: Loss: 0.001221005829575006\n",
      "Epoch 49/100: Loss: 0.0018871406955440762\n",
      "Epoch 50/100: Loss: 0.0005659876042045653\n",
      "Epoch 51/100: Loss: 0.0004793817253812449\n",
      "Epoch 52/100: Loss: 0.00036498261601991544\n",
      "Epoch 53/100: Loss: 0.00047042595761013215\n",
      "Epoch 54/100: Loss: 0.0003340580191434128\n",
      "Epoch 55/100: Loss: 0.0006152705513159162\n",
      "Epoch 56/100: Loss: 0.0005691598578778212\n",
      "Epoch 57/100: Loss: 0.000501680876914179\n",
      "Epoch 58/100: Loss: 0.00046980782663013087\n",
      "Epoch 59/100: Loss: 0.000437642604993016\n",
      "Epoch 60/100: Loss: 0.0002654076444741804\n",
      "Epoch 61/100: Loss: 0.0003416892864919419\n",
      "Epoch 62/100: Loss: 0.00043020056382374604\n",
      "Epoch 63/100: Loss: 0.0005699719986296259\n",
      "Epoch 64/100: Loss: 0.0003452664803262451\n",
      "Epoch 65/100: Loss: 0.0004160302109085023\n",
      "Epoch 66/100: Loss: 0.000326281698562525\n",
      "Epoch 67/100: Loss: 0.0006467586112194112\n",
      "Epoch 68/100: Loss: 0.00162568445521174\n",
      "Epoch 69/100: Loss: 0.0004050569885293953\n",
      "Epoch 70/100: Loss: 0.0010852718693058704\n",
      "Epoch 71/100: Loss: 0.000489587348056375\n",
      "Epoch 72/100: Loss: 0.00040917076403275133\n",
      "Epoch 73/100: Loss: 0.0004690257912443485\n",
      "Epoch 74/100: Loss: 0.00040360865295951953\n",
      "Epoch 75/100: Loss: 0.000335468629054958\n",
      "Epoch 76/100: Loss: 0.0003407214521757851\n",
      "Epoch 77/100: Loss: 0.0002442429345137498\n",
      "Epoch 78/100: Loss: 0.0004118081449632882\n",
      "Epoch 79/100: Loss: 0.00040720167926338035\n",
      "Epoch 80/100: Loss: 0.0003585511361961835\n",
      "Epoch 81/100: Loss: 0.0003368762960235472\n",
      "Epoch 82/100: Loss: 0.0003566966709058761\n",
      "Epoch 83/100: Loss: 0.0003953175400056352\n",
      "Epoch 84/100: Loss: 0.00047569462440151257\n",
      "Epoch 85/100: Loss: 0.0004869571479503065\n",
      "Epoch 86/100: Loss: 0.004655281551640656\n",
      "Epoch 87/100: Loss: 0.0023459556761508795\n",
      "Epoch 88/100: Loss: 0.0008187425843061647\n",
      "Epoch 89/100: Loss: 0.0008755991439102218\n",
      "Epoch 90/100: Loss: 0.001845282309477625\n",
      "Epoch 91/100: Loss: 0.0011599421615756\n",
      "Epoch 92/100: Loss: 0.0005327644272256294\n",
      "Epoch 93/100: Loss: 0.0007183486048234044\n",
      "Epoch 94/100: Loss: 0.0010092764950059064\n",
      "Epoch 95/100: Loss: 0.000524330310872756\n",
      "Epoch 96/100: Loss: 0.00036177974579914006\n",
      "Epoch 97/100: Loss: 0.0005862025242095115\n",
      "Epoch 98/100: Loss: 0.0004885607399046421\n",
      "Epoch 99/100: Loss: 0.0004148236175751663\n",
      "Epoch 100/100: Loss: 0.0004603083250913187\n",
      "time costs: 802.2901048660278\n",
      "[98.74597519  8.33031408 69.39413259  6.50015631  0.28673002]\n",
      "Epoch 1/100: Loss: 1.0058838874101639\n",
      "Epoch 2/100: Loss: 0.976407727599144\n",
      "Epoch 3/100: Loss: 0.9980064183473587\n",
      "Epoch 4/100: Loss: 0.9247166991233826\n",
      "Epoch 5/100: Loss: 0.8756233036518097\n",
      "Epoch 6/100: Loss: 0.8863418996334076\n",
      "Epoch 7/100: Loss: 0.822034877538681\n",
      "Epoch 8/100: Loss: 0.734300720691681\n",
      "Epoch 9/100: Loss: 0.6460050761699676\n",
      "Epoch 10/100: Loss: 0.5290560558438301\n",
      "Epoch 11/100: Loss: 0.39489776119589803\n",
      "Epoch 12/100: Loss: 0.395400819927454\n",
      "Epoch 13/100: Loss: 0.36376139968633653\n",
      "Epoch 14/100: Loss: 0.3038738168776035\n",
      "Epoch 15/100: Loss: 0.21589366272091864\n",
      "Epoch 16/100: Loss: 0.2945081377401948\n",
      "Epoch 17/100: Loss: 0.19900269173085688\n",
      "Epoch 18/100: Loss: 0.245207323692739\n",
      "Epoch 19/100: Loss: 0.23585659083910288\n",
      "Epoch 20/100: Loss: 0.12863024354446678\n",
      "Epoch 21/100: Loss: 0.1316600747872144\n",
      "Epoch 22/100: Loss: 0.0933302219316829\n",
      "Epoch 23/100: Loss: 0.08003274877555669\n",
      "Epoch 24/100: Loss: 0.07773184810648673\n",
      "Epoch 25/100: Loss: 0.04222985961241647\n",
      "Epoch 26/100: Loss: 0.027267151948763058\n",
      "Epoch 27/100: Loss: 0.021848878666060046\n",
      "Epoch 28/100: Loss: 0.009330434375442564\n",
      "Epoch 29/100: Loss: 0.007954271978815087\n",
      "Epoch 30/100: Loss: 0.001775541785900714\n",
      "Epoch 31/100: Loss: 0.0006971920755859173\n",
      "Epoch 32/100: Loss: 0.0012815608029995928\n",
      "Epoch 33/100: Loss: 0.0005912123489906663\n",
      "Epoch 34/100: Loss: 0.0007771123277052538\n",
      "Epoch 35/100: Loss: 0.0004297174886232824\n",
      "Epoch 36/100: Loss: 0.0003420561602979433\n",
      "Epoch 37/100: Loss: 0.0004093528128578328\n",
      "Epoch 38/100: Loss: 0.000648926587200549\n",
      "Epoch 39/100: Loss: 0.0004944037409586599\n",
      "Epoch 40/100: Loss: 0.0003866792589178658\n",
      "Epoch 41/100: Loss: 0.0003435300730416202\n",
      "Epoch 42/100: Loss: 0.0006181304253914278\n",
      "Epoch 43/100: Loss: 0.00039778173895683723\n",
      "Epoch 44/100: Loss: 0.0003611776050092885\n",
      "Epoch 45/100: Loss: 0.00037477021796803454\n",
      "Epoch 46/100: Loss: 0.0004442558909431682\n",
      "Epoch 47/100: Loss: 0.0004976477688614977\n",
      "Epoch 48/100: Loss: 0.0004387179973491584\n",
      "Epoch 49/100: Loss: 0.0003014993099441199\n",
      "Epoch 50/100: Loss: 0.0003179200752128963\n",
      "Epoch 51/100: Loss: 0.0003762815325899282\n",
      "Epoch 52/100: Loss: 0.0005572779944486683\n",
      "Epoch 53/100: Loss: 0.0003735097631761164\n",
      "Epoch 54/100: Loss: 0.0004179382858637837\n",
      "Epoch 55/100: Loss: 0.0004979947665560758\n",
      "Epoch 56/100: Loss: 0.0006912016458954894\n",
      "Epoch 57/100: Loss: 0.0004535354833933525\n",
      "Epoch 58/100: Loss: 0.00043812843705381965\n",
      "Epoch 59/100: Loss: 0.0004957505436323118\n",
      "Epoch 60/100: Loss: 0.0005270625657431083\n",
      "Epoch 61/100: Loss: 0.0005894209454709199\n",
      "Epoch 62/100: Loss: 0.0004731994757548819\n",
      "Epoch 63/100: Loss: 0.0005385043914429843\n",
      "Epoch 64/100: Loss: 0.0005262480899546063\n",
      "Epoch 65/100: Loss: 0.0004964360402027523\n",
      "Epoch 66/100: Loss: 0.05721705555988592\n",
      "Epoch 67/100: Loss: 0.0031459352387173565\n",
      "Epoch 68/100: Loss: 0.0020045776378537993\n",
      "Epoch 69/100: Loss: 0.0010891744001128244\n",
      "Epoch 70/100: Loss: 0.0007733170506980969\n",
      "Epoch 71/100: Loss: 0.0004693806752584351\n",
      "Epoch 72/100: Loss: 0.0005851408235685085\n",
      "Epoch 73/100: Loss: 0.0004541552443697583\n",
      "Epoch 74/100: Loss: 0.0004934907232382102\n",
      "Epoch 75/100: Loss: 0.0008492020704579772\n",
      "Epoch 76/100: Loss: 0.001032553669756453\n",
      "Epoch 77/100: Loss: 0.0006872118603496347\n",
      "Epoch 78/100: Loss: 0.0007848414039472118\n",
      "Epoch 79/100: Loss: 0.00037778430978505637\n",
      "Epoch 80/100: Loss: 0.00043760001863120125\n",
      "Epoch 81/100: Loss: 0.00048461367150594016\n",
      "Epoch 82/100: Loss: 0.004689737393346149\n",
      "Epoch 83/100: Loss: 0.0010704357886424988\n",
      "Epoch 84/100: Loss: 0.0010397464542620583\n",
      "Epoch 85/100: Loss: 0.0007025080547464313\n",
      "Epoch 86/100: Loss: 0.0005740654036344494\n",
      "Epoch 87/100: Loss: 0.0004671989455346193\n",
      "Epoch 88/100: Loss: 0.0005846327991093858\n",
      "Epoch 89/100: Loss: 0.0006952259716854314\n",
      "Epoch 90/100: Loss: 0.00047272554947994647\n",
      "Epoch 91/100: Loss: 0.0006905910457135178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/100: Loss: 0.0005188200413613231\n",
      "Epoch 93/100: Loss: 0.0056266953710292\n",
      "Epoch 94/100: Loss: 0.0061604001457453705\n",
      "Epoch 95/100: Loss: 0.005110102905382519\n",
      "Epoch 96/100: Loss: 0.002119820321968291\n",
      "Epoch 97/100: Loss: 0.0004323937564549851\n",
      "Epoch 98/100: Loss: 0.0003797976135501813\n",
      "Epoch 99/100: Loss: 0.0005507735118953861\n",
      "Epoch 100/100: Loss: 0.0029717242716287727\n",
      "time costs: 882.0260615348816\n",
      "[ 96.79227582  19.60105163 384.20122518  16.62703036   0.65981665]\n",
      "Epoch 1/100: Loss: 1.0253354787826539\n",
      "Epoch 2/100: Loss: 0.9344563066959382\n",
      "Epoch 3/100: Loss: 0.9064482033252717\n",
      "Epoch 4/100: Loss: 0.9133419781923294\n",
      "Epoch 5/100: Loss: 0.8163764357566834\n",
      "Epoch 6/100: Loss: 0.7314043521881104\n",
      "Epoch 7/100: Loss: 0.6218512117862701\n",
      "Epoch 8/100: Loss: 0.5101951912045479\n",
      "Epoch 9/100: Loss: 0.4728072129189968\n",
      "Epoch 10/100: Loss: 0.404714135825634\n",
      "Epoch 11/100: Loss: 0.34769848026335237\n",
      "Epoch 12/100: Loss: 0.3425219919532537\n",
      "Epoch 13/100: Loss: 0.3206147100776434\n",
      "Epoch 14/100: Loss: 0.40383513998240234\n",
      "Epoch 15/100: Loss: 0.2784464318305254\n",
      "Epoch 16/100: Loss: 0.21312147369608284\n",
      "Epoch 17/100: Loss: 0.23763981489464642\n",
      "Epoch 18/100: Loss: 0.19066244323039427\n",
      "Epoch 19/100: Loss: 0.16577206255169585\n",
      "Epoch 20/100: Loss: 0.10422623370541259\n",
      "Epoch 21/100: Loss: 0.05968769452301785\n",
      "Epoch 22/100: Loss: 0.06520777700643521\n",
      "Epoch 23/100: Loss: 0.037724049176904376\n",
      "Epoch 24/100: Loss: 0.016701755307076384\n",
      "Epoch 25/100: Loss: 0.010604231787374374\n",
      "Epoch 26/100: Loss: 0.004026853992399992\n",
      "Epoch 27/100: Loss: 0.0016924474701227154\n",
      "Epoch 28/100: Loss: 0.001311614467704203\n",
      "Epoch 29/100: Loss: 0.0006539598656672751\n",
      "Epoch 30/100: Loss: 0.000348232591386477\n",
      "Epoch 31/100: Loss: 0.06313357843391713\n",
      "Epoch 32/100: Loss: 0.0027336729996022767\n",
      "Epoch 33/100: Loss: 0.05005419167864602\n",
      "Epoch 34/100: Loss: 0.003158675498343655\n",
      "Epoch 35/100: Loss: 0.0020452125776500908\n",
      "Epoch 36/100: Loss: 0.0010039735989266774\n",
      "Epoch 37/100: Loss: 0.0021788183826174645\n",
      "Epoch 38/100: Loss: 0.0008151745758368633\n",
      "Epoch 39/100: Loss: 0.0006462662451667712\n",
      "Epoch 40/100: Loss: 0.0005659364971506875\n",
      "Epoch 41/100: Loss: 0.0009567897584929596\n",
      "Epoch 42/100: Loss: 0.0024675305059645323\n",
      "Epoch 43/100: Loss: 0.0007000834331847728\n",
      "Epoch 44/100: Loss: 0.0015448922029463574\n",
      "Epoch 45/100: Loss: 0.03198641953567858\n",
      "Epoch 46/100: Loss: 0.003198966322815977\n",
      "Epoch 47/100: Loss: 0.0009205312820995459\n",
      "Epoch 48/100: Loss: 0.026365130076101195\n",
      "Epoch 49/100: Loss: 0.003806460424675606\n",
      "Epoch 50/100: Loss: 0.0013865555003576447\n",
      "Epoch 51/100: Loss: 0.000808128428980126\n",
      "Epoch 52/100: Loss: 0.0003935133500817756\n",
      "Epoch 53/100: Loss: 0.0005130441650635475\n",
      "Epoch 54/100: Loss: 0.0005756597458457691\n",
      "Epoch 55/100: Loss: 0.0005891509612411028\n",
      "Epoch 56/100: Loss: 0.0007770679476379883\n",
      "Epoch 57/100: Loss: 0.000428678231764934\n",
      "Epoch 58/100: Loss: 0.00038532511971425267\n",
      "Epoch 59/100: Loss: 0.0007411395223243744\n",
      "Epoch 60/100: Loss: 0.0005667043460562127\n",
      "Epoch 61/100: Loss: 0.0007125109765183879\n",
      "Epoch 62/100: Loss: 0.0005539249524190382\n",
      "Epoch 63/100: Loss: 0.0016637672977594775\n",
      "Epoch 64/100: Loss: 0.000686382976709865\n",
      "Epoch 65/100: Loss: 0.0006237191529180564\n",
      "Epoch 66/100: Loss: 0.0004011174329207279\n",
      "Epoch 67/100: Loss: 0.003179619891307084\n",
      "Epoch 68/100: Loss: 0.0008171446323103737\n",
      "Epoch 69/100: Loss: 0.0007692050232435577\n",
      "Epoch 70/100: Loss: 0.0009718414105009288\n",
      "Epoch 71/100: Loss: 0.00048824424520717004\n",
      "Epoch 72/100: Loss: 0.001534921573511383\n",
      "Epoch 73/100: Loss: 0.00048292803248841667\n",
      "Epoch 74/100: Loss: 0.0004068525231559761\n",
      "Epoch 75/100: Loss: 0.0005263488696073182\n",
      "Epoch 76/100: Loss: 0.00046526895584975136\n",
      "Epoch 77/100: Loss: 0.0004594163088768255\n",
      "Epoch 78/100: Loss: 0.11077802840154619\n",
      "Epoch 79/100: Loss: 0.0058966867160052065\n",
      "Epoch 80/100: Loss: 0.0011188696764293127\n",
      "Epoch 81/100: Loss: 0.0006134769224445336\n",
      "Epoch 82/100: Loss: 0.0006388224664988229\n",
      "Epoch 83/100: Loss: 0.0005655381737597054\n",
      "Epoch 84/100: Loss: 0.0005024760805099505\n",
      "Epoch 85/100: Loss: 0.00044147926219011423\n",
      "Epoch 86/100: Loss: 0.0005799370817840099\n",
      "Epoch 87/100: Loss: 0.04280050911329454\n",
      "Epoch 88/100: Loss: 0.0021608799084788187\n",
      "Epoch 89/100: Loss: 0.0007758226369332988\n",
      "Epoch 90/100: Loss: 0.0007623058423632756\n",
      "Epoch 91/100: Loss: 0.000829400429938687\n",
      "Epoch 92/100: Loss: 0.00048396645697721394\n",
      "Epoch 93/100: Loss: 0.000539765215398802\n",
      "Epoch 94/100: Loss: 0.0003307111598587653\n",
      "Epoch 95/100: Loss: 0.00032274394930027485\n",
      "Epoch 96/100: Loss: 0.0020384874143928753\n",
      "Epoch 97/100: Loss: 0.0009187111503706546\n",
      "Epoch 98/100: Loss: 0.0005247518249234418\n",
      "Epoch 99/100: Loss: 0.0005286186755256494\n",
      "Epoch 100/100: Loss: 0.0007551666006293089\n",
      "time costs: 1309.4108047485352\n",
      "[98.73007369  8.68833364 75.48714138  6.58258071  0.26861778]\n",
      "mean acc:  98.15764478185861\n",
      "mean rmse:  11.876788149720786\n",
      "mean mse:  157.80795717539\n",
      "mean mae:  9.549728845085813\n",
      "mean mape:  0.38799482748210523\n"
     ]
    }
   ],
   "source": [
    "epoch = 5\n",
    "acc, rmse, mse, mae, mape = 0, 0, 0, 0, 0\n",
    "for i in range(epoch):\n",
    "    dropout_lock = True\n",
    "    qmodel = QModel(input_size, hidden_size, num_output, \n",
    "                    num_layers = num_layers, ctx = ctx, mode='classical', dropout_rate = 0.0001)\n",
    "    optimizer = torch.optim.Adam(qmodel.parameters(), lr = 0.0035)\n",
    "    loss_func = nn.MSELoss()\n",
    "\n",
    "    start = time.time()\n",
    "    losses = train_model(qmodel, train_data, batch_size=20,          \n",
    "                   loss_func = loss_func, optimizer = optimizer, epoch = 100, early_stop=True)\n",
    "    end = time.time()\n",
    "\n",
    "    print(f'time costs: {end - start}')\n",
    "\n",
    "    dropout_lock = False\n",
    "    results = calculate_accuarcy(qmodel, X_test, y_test)\n",
    "    acc += results[0]\n",
    "    rmse += results[1]\n",
    "    mse += results[2]\n",
    "    mae += results[3]\n",
    "    mape += results[4]\n",
    "\n",
    "    print(results)\n",
    "\n",
    "print('mean acc: ', acc / epoch)\n",
    "print('mean rmse: ', rmse / epoch)\n",
    "print('mean mse: ', mse / epoch)\n",
    "print('mean mae: ', mae / epoch)\n",
    "print('mean mape: ', mape / epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9af38e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bitphase flip: 0.0001\n",
    "# mean acc:  98.15764478185861\n",
    "# mean rmse:  11.876788149720786\n",
    "# mean mse:  157.80795717539\n",
    "# mean mae:  9.549728845085813\n",
    "# mean mape:  0.38799482748210523"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0634a268",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "Epoch 1/100: Loss: 1.01621812582016\n",
      "Epoch 2/100: Loss: 0.9726888716220856\n",
      "Epoch 3/100: Loss: 0.9585238456726074\n",
      "Epoch 4/100: Loss: 0.9336611896753311\n",
      "Epoch 5/100: Loss: 0.8838653773069381\n",
      "Epoch 6/100: Loss: 0.8021602988243103\n",
      "Epoch 7/100: Loss: 0.7433784410357476\n",
      "Epoch 8/100: Loss: 0.7024115860462189\n",
      "Epoch 9/100: Loss: 0.5561951603740454\n",
      "Epoch 10/100: Loss: 0.549027425237\n",
      "Epoch 11/100: Loss: 0.38579808417707684\n",
      "Epoch 12/100: Loss: 0.3946440835949033\n",
      "Epoch 13/100: Loss: 0.3529249018989503\n",
      "Epoch 14/100: Loss: 0.3135389775037766\n",
      "Epoch 15/100: Loss: 0.3298674869991373\n",
      "Epoch 16/100: Loss: 0.27423858490074055\n",
      "Epoch 17/100: Loss: 0.1907772849081084\n",
      "Epoch 18/100: Loss: 0.30224682339467107\n",
      "Epoch 19/100: Loss: 0.24711910504847764\n",
      "Epoch 20/100: Loss: 0.20517816240899264\n",
      "Epoch 21/100: Loss: 0.13721447819843888\n",
      "Epoch 22/100: Loss: 0.13634802733176912\n",
      "Epoch 23/100: Loss: 0.0658978756837314\n",
      "Epoch 24/100: Loss: 0.06859580263844692\n",
      "Epoch 25/100: Loss: 0.08912023744778708\n",
      "Epoch 26/100: Loss: 0.035344991576857866\n",
      "Epoch 27/100: Loss: 0.2512497578529292\n",
      "Epoch 28/100: Loss: 0.03469134162805858\n",
      "Epoch 29/100: Loss: 0.0215189345064573\n",
      "Epoch 30/100: Loss: 0.02101143230102025\n",
      "Epoch 31/100: Loss: 0.028510344430833355\n",
      "Epoch 32/100: Loss: 0.01921717629302293\n",
      "Epoch 33/100: Loss: 0.01382704828374699\n",
      "Epoch 34/100: Loss: 0.00825718040287029\n",
      "Epoch 35/100: Loss: 0.01629211407052935\n",
      "Epoch 36/100: Loss: 0.059815767605323346\n",
      "Epoch 37/100: Loss: 0.0016777803932200186\n",
      "Epoch 38/100: Loss: 0.008379683291786932\n",
      "Epoch 39/100: Loss: 0.01530641607751022\n",
      "Epoch 40/100: Loss: 0.0014296738077973713\n",
      "Epoch 41/100: Loss: 0.0038306392099912044\n",
      "Epoch 42/100: Loss: 0.006721893977555737\n",
      "Epoch 43/100: Loss: 0.0006924907005668501\n",
      "Epoch 44/100: Loss: 0.0025108695630478906\n",
      "Epoch 45/100: Loss: 0.0005486219526574132\n",
      "Epoch 46/100: Loss: 0.015064602117672622\n",
      "Epoch 47/100: Loss: 0.01179880598501768\n",
      "Epoch 48/100: Loss: 0.002588963694870472\n",
      "Epoch 49/100: Loss: 0.0015057038832310353\n",
      "Epoch 50/100: Loss: 0.017846696295782748\n",
      "Epoch 51/100: Loss: 0.0013796215345792007\n",
      "Epoch 52/100: Loss: 0.0005421963360277005\n",
      "Epoch 53/100: Loss: 0.08504094584786799\n",
      "Epoch 54/100: Loss: 0.004252881958018406\n",
      "Epoch 55/100: Loss: 0.0015811017146916129\n",
      "Epoch 56/100: Loss: 0.001994113870205183\n",
      "Epoch 57/100: Loss: 0.0005990752568322932\n",
      "Epoch 58/100: Loss: 0.022620532992004883\n",
      "Epoch 59/100: Loss: 0.025539297334034927\n",
      "Epoch 60/100: Loss: 0.038643862781464124\n",
      "Epoch 61/100: Loss: 0.015550485039420891\n",
      "Epoch 62/100: Loss: 0.21425837413298723\n",
      "Epoch 63/100: Loss: 0.015831160172820092\n",
      "Epoch 64/100: Loss: 0.0071725827001500875\n",
      "Epoch 65/100: Loss: 0.008970305399270729\n",
      "Epoch 66/100: Loss: 0.011000183526630281\n",
      "Epoch 67/100: Loss: 0.0022151133434817893\n",
      "Epoch 68/100: Loss: 0.0006224681359526585\n",
      "Epoch 69/100: Loss: 0.07252747876627837\n",
      "Epoch 70/100: Loss: 0.003600930914399214\n",
      "Epoch 71/100: Loss: 0.014706877694698051\n",
      "Epoch 72/100: Loss: 0.007008061482702032\n",
      "Epoch 73/100: Loss: 0.0010064898669952527\n",
      "Epoch 74/100: Loss: 0.0024455376144032924\n",
      "Epoch 75/100: Loss: 0.0027089888051705204\n",
      "Epoch 76/100: Loss: 0.002986343458906049\n",
      "Epoch 77/100: Loss: 0.006465194915654138\n",
      "Epoch 78/100: Loss: 0.0030239625040849203\n",
      "Epoch 79/100: Loss: 0.0005004936043405906\n",
      "Epoch 80/100: Loss: 0.0013392024380664224\n",
      "Epoch 81/100: Loss: 0.0009137474695307901\n",
      "Epoch 82/100: Loss: 0.0010132287832675501\n",
      "Epoch 83/100: Loss: 0.0015800757908436935\n",
      "Epoch 84/100: Loss: 0.003576515919849044\n",
      "Epoch 85/100: Loss: 0.0004640600118364091\n",
      "Epoch 86/100: Loss: 0.0013103829667670652\n",
      "Epoch 87/100: Loss: 0.0006646531437581871\n",
      "Epoch 88/100: Loss: 0.000430351535032969\n",
      "Epoch 89/100: Loss: 0.0008148938155500218\n",
      "Epoch 90/100: Loss: 0.06442898418972617\n",
      "Epoch 91/100: Loss: 0.0041691690224979535\n",
      "Epoch 92/100: Loss: 0.0007826039691281039\n",
      "Epoch 93/100: Loss: 0.0005930498031375464\n",
      "Epoch 94/100: Loss: 0.0017462050667745644\n",
      "Epoch 95/100: Loss: 0.0006397318520612316\n",
      "Epoch 96/100: Loss: 0.002191603693790967\n",
      "Epoch 97/100: Loss: 0.07674345338673447\n",
      "Epoch 98/100: Loss: 0.005618791311280802\n",
      "Epoch 99/100: Loss: 0.003449956165422918\n",
      "Epoch 100/100: Loss: 0.0010208441119175405\n",
      "time costs: 1143.4417581558228\n",
      "[98.55703092  9.30777282 86.63463478  7.47953671  0.39846074]\n",
      "epoch: 2\n",
      "Epoch 1/100: Loss: 1.0059009045362473\n",
      "Epoch 2/100: Loss: 0.9864433377981185\n",
      "Epoch 3/100: Loss: 0.9495285540819168\n",
      "Epoch 4/100: Loss: 0.8460758358240128\n",
      "Epoch 5/100: Loss: 0.7572790294885635\n",
      "Epoch 6/100: Loss: 0.7224645182490349\n",
      "Epoch 7/100: Loss: 0.5387516289949417\n",
      "Epoch 8/100: Loss: 0.31084966622293\n",
      "Epoch 9/100: Loss: 0.38516228199005126\n",
      "Epoch 10/100: Loss: 0.24397954065352678\n",
      "Epoch 11/100: Loss: 0.174915377702564\n",
      "Epoch 12/100: Loss: 0.14134981585666537\n",
      "Epoch 13/100: Loss: 0.057312011579051615\n",
      "Epoch 14/100: Loss: 0.3348348017781973\n",
      "Epoch 15/100: Loss: 0.11246310523711145\n",
      "Epoch 16/100: Loss: 0.10901363777229563\n",
      "Epoch 17/100: Loss: 0.06047169079538435\n",
      "Epoch 18/100: Loss: 0.055085895239608364\n",
      "Epoch 19/100: Loss: 0.023105148202739657\n",
      "Epoch 20/100: Loss: 0.018891815033566673\n",
      "Epoch 21/100: Loss: 0.1266446703404654\n",
      "Epoch 22/100: Loss: 0.015694518899545075\n",
      "Epoch 23/100: Loss: 0.006197963979502674\n",
      "Epoch 24/100: Loss: 0.0032662394849467093\n",
      "Epoch 25/100: Loss: 0.13524354396795388\n",
      "Epoch 26/100: Loss: 0.008008285399409943\n",
      "Epoch 27/100: Loss: 0.0011657122558972333\n",
      "Epoch 28/100: Loss: 0.19703812970892615\n",
      "Epoch 29/100: Loss: 0.019120106199989096\n",
      "Epoch 30/100: Loss: 0.009764765546424314\n",
      "Epoch 31/100: Loss: 0.004617030209919904\n",
      "Epoch 32/100: Loss: 0.007686593418475241\n",
      "Epoch 33/100: Loss: 0.09536774022271857\n",
      "Epoch 34/100: Loss: 0.011130219995538936\n",
      "Epoch 35/100: Loss: 0.0014040719710465056\n",
      "Epoch 36/100: Loss: 0.003374741987499874\n",
      "Epoch 37/100: Loss: 0.004885062257380923\n",
      "Epoch 38/100: Loss: 0.008130465189969982\n",
      "Epoch 39/100: Loss: 0.01143761266284855\n",
      "Epoch 40/100: Loss: 0.009052052619881578\n",
      "Epoch 41/100: Loss: 0.00811232120031491\n",
      "Epoch 42/100: Loss: 0.00549023590865545\n",
      "Epoch 43/100: Loss: 0.005663442466175184\n",
      "Epoch 44/100: Loss: 0.0408202494145371\n",
      "Epoch 45/100: Loss: 0.006237934788805433\n",
      "Epoch 46/100: Loss: 0.14312351372163903\n",
      "Epoch 47/100: Loss: 0.007969273960407008\n",
      "Epoch 48/100: Loss: 0.09353336846688762\n",
      "Epoch 49/100: Loss: 0.05059872873534914\n",
      "Epoch 50/100: Loss: 0.007337858053506352\n",
      "Epoch 51/100: Loss: 0.001106953116686782\n",
      "Epoch 52/100: Loss: 0.02433985279494664\n",
      "Epoch 53/100: Loss: 0.003933241124650521\n",
      "Epoch 54/100: Loss: 0.005676122285694874\n",
      "Epoch 55/100: Loss: 0.048306531831622125\n",
      "Epoch 56/100: Loss: 0.004625809083518106\n",
      "Epoch 57/100: Loss: 0.0031876758621365298\n",
      "Epoch 58/100: Loss: 0.06459112788397761\n",
      "Epoch 59/100: Loss: 0.026137310202466325\n",
      "Epoch 60/100: Loss: 0.0036857227481959854\n",
      "Epoch 61/100: Loss: 0.011308540158279357\n",
      "Epoch 62/100: Loss: 0.003982376748172101\n",
      "Epoch 63/100: Loss: 0.0008937583581428044\n",
      "Epoch 64/100: Loss: 0.0010589580982923509\n",
      "Epoch 65/100: Loss: 0.00043701701124518875\n",
      "Epoch 66/100: Loss: 0.002865431155805709\n",
      "Epoch 67/100: Loss: 0.0009329672157036839\n",
      "Epoch 68/100: Loss: 0.0009061830987775465\n",
      "Epoch 69/100: Loss: 0.007336313217001589\n",
      "Epoch 70/100: Loss: 0.005213047899997036\n",
      "Epoch 71/100: Loss: 0.0017591100155186722\n",
      "Epoch 72/100: Loss: 0.012010635990009177\n",
      "Epoch 73/100: Loss: 0.0017987399859521248\n",
      "Epoch 74/100: Loss: 0.013693523144320352\n",
      "Epoch 75/100: Loss: 0.0021602072458335895\n",
      "Epoch 76/100: Loss: 0.0005764858632574032\n",
      "Epoch 77/100: Loss: 0.020502804698753607\n",
      "Epoch 78/100: Loss: 0.00468626802394283\n",
      "Epoch 79/100: Loss: 0.012307362986030057\n",
      "Epoch 80/100: Loss: 0.0028800175816286354\n",
      "Epoch 81/100: Loss: 0.0017400199321855325\n",
      "Epoch 82/100: Loss: 0.0027986912416963607\n",
      "Epoch 83/100: Loss: 0.002855493948663934\n",
      "Epoch 84/100: Loss: 0.01646797728317324\n",
      "Epoch 85/100: Loss: 0.004050720822851872\n",
      "Epoch 86/100: Loss: 0.02599274092935957\n",
      "Epoch 87/100: Loss: 0.0020764806541592406\n",
      "Epoch 88/100: Loss: 0.003908108180621639\n",
      "Epoch 89/100: Loss: 0.00155195034967619\n",
      "Epoch 90/100: Loss: 0.004066853233234724\n",
      "Epoch 91/100: Loss: 0.0017939238430699333\n",
      "Epoch 92/100: Loss: 0.0006319268110019039\n",
      "Epoch 93/100: Loss: 0.0015721402713097631\n",
      "Epoch 94/100: Loss: 0.0006951755141926697\n",
      "Epoch 95/100: Loss: 0.0026240291321300902\n",
      "Epoch 96/100: Loss: 0.0007521820843976457\n",
      "Epoch 97/100: Loss: 0.002582839709793916\n",
      "Epoch 98/100: Loss: 0.0004362454390502535\n",
      "Epoch 99/100: Loss: 0.017101503256253637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100: Loss: 0.018848297971999273\n",
      "time costs: 922.081375837326\n",
      "[ 96.4591869   21.51980121 463.10184414  18.35357518   0.94383315]\n",
      "epoch: 3\n",
      "Epoch 1/100: Loss: 1.0036854863166809\n",
      "Epoch 2/100: Loss: 1.0212879091501237\n",
      "Epoch 3/100: Loss: 0.9745456725358963\n",
      "Epoch 4/100: Loss: 0.9373916327953339\n",
      "Epoch 5/100: Loss: 0.8455839663743973\n",
      "Epoch 6/100: Loss: 0.7837282508611679\n",
      "Epoch 7/100: Loss: 0.6679483011364937\n",
      "Epoch 8/100: Loss: 0.5783219173550606\n",
      "Epoch 9/100: Loss: 0.43371990919113157\n",
      "Epoch 10/100: Loss: 0.3027335211634636\n",
      "Epoch 11/100: Loss: 0.298170930147171\n",
      "Epoch 12/100: Loss: 0.22855509929358958\n",
      "Epoch 13/100: Loss: 0.13148433864116668\n",
      "Epoch 14/100: Loss: 0.11283894167281687\n",
      "Epoch 15/100: Loss: 0.07268285282189027\n",
      "Epoch 16/100: Loss: 0.03738184943504166\n",
      "Epoch 17/100: Loss: 0.015454607229912654\n",
      "Epoch 18/100: Loss: 0.04005370549857616\n",
      "Epoch 19/100: Loss: 0.09238923771627014\n",
      "Epoch 20/100: Loss: 0.012664858714560977\n",
      "Epoch 21/100: Loss: 0.002669909462565556\n",
      "Epoch 22/100: Loss: 0.06103872833409696\n",
      "Epoch 23/100: Loss: 0.0049339734949171545\n",
      "Epoch 24/100: Loss: 0.0009434451229026308\n",
      "Epoch 25/100: Loss: 0.002304830545472214\n",
      "Epoch 26/100: Loss: 0.0008646387241242337\n",
      "Epoch 27/100: Loss: 0.002124013776665379\n",
      "Epoch 28/100: Loss: 0.11175422317587617\n",
      "Epoch 29/100: Loss: 0.008512641570996493\n",
      "Epoch 30/100: Loss: 0.013214052106195594\n",
      "Epoch 31/100: Loss: 0.01924540134205017\n",
      "Epoch 32/100: Loss: 0.00296719277248485\n",
      "Epoch 33/100: Loss: 0.0011359390173311112\n",
      "Epoch 34/100: Loss: 0.0005807476281916024\n",
      "Epoch 35/100: Loss: 0.003850541262727347\n",
      "Epoch 36/100: Loss: 0.0009582101438354584\n",
      "Epoch 37/100: Loss: 0.07297776351406356\n",
      "Epoch 38/100: Loss: 0.009699547149648425\n",
      "Epoch 39/100: Loss: 0.0020300341973779725\n",
      "Epoch 40/100: Loss: 0.0007512328964367043\n",
      "Epoch 41/100: Loss: 0.1269498624576954\n",
      "Epoch 42/100: Loss: 0.00904546878518886\n",
      "Epoch 43/100: Loss: 0.02959776783172856\n",
      "Epoch 44/100: Loss: 0.012891829322325066\n",
      "Epoch 45/100: Loss: 0.0038074958429206163\n",
      "Epoch 46/100: Loss: 0.0011810082251031417\n",
      "Epoch 47/100: Loss: 0.0005402191280154511\n",
      "Epoch 48/100: Loss: 0.0015858257376748953\n",
      "Epoch 49/100: Loss: 0.026887435506978363\n",
      "Epoch 50/100: Loss: 0.004160232513822848\n",
      "Epoch 51/100: Loss: 0.06231866589696437\n",
      "Epoch 52/100: Loss: 0.01614856339583639\n",
      "Epoch 53/100: Loss: 0.035767856769962234\n",
      "Epoch 54/100: Loss: 0.0043820625054650005\n",
      "Epoch 55/100: Loss: 0.000920229879557155\n",
      "Epoch 56/100: Loss: 0.021183896666116198\n",
      "Epoch 57/100: Loss: 0.0502331137836336\n",
      "Epoch 58/100: Loss: 0.006517223748960532\n",
      "Epoch 59/100: Loss: 0.0020936087341397068\n",
      "Epoch 60/100: Loss: 0.0011132230261864605\n",
      "Epoch 61/100: Loss: 0.0010118533986315016\n",
      "Epoch 62/100: Loss: 0.0008930762416639482\n",
      "Epoch 63/100: Loss: 0.0026726626683739596\n",
      "Epoch 64/100: Loss: 0.0009623102656405536\n",
      "Epoch 65/100: Loss: 0.0009340442204120337\n",
      "Epoch 66/100: Loss: 0.0010940133804979268\n",
      "Epoch 67/100: Loss: 0.0005711583673473797\n",
      "Epoch 68/100: Loss: 0.0016429209430498305\n",
      "Epoch 69/100: Loss: 0.0005811617975268746\n",
      "Epoch 70/100: Loss: 0.14579587808307223\n",
      "Epoch 71/100: Loss: 0.010390033334260806\n",
      "Epoch 72/100: Loss: 0.001955066910159076\n",
      "Epoch 73/100: Loss: 0.003534921837126603\n",
      "Epoch 74/100: Loss: 0.008781250927131622\n",
      "Epoch 75/100: Loss: 0.003274582173617091\n",
      "Epoch 76/100: Loss: 0.0011991565970674856\n",
      "Epoch 77/100: Loss: 0.0008353172124770936\n",
      "Epoch 78/100: Loss: 0.000730803313490469\n",
      "Epoch 79/100: Loss: 0.014646544752758927\n",
      "Epoch 80/100: Loss: 0.04916456775681581\n",
      "Epoch 81/100: Loss: 0.0067903350754932035\n",
      "Epoch 82/100: Loss: 0.0025573813218215946\n",
      "Epoch 83/100: Loss: 0.0006538547968375497\n",
      "Epoch 84/100: Loss: 0.0003739266096090432\n",
      "Epoch 85/100: Loss: 0.004320963635109365\n",
      "Epoch 86/100: Loss: 0.0015091660266989492\n",
      "Epoch 87/100: Loss: 0.08105731378018391\n",
      "Epoch 88/100: Loss: 0.004982645955169574\n",
      "Epoch 89/100: Loss: 0.014382941804797156\n",
      "Epoch 90/100: Loss: 0.031461644427326976\n",
      "Epoch 91/100: Loss: 0.0030091791966697203\n",
      "Epoch 92/100: Loss: 0.0011238762224820675\n",
      "Epoch 93/100: Loss: 0.03554119287946378\n",
      "Epoch 94/100: Loss: 0.0190185947874852\n",
      "Epoch 95/100: Loss: 0.0027008357112208612\n",
      "Epoch 96/100: Loss: 0.0015374712835182435\n",
      "Epoch 97/100: Loss: 0.001947849689531722\n",
      "Epoch 98/100: Loss: 0.0018907488910372195\n",
      "Epoch 99/100: Loss: 0.0021554045983066318\n",
      "Epoch 100/100: Loss: 0.0008947847458330216\n",
      "time costs: 970.1799709796906\n",
      "[98.66069767  8.82985034 77.96625698  6.94218679  0.35744585]\n",
      "epoch: 4\n",
      "Epoch 1/100: Loss: 1.0128491669893265\n",
      "Epoch 2/100: Loss: 1.0220801115036011\n",
      "Epoch 3/100: Loss: 1.0476468205451965\n",
      "Epoch 4/100: Loss: 0.9860571324825287\n",
      "Epoch 5/100: Loss: 0.9387730091810227\n",
      "Epoch 6/100: Loss: 0.9399652004241943\n",
      "Epoch 7/100: Loss: 0.9538219481706619\n",
      "Epoch 8/100: Loss: 0.9006463170051575\n",
      "Epoch 9/100: Loss: 0.8468610584735871\n",
      "Epoch 10/100: Loss: 0.8006203025579453\n",
      "Epoch 11/100: Loss: 0.7282712563872338\n",
      "Epoch 12/100: Loss: 0.6561503946781159\n",
      "Epoch 13/100: Loss: 0.6028803005814553\n",
      "Epoch 14/100: Loss: 0.621950101852417\n",
      "Epoch 15/100: Loss: 0.5093436509370803\n",
      "Epoch 16/100: Loss: 0.3795450545847416\n",
      "Epoch 17/100: Loss: 0.3719504773616791\n",
      "Epoch 18/100: Loss: 0.30573599599301815\n",
      "Epoch 19/100: Loss: 0.23979131132364273\n",
      "Epoch 20/100: Loss: 0.16462584659457208\n",
      "Epoch 21/100: Loss: 0.1493592530488968\n",
      "Epoch 22/100: Loss: 0.1122400039806962\n",
      "Epoch 23/100: Loss: 0.07745563755743205\n",
      "Epoch 24/100: Loss: 0.049702363221149425\n",
      "Epoch 25/100: Loss: 0.06367024805222173\n",
      "Epoch 26/100: Loss: 0.026742730138357727\n",
      "Epoch 27/100: Loss: 0.02754138018353842\n",
      "Epoch 28/100: Loss: 0.016898540704278275\n",
      "Epoch 29/100: Loss: 0.007444708818366052\n",
      "Epoch 30/100: Loss: 0.012446481427468825\n",
      "Epoch 31/100: Loss: 0.004384792729979381\n",
      "Epoch 32/100: Loss: 0.10725840171799064\n",
      "Epoch 33/100: Loss: 0.023470292158890516\n",
      "Epoch 34/100: Loss: 0.006694512843387202\n",
      "Epoch 35/100: Loss: 0.006786368976463564\n",
      "Epoch 36/100: Loss: 0.004764922418689821\n",
      "Epoch 37/100: Loss: 0.10332889907003846\n",
      "Epoch 38/100: Loss: 0.008753225380496587\n",
      "Epoch 39/100: Loss: 0.007524140609893948\n",
      "Epoch 40/100: Loss: 0.007493332785088569\n",
      "Epoch 41/100: Loss: 0.0029396270387223923\n",
      "Epoch 42/100: Loss: 0.001912652656028513\n",
      "Epoch 43/100: Loss: 0.07604821470595198\n",
      "Epoch 44/100: Loss: 0.015711136630852707\n",
      "Epoch 45/100: Loss: 0.00521222620154731\n",
      "Epoch 46/100: Loss: 0.3216437143113581\n",
      "Epoch 47/100: Loss: 0.04067891653030529\n",
      "Epoch 48/100: Loss: 0.017910413444042206\n",
      "Epoch 49/100: Loss: 0.023555386066436767\n",
      "Epoch 50/100: Loss: 0.019763856730423867\n",
      "Epoch 51/100: Loss: 0.010631392427603715\n",
      "Epoch 52/100: Loss: 0.040251808695029465\n",
      "Epoch 53/100: Loss: 0.012620181548845722\n",
      "Epoch 54/100: Loss: 0.0034827684256015347\n",
      "Epoch 55/100: Loss: 0.002551304029475432\n",
      "Epoch 56/100: Loss: 0.003955646750546294\n",
      "Epoch 57/100: Loss: 0.0022565145867702086\n",
      "Epoch 58/100: Loss: 0.000810086391720688\n",
      "Epoch 59/100: Loss: 0.0025033188278030137\n",
      "Epoch 60/100: Loss: 0.010830053951212903\n",
      "Epoch 61/100: Loss: 0.0038299703712254994\n",
      "Epoch 62/100: Loss: 0.009175179171506898\n",
      "Epoch 63/100: Loss: 0.06222056826809421\n",
      "Epoch 64/100: Loss: 0.004350498656276613\n",
      "Epoch 65/100: Loss: 0.01709629046381451\n",
      "Epoch 66/100: Loss: 0.01067255444067996\n",
      "Epoch 67/100: Loss: 0.02016153533331817\n",
      "Epoch 68/100: Loss: 0.009084158131008735\n",
      "Epoch 69/100: Loss: 0.0075448229756148065\n",
      "Epoch 70/100: Loss: 0.002161611096380511\n",
      "Epoch 71/100: Loss: 0.0008630049444036559\n",
      "Epoch 72/100: Loss: 0.36254205077966617\n",
      "Epoch 73/100: Loss: 0.09312181196874007\n",
      "Epoch 74/100: Loss: 0.013219474568904844\n",
      "Epoch 75/100: Loss: 0.04458635794871953\n",
      "Epoch 76/100: Loss: 0.01462054651346989\n",
      "Epoch 77/100: Loss: 0.006226671463809908\n",
      "Epoch 78/100: Loss: 0.004456514358753339\n",
      "Epoch 79/100: Loss: 0.008052858036171529\n",
      "Epoch 80/100: Loss: 0.20402256986999417\n",
      "Epoch 81/100: Loss: 0.010057032335316763\n",
      "Epoch 82/100: Loss: 0.022881262783630518\n",
      "Epoch 83/100: Loss: 0.17776397163397634\n",
      "Epoch 84/100: Loss: 0.014403516665333882\n",
      "Epoch 85/100: Loss: 0.006961361010326073\n",
      "Epoch 86/100: Loss: 0.16896819235262228\n",
      "Epoch 87/100: Loss: 0.022897978276887443\n",
      "Epoch 88/100: Loss: 0.01021330275107175\n",
      "Epoch 89/100: Loss: 0.010246194912178907\n",
      "Epoch 90/100: Loss: 0.008049009020032827\n",
      "Epoch 91/100: Loss: 0.1317029132391326\n",
      "Epoch 92/100: Loss: 0.19968491125328\n",
      "Epoch 93/100: Loss: 0.03347482258686796\n",
      "Epoch 94/100: Loss: 0.009419880300265504\n",
      "Epoch 95/100: Loss: 0.014425398819730617\n",
      "Epoch 96/100: Loss: 0.0023672598981647752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100: Loss: 0.0013490287066815654\n",
      "Epoch 98/100: Loss: 0.014286045695189386\n",
      "Epoch 99/100: Loss: 0.003308660743641667\n",
      "Epoch 100/100: Loss: 0.004995327325741527\n",
      "time costs: 975.1647825241089\n",
      "[ 97.16015438  18.17414453 330.29952949  14.72015569   0.70347775]\n",
      "epoch: 5\n",
      "Epoch 1/100: Loss: 0.9742562741041183\n",
      "Epoch 2/100: Loss: 0.9956578493118287\n",
      "Epoch 3/100: Loss: 0.9360104203224182\n",
      "Epoch 4/100: Loss: 0.9791715174913407\n",
      "Epoch 5/100: Loss: 0.8990677505731582\n",
      "Epoch 6/100: Loss: 0.8124117344617844\n",
      "Epoch 7/100: Loss: 0.6092034488916397\n",
      "Epoch 8/100: Loss: 0.5619580708444118\n",
      "Epoch 9/100: Loss: 0.5650837481021881\n",
      "Epoch 10/100: Loss: 0.4247417276725173\n",
      "Epoch 11/100: Loss: 0.4795513592660427\n",
      "Epoch 12/100: Loss: 0.35889325607568023\n",
      "Epoch 13/100: Loss: 0.23995683407410978\n",
      "Epoch 14/100: Loss: 0.21957505652680992\n",
      "Epoch 15/100: Loss: 0.2479157356545329\n",
      "Epoch 16/100: Loss: 0.1871251561678946\n",
      "Epoch 17/100: Loss: 0.24331027488224208\n",
      "Epoch 18/100: Loss: 0.12457360178232194\n",
      "Epoch 19/100: Loss: 0.06538894770201295\n",
      "Epoch 20/100: Loss: 0.17415858151216526\n",
      "Epoch 21/100: Loss: 0.05314832595176995\n",
      "Epoch 22/100: Loss: 0.03685241897474043\n",
      "Epoch 23/100: Loss: 0.024196052375191356\n",
      "Epoch 24/100: Loss: 0.022672175575280562\n",
      "Epoch 25/100: Loss: 0.009369605308165774\n",
      "Epoch 26/100: Loss: 0.005208150825637858\n",
      "Epoch 27/100: Loss: 0.004502574288926553\n",
      "Epoch 28/100: Loss: 0.001510162660269998\n",
      "Epoch 29/100: Loss: 0.001812635883834446\n",
      "Epoch 30/100: Loss: 0.00782964285244816\n",
      "Epoch 31/100: Loss: 0.001740514965786133\n",
      "Epoch 32/100: Loss: 0.0020063463320184383\n",
      "Epoch 33/100: Loss: 0.00498051512913662\n",
      "Epoch 34/100: Loss: 0.0010694675603190261\n",
      "Epoch 35/100: Loss: 0.003979079161399568\n",
      "Epoch 36/100: Loss: 0.15171390469477047\n",
      "Epoch 37/100: Loss: 0.01201651820447296\n",
      "Epoch 38/100: Loss: 0.02639494207687676\n",
      "Epoch 39/100: Loss: 0.011382315200171434\n",
      "Epoch 40/100: Loss: 0.022226457862416282\n",
      "Epoch 41/100: Loss: 0.0035164416767656803\n",
      "Epoch 42/100: Loss: 0.0020354873035103084\n",
      "Epoch 43/100: Loss: 0.00578853194747353\n",
      "Epoch 44/100: Loss: 0.0023292837280678214\n",
      "Epoch 45/100: Loss: 0.001957384948764229\n",
      "Epoch 46/100: Loss: 0.0008575335808927775\n",
      "Epoch 47/100: Loss: 0.005675728535425151\n",
      "Epoch 48/100: Loss: 0.1195309104914486\n",
      "Epoch 49/100: Loss: 0.01957560863083927\n",
      "Epoch 50/100: Loss: 0.007413253776030615\n",
      "Epoch 51/100: Loss: 0.0028710566310110154\n",
      "Epoch 52/100: Loss: 0.000761172195780091\n",
      "Epoch 53/100: Loss: 0.0008686742650752422\n",
      "Epoch 54/100: Loss: 0.19836847471451619\n",
      "Epoch 55/100: Loss: 0.01972471908084117\n",
      "Epoch 56/100: Loss: 0.0047926070623361735\n",
      "Epoch 57/100: Loss: 0.024110116156225558\n",
      "Epoch 58/100: Loss: 0.019779987372749018\n",
      "Epoch 59/100: Loss: 0.0505303325742716\n",
      "Epoch 60/100: Loss: 0.011351602541981264\n",
      "Epoch 61/100: Loss: 0.0019566384711652064\n",
      "Epoch 62/100: Loss: 0.0009733573489938863\n",
      "Epoch 63/100: Loss: 0.002703948898852104\n",
      "Epoch 64/100: Loss: 0.0022427826559578536\n",
      "Epoch 65/100: Loss: 0.0012943587940753786\n",
      "Epoch 66/100: Loss: 0.06141148369133589\n",
      "Epoch 67/100: Loss: 0.038810818555066365\n",
      "Epoch 68/100: Loss: 0.011257787976501277\n",
      "Epoch 69/100: Loss: 0.00610145116224885\n",
      "Epoch 70/100: Loss: 0.001603045005685999\n",
      "Epoch 71/100: Loss: 0.001564782975037815\n",
      "Epoch 72/100: Loss: 0.0024017073865252314\n",
      "Epoch 73/100: Loss: 0.0015478845292818733\n",
      "Epoch 74/100: Loss: 0.05016230715118582\n",
      "Epoch 75/100: Loss: 0.005497818683215883\n",
      "Epoch 76/100: Loss: 0.1589205767188105\n",
      "Epoch 77/100: Loss: 0.023597905614587945\n",
      "Epoch 78/100: Loss: 0.16035266796243378\n",
      "Epoch 79/100: Loss: 0.02698755671735853\n",
      "Epoch 80/100: Loss: 0.005699021184409503\n",
      "Epoch 81/100: Loss: 0.003044548186881002\n",
      "Epoch 82/100: Loss: 0.007744056738738436\n",
      "Epoch 83/100: Loss: 0.001184515328714042\n",
      "Epoch 84/100: Loss: 0.0026646948921552394\n",
      "Epoch 85/100: Loss: 0.00154063859154121\n",
      "Epoch 86/100: Loss: 0.0017809398672397948\n",
      "Epoch 87/100: Loss: 0.0014257186563554568\n",
      "Epoch 88/100: Loss: 0.012380337258218788\n",
      "Epoch 89/100: Loss: 0.0007183095716754906\n",
      "Epoch 90/100: Loss: 0.009197840731212636\n",
      "Epoch 91/100: Loss: 0.005224156416807091\n",
      "Epoch 92/100: Loss: 0.0016559560877794865\n",
      "Epoch 93/100: Loss: 0.18173669130701456\n",
      "Epoch 94/100: Loss: 0.016862145617051284\n",
      "Epoch 95/100: Loss: 0.008815682149725034\n",
      "Epoch 96/100: Loss: 0.16888960065698483\n",
      "Epoch 97/100: Loss: 0.025452313889400103\n",
      "Epoch 98/100: Loss: 0.01917929929040838\n",
      "Epoch 99/100: Loss: 0.015736503637344867\n",
      "Epoch 100/100: Loss: 0.003772664096322842\n",
      "time costs: 1096.550930261612\n",
      "[ 97.35505127  16.15832308 261.09140477  13.70992029   0.63540265]\n",
      "mean acc:  97.63842422700714\n",
      "mean rmse:  14.797978395114281\n",
      "mean mse:  243.8187340298342\n",
      "mean mae:  12.241074933398034\n",
      "mean mape:  0.6077240289731745\n"
     ]
    }
   ],
   "source": [
    "epoch = 5\n",
    "acc, rmse, mse, mae, mape = 0, 0, 0, 0, 0\n",
    "for i in range(epoch):\n",
    "    print(f\"epoch: {i + 1}\")\n",
    "    dropout_lock = True\n",
    "    qmodel = QModel(input_size, hidden_size, num_output, \n",
    "                    num_layers = num_layers, ctx = ctx, mode='classical', dropout_rate = 0.001)\n",
    "    optimizer = torch.optim.Adam(qmodel.parameters(), lr = 0.0035)\n",
    "    loss_func = nn.MSELoss()\n",
    "\n",
    "    start = time.time()\n",
    "    losses = train_model(qmodel, train_data, batch_size=20,          \n",
    "                   loss_func = loss_func, optimizer = optimizer, epoch = 100, early_stop=True)\n",
    "    end = time.time()\n",
    "\n",
    "    print(f'time costs: {end - start}')\n",
    "\n",
    "    dropout_lock = False\n",
    "    results = calculate_accuarcy(qmodel, X_test, y_test)\n",
    "    acc += results[0]\n",
    "    rmse += results[1]\n",
    "    mse += results[2]\n",
    "    mae += results[3]\n",
    "    mape += results[4]\n",
    "\n",
    "    print(results)\n",
    "\n",
    "print('mean acc: ', acc / epoch)\n",
    "print('mean rmse: ', rmse / epoch)\n",
    "print('mean mse: ', mse / epoch)\n",
    "print('mean mae: ', mae / epoch)\n",
    "print('mean mape: ', mape / epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "459c8e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean acc:  97.63842422700714\n",
    "# mean rmse:  14.797978395114281\n",
    "# mean mse:  243.8187340298342\n",
    "# mean mae:  12.241074933398034\n",
    "# mean mape:  0.6077240289731745"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6ae1b089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: Loss: 1.0055130004882813\n",
      "Epoch 2/100: Loss: 0.9704905688762665\n",
      "Epoch 3/100: Loss: 0.9630233883857727\n",
      "Epoch 4/100: Loss: 0.9203788965940476\n",
      "Epoch 5/100: Loss: 0.9083323806524277\n",
      "Epoch 6/100: Loss: 0.822154876589775\n",
      "Epoch 7/100: Loss: 0.7959493100643158\n",
      "Epoch 8/100: Loss: 0.7047089576721192\n",
      "Epoch 9/100: Loss: 0.6152191966772079\n",
      "Epoch 10/100: Loss: 0.5924026057124138\n",
      "Epoch 11/100: Loss: 0.6963944435119629\n",
      "Epoch 12/100: Loss: 0.6101985424757004\n",
      "Epoch 13/100: Loss: 0.5625968322157859\n",
      "Epoch 14/100: Loss: 0.5063739709556103\n",
      "Epoch 15/100: Loss: 0.5272157192230225\n",
      "Epoch 16/100: Loss: 0.49311244040727614\n",
      "Epoch 17/100: Loss: 0.48294295743107796\n",
      "Epoch 18/100: Loss: 0.40188546739518644\n",
      "Epoch 19/100: Loss: 0.5286066561937333\n",
      "Epoch 20/100: Loss: 0.44534354843199253\n",
      "Epoch 21/100: Loss: 0.28239002972841265\n",
      "Epoch 22/100: Loss: 0.25587108377367257\n",
      "Epoch 23/100: Loss: 0.3491518967784941\n",
      "Epoch 24/100: Loss: 0.2231654657050967\n",
      "Epoch 25/100: Loss: 0.14773291517049075\n",
      "Epoch 26/100: Loss: 0.08441991142462939\n",
      "Epoch 27/100: Loss: 0.37876528976485135\n",
      "Epoch 28/100: Loss: 0.20077239107340575\n",
      "Epoch 29/100: Loss: 0.13891186569817365\n",
      "Epoch 30/100: Loss: 0.3270995487226173\n",
      "Epoch 31/100: Loss: 0.4351087061688304\n",
      "Epoch 32/100: Loss: 0.11217334917746484\n",
      "Epoch 33/100: Loss: 0.17786571723408998\n",
      "Epoch 34/100: Loss: 0.15744555434212087\n",
      "Epoch 35/100: Loss: 0.27860352443531156\n",
      "Epoch 36/100: Loss: 0.06121194915031083\n",
      "Epoch 37/100: Loss: 0.07285241266945378\n",
      "Epoch 38/100: Loss: 0.14280883487081156\n",
      "Epoch 39/100: Loss: 0.21401782305911182\n",
      "Epoch 40/100: Loss: 0.10641745303291827\n",
      "Epoch 41/100: Loss: 0.2901432709855726\n",
      "Epoch 42/100: Loss: 0.08319758319994434\n",
      "Epoch 43/100: Loss: 0.17927223122678698\n",
      "Epoch 44/100: Loss: 0.11870476179756224\n",
      "Epoch 45/100: Loss: 0.06312516718171537\n",
      "Epoch 46/100: Loss: 0.08729933148715645\n",
      "Epoch 47/100: Loss: 0.14280779108157732\n",
      "Epoch 48/100: Loss: 0.15927441946259932\n",
      "Epoch 49/100: Loss: 0.08833554561715573\n",
      "Epoch 50/100: Loss: 0.0765201379195787\n",
      "Epoch 51/100: Loss: 0.2238991281716153\n",
      "Epoch 52/100: Loss: 0.17534336191019975\n",
      "Epoch 53/100: Loss: 0.07494750564801507\n",
      "Epoch 54/100: Loss: 0.1366845712531358\n",
      "Epoch 55/100: Loss: 0.03971554005111102\n",
      "Epoch 56/100: Loss: 0.17477106855658348\n",
      "Epoch 57/100: Loss: 0.08435022756748367\n",
      "Epoch 58/100: Loss: 0.12224284081312362\n",
      "Epoch 59/100: Loss: 0.10276838750578463\n",
      "Epoch 60/100: Loss: 0.11995818463619798\n",
      "Epoch 61/100: Loss: 0.10939258635044098\n",
      "Epoch 62/100: Loss: 0.03419196833856404\n",
      "Epoch 63/100: Loss: 0.11536807686788961\n",
      "Epoch 64/100: Loss: 0.2187852362927515\n",
      "Epoch 65/100: Loss: 0.09495319377165287\n",
      "Epoch 66/100: Loss: 0.19161418455187232\n",
      "Epoch 67/100: Loss: 0.16935755877639166\n",
      "Epoch 68/100: Loss: 0.441135159204714\n",
      "Epoch 69/100: Loss: 0.08771945519838482\n",
      "Epoch 70/100: Loss: 0.062072926561813804\n",
      "Epoch 71/100: Loss: 0.08190653882193147\n",
      "Epoch 72/100: Loss: 0.037285251656430776\n",
      "Epoch 73/100: Loss: 0.3201314247533446\n",
      "Epoch 74/100: Loss: 0.182603397659841\n",
      "Epoch 75/100: Loss: 0.051383777492446825\n",
      "Epoch 76/100: Loss: 0.17456776748877018\n",
      "Epoch 77/100: Loss: 0.11505210341711063\n",
      "Epoch 78/100: Loss: 0.03765580080798827\n",
      "Epoch 79/100: Loss: 0.1001913636282552\n",
      "Epoch 80/100: Loss: 0.12570273300516419\n",
      "Epoch 81/100: Loss: 0.38856014743214473\n",
      "Epoch 82/100: Loss: 0.058245402318425475\n",
      "Epoch 83/100: Loss: 0.03350857418263331\n",
      "Epoch 84/100: Loss: 0.11035447721369565\n",
      "Epoch 85/100: Loss: 0.08633137727738358\n",
      "Epoch 86/100: Loss: 0.1713401861488819\n",
      "Epoch 87/100: Loss: 0.13166523249819875\n",
      "Epoch 88/100: Loss: 0.1238008109619841\n",
      "Epoch 89/100: Loss: 0.10313554063905031\n",
      "Epoch 90/100: Loss: 0.14880263067898342\n",
      "Epoch 91/100: Loss: 0.13544517335249112\n",
      "Epoch 92/100: Loss: 0.1666131116100587\n",
      "Epoch 93/100: Loss: 0.08794153815251775\n",
      "Epoch 94/100: Loss: 0.039343042834661904\n",
      "Epoch 95/100: Loss: 0.10669378578022588\n",
      "Epoch 96/100: Loss: 0.018735658234800213\n",
      "Epoch 97/100: Loss: 0.10031968096154742\n",
      "Epoch 98/100: Loss: 0.05554795347270556\n",
      "Epoch 99/100: Loss: 0.05104485938209109\n",
      "Epoch 100/100: Loss: 0.0772391533915652\n",
      "time costs: 1896.495045185089\n",
      "[ 95.99850497  26.73608159 714.81805869  20.74149012   0.71972008]\n",
      "Epoch 1/100: Loss: 1.016302478313446\n",
      "Epoch 2/100: Loss: 1.0141936391592026\n",
      "Epoch 3/100: Loss: 0.9504936575889588\n",
      "Epoch 4/100: Loss: 0.8944530606269836\n",
      "Epoch 5/100: Loss: 0.855837470293045\n",
      "Epoch 6/100: Loss: 0.8195307552814484\n",
      "Epoch 7/100: Loss: 0.6980269461870193\n",
      "Epoch 8/100: Loss: 0.6153129816055298\n",
      "Epoch 9/100: Loss: 0.510316076874733\n",
      "Epoch 10/100: Loss: 0.4737916514277458\n",
      "Epoch 11/100: Loss: 0.3644365556538105\n",
      "Epoch 12/100: Loss: 0.5235111899673939\n",
      "Epoch 13/100: Loss: 0.3599174417555332\n",
      "Epoch 14/100: Loss: 0.4032873407006264\n",
      "Epoch 15/100: Loss: 0.3040358295664191\n",
      "Epoch 16/100: Loss: 0.4002115041017532\n",
      "Epoch 17/100: Loss: 0.26998670436441896\n",
      "Epoch 18/100: Loss: 0.33571712747216226\n",
      "Epoch 19/100: Loss: 0.2373479574918747\n",
      "Epoch 20/100: Loss: 0.33318725023418666\n",
      "Epoch 21/100: Loss: 0.15849126502871513\n",
      "Epoch 22/100: Loss: 0.16200600797310472\n",
      "Epoch 23/100: Loss: 0.39917767541483046\n",
      "Epoch 24/100: Loss: 0.17621400211937727\n",
      "Epoch 25/100: Loss: 0.2661842690780759\n",
      "Epoch 26/100: Loss: 0.10870112364646048\n",
      "Epoch 27/100: Loss: 0.08864639105013339\n",
      "Epoch 28/100: Loss: 0.0725029340130277\n",
      "Epoch 29/100: Loss: 0.06251088153803722\n",
      "Epoch 30/100: Loss: 0.19069636206841095\n",
      "Epoch 31/100: Loss: 0.08587312295567244\n",
      "Epoch 32/100: Loss: 0.0650792735395953\n",
      "Epoch 33/100: Loss: 0.1780861601466313\n",
      "Epoch 34/100: Loss: 0.10619856988778338\n",
      "Epoch 35/100: Loss: 0.17039431850425898\n",
      "Epoch 36/100: Loss: 0.07038126878906041\n",
      "Epoch 37/100: Loss: 0.18243389517301695\n",
      "Epoch 38/100: Loss: 0.1406068582669832\n",
      "Epoch 39/100: Loss: 0.051318226102739575\n",
      "Epoch 40/100: Loss: 0.016481144548743033\n",
      "Epoch 41/100: Loss: 0.20830707723362138\n",
      "Epoch 42/100: Loss: 0.11234559159493074\n",
      "Epoch 43/100: Loss: 0.0738368393300334\n",
      "Epoch 44/100: Loss: 0.23728795256465673\n",
      "Epoch 45/100: Loss: 0.29392358849290756\n",
      "Epoch 46/100: Loss: 0.03206965826393571\n",
      "Epoch 47/100: Loss: 0.063764158799313\n",
      "Epoch 48/100: Loss: 0.1827559835423017\n",
      "Epoch 49/100: Loss: 0.14946686012553984\n",
      "Epoch 50/100: Loss: 0.18839949818793683\n",
      "Epoch 51/100: Loss: 0.13783535691909493\n",
      "Epoch 52/100: Loss: 0.055207132874056694\n",
      "Epoch 53/100: Loss: 0.10546226132428274\n",
      "Epoch 54/100: Loss: 0.06525312708399725\n",
      "Epoch 55/100: Loss: 0.08946477354038507\n",
      "Epoch 56/100: Loss: 0.13340339350397698\n",
      "Epoch 57/100: Loss: 0.14230633752886207\n",
      "Epoch 58/100: Loss: 0.1287524207145907\n",
      "Epoch 59/100: Loss: 0.21864134427160026\n",
      "Epoch 60/100: Loss: 0.08704312292684335\n",
      "Epoch 61/100: Loss: 0.06370859052112791\n",
      "Epoch 62/100: Loss: 0.06405072787893004\n",
      "Epoch 63/100: Loss: 0.11481284940382466\n",
      "Epoch 64/100: Loss: 0.1862094488926232\n",
      "Epoch 65/100: Loss: 0.16114192185923457\n",
      "Epoch 66/100: Loss: 0.10151638607494533\n",
      "Epoch 67/100: Loss: 0.024981844369176543\n",
      "Epoch 68/100: Loss: 0.07809648512047715\n",
      "Epoch 69/100: Loss: 0.0743455116651603\n",
      "Epoch 70/100: Loss: 0.11542257632827387\n",
      "Epoch 71/100: Loss: 0.18612375593511388\n",
      "Epoch 72/100: Loss: 0.08151644628960639\n",
      "Epoch 73/100: Loss: 0.08940441862214357\n",
      "Epoch 74/100: Loss: 0.08608381686499342\n",
      "Epoch 75/100: Loss: 0.05574510877486318\n",
      "Epoch 76/100: Loss: 0.035496593330753966\n",
      "Epoch 77/100: Loss: 0.03577018441865221\n",
      "Epoch 78/100: Loss: 0.2101103394830716\n",
      "Epoch 79/100: Loss: 0.0887124297907576\n",
      "Epoch 80/100: Loss: 0.02048011563019827\n",
      "Epoch 81/100: Loss: 0.1886351347231539\n",
      "Epoch 82/100: Loss: 0.02484445176960435\n",
      "Epoch 83/100: Loss: 0.06310884081176482\n",
      "Epoch 84/100: Loss: 0.0509312309382949\n",
      "Epoch 85/100: Loss: 0.15301783342438285\n",
      "Epoch 86/100: Loss: 0.07290076524514007\n",
      "Epoch 87/100: Loss: 0.07527723288658308\n",
      "Epoch 88/100: Loss: 0.09014863519696519\n",
      "Epoch 89/100: Loss: 0.1591415039729327\n",
      "Epoch 90/100: Loss: 0.029459124685672577\n",
      "Epoch 91/100: Loss: 0.02594219729071483\n",
      "Epoch 92/100: Loss: 0.07853447905508801\n",
      "Epoch 93/100: Loss: 0.14862890222575514\n",
      "Epoch 94/100: Loss: 0.14642836901475675\n",
      "Epoch 95/100: Loss: 0.01985420067794621\n",
      "Epoch 96/100: Loss: 0.13478115580510347\n",
      "Epoch 97/100: Loss: 0.08282576134079137\n",
      "Epoch 98/100: Loss: 0.08887219558528159\n",
      "Epoch 99/100: Loss: 0.01725072131957859\n",
      "Epoch 100/100: Loss: 0.09330061630462297\n",
      "time costs: 1339.4776360988617\n",
      "[ 97.28502134  17.24945835 297.54381336  14.07291587   1.25650332]\n",
      "Epoch 1/100: Loss: 1.0201226472854614\n",
      "Epoch 2/100: Loss: 0.9802786558866501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100: Loss: 0.9405951172113418\n",
      "Epoch 4/100: Loss: 0.9764581799507142\n",
      "Epoch 5/100: Loss: 0.9113746702671051\n",
      "Epoch 6/100: Loss: 0.8782005250453949\n",
      "Epoch 7/100: Loss: 0.8342828631401062\n",
      "Epoch 8/100: Loss: 0.7017955958843232\n",
      "Epoch 9/100: Loss: 0.7176925703883171\n",
      "Epoch 10/100: Loss: 0.6521867252886295\n",
      "Epoch 11/100: Loss: 0.5601324580609799\n",
      "Epoch 12/100: Loss: 0.5047030456364154\n",
      "Epoch 13/100: Loss: 0.548400129377842\n",
      "Epoch 14/100: Loss: 0.41079447269439695\n",
      "Epoch 15/100: Loss: 0.38055125921964644\n",
      "Epoch 16/100: Loss: 0.45990986451506616\n",
      "Epoch 17/100: Loss: 0.2816485784947872\n",
      "Epoch 18/100: Loss: 0.38884245716035365\n",
      "Epoch 19/100: Loss: 0.4326167326420546\n",
      "Epoch 20/100: Loss: 0.30015705302357676\n",
      "Epoch 21/100: Loss: 0.21486206352710724\n",
      "Epoch 22/100: Loss: 0.3754990238696337\n",
      "Epoch 23/100: Loss: 0.17155730072408915\n",
      "Epoch 24/100: Loss: 0.4161907346453518\n",
      "Epoch 25/100: Loss: 0.20269249211996793\n",
      "Epoch 26/100: Loss: 0.10366999376565218\n",
      "Epoch 27/100: Loss: 0.18893156708218156\n",
      "Epoch 28/100: Loss: 0.1515575504861772\n",
      "Epoch 29/100: Loss: 0.24478511775378137\n",
      "Epoch 30/100: Loss: 0.17630708701908587\n",
      "Epoch 31/100: Loss: 0.14721966534852982\n",
      "Epoch 32/100: Loss: 0.29301715351175517\n",
      "Epoch 33/100: Loss: 0.2828312302590348\n",
      "Epoch 34/100: Loss: 0.18639160823076964\n",
      "Epoch 35/100: Loss: 0.15533451437950135\n",
      "Epoch 36/100: Loss: 0.04324793447740376\n",
      "Epoch 37/100: Loss: 0.059169535711407664\n",
      "Epoch 38/100: Loss: 0.03598549492890015\n",
      "Epoch 39/100: Loss: 0.19181743001099677\n",
      "Epoch 40/100: Loss: 0.0938637207262218\n",
      "Epoch 41/100: Loss: 0.17959355455823242\n",
      "Epoch 42/100: Loss: 0.31096712734433823\n",
      "Epoch 43/100: Loss: 0.2310033902293071\n",
      "Epoch 44/100: Loss: 0.1603121616411954\n",
      "Epoch 45/100: Loss: 0.22127111327135934\n",
      "Epoch 46/100: Loss: 0.2707155728014186\n",
      "Epoch 47/100: Loss: 0.34302721804124303\n",
      "Epoch 48/100: Loss: 0.24512983623426407\n",
      "Epoch 49/100: Loss: 0.08644376156153158\n",
      "Epoch 50/100: Loss: 0.23925559686031192\n",
      "Epoch 51/100: Loss: 0.11433528140187263\n",
      "Epoch 52/100: Loss: 0.20877843691268935\n",
      "Epoch 53/100: Loss: 0.09211579902330413\n",
      "Epoch 54/100: Loss: 0.2084841476753354\n",
      "Epoch 55/100: Loss: 0.21331009216373786\n",
      "Epoch 56/100: Loss: 0.0808573994145263\n",
      "Epoch 57/100: Loss: 0.0935038101801183\n",
      "Epoch 58/100: Loss: 0.06096539784921333\n",
      "Epoch 59/100: Loss: 0.18215372473350727\n",
      "Epoch 60/100: Loss: 0.29469425678253175\n",
      "Epoch 61/100: Loss: 0.29606650534551593\n",
      "Epoch 62/100: Loss: 0.10165708788263146\n",
      "Epoch 63/100: Loss: 0.06867922049714252\n",
      "Epoch 64/100: Loss: 0.07451147252577357\n",
      "Epoch 65/100: Loss: 0.13535600692266597\n",
      "Epoch 66/100: Loss: 0.21289226547814905\n",
      "Epoch 67/100: Loss: 0.11003297608112916\n",
      "Epoch 68/100: Loss: 0.12053299418184907\n",
      "Epoch 69/100: Loss: 0.12889625530224294\n",
      "Epoch 70/100: Loss: 0.1250391185458284\n",
      "Epoch 71/100: Loss: 0.054273008625023066\n",
      "Epoch 72/100: Loss: 0.09634209668729454\n",
      "Epoch 73/100: Loss: 0.10910272963228636\n",
      "Epoch 74/100: Loss: 0.4093841085996246\n",
      "Epoch 75/100: Loss: 0.18598773338017055\n",
      "Epoch 76/100: Loss: 0.03704178988700733\n",
      "Epoch 77/100: Loss: 0.05492484620772302\n",
      "Epoch 78/100: Loss: 0.11436606259085239\n",
      "Epoch 79/100: Loss: 0.15102817555889486\n",
      "Epoch 80/100: Loss: 0.02728071903111413\n",
      "Epoch 81/100: Loss: 0.1735010010539554\n",
      "Epoch 82/100: Loss: 0.2806841128738597\n",
      "Epoch 83/100: Loss: 0.10316439592279494\n",
      "Epoch 84/100: Loss: 0.0230023224838078\n",
      "Epoch 85/100: Loss: 0.10778116625733673\n",
      "Epoch 86/100: Loss: 0.16714228782220744\n",
      "Epoch 87/100: Loss: 0.07438988092471846\n",
      "Epoch 88/100: Loss: 0.23019843838119414\n",
      "Epoch 89/100: Loss: 0.05893594962544739\n",
      "Epoch 90/100: Loss: 0.20800217560026796\n",
      "Epoch 91/100: Loss: 0.10394921484403312\n",
      "Epoch 92/100: Loss: 0.050769278437655885\n",
      "Epoch 93/100: Loss: 0.0872355021740077\n",
      "Epoch 94/100: Loss: 0.058021717639348935\n",
      "Epoch 95/100: Loss: 0.016777014901163057\n",
      "Epoch 96/100: Loss: 0.10265380763739813\n",
      "Epoch 97/100: Loss: 0.11199923805543222\n",
      "Epoch 98/100: Loss: 0.05234967069482081\n",
      "Epoch 99/100: Loss: 0.09387285076081753\n",
      "Epoch 100/100: Loss: 0.09837355802883394\n",
      "time costs: 1448.09952378273\n",
      "[9.60037983e+01 2.61633161e+01 6.84519112e+02 2.07140526e+01\n",
      " 5.98583141e-01]\n",
      "Epoch 1/100: Loss: 1.0267834812402725\n",
      "Epoch 2/100: Loss: 0.9607956409454346\n",
      "Epoch 3/100: Loss: 0.9461897701025009\n",
      "Epoch 4/100: Loss: 0.8560534328222275\n",
      "Epoch 5/100: Loss: 0.8027027189731598\n",
      "Epoch 6/100: Loss: 0.7457468315958977\n",
      "Epoch 7/100: Loss: 0.666977907717228\n",
      "Epoch 8/100: Loss: 0.5239155307412148\n",
      "Epoch 9/100: Loss: 0.4850662875920534\n",
      "Epoch 10/100: Loss: 0.35755390897393224\n",
      "Epoch 11/100: Loss: 0.34116748422384263\n",
      "Epoch 12/100: Loss: 0.36070193760097025\n",
      "Epoch 13/100: Loss: 0.32229896169155836\n",
      "Epoch 14/100: Loss: 0.33148506060242655\n",
      "Epoch 15/100: Loss: 0.39519052132964133\n",
      "Epoch 16/100: Loss: 0.4772141020745039\n",
      "Epoch 17/100: Loss: 0.3117095772176981\n",
      "Epoch 18/100: Loss: 0.3039449468255043\n",
      "Epoch 19/100: Loss: 0.22822334431111813\n",
      "Epoch 20/100: Loss: 0.31253983937203883\n",
      "Epoch 21/100: Loss: 0.19389219544827938\n",
      "Epoch 22/100: Loss: 0.17750019803643227\n",
      "Epoch 23/100: Loss: 0.21263363119214773\n",
      "Epoch 24/100: Loss: 0.2288498634006828\n",
      "Epoch 25/100: Loss: 0.2064753606915474\n",
      "Epoch 26/100: Loss: 0.15785846011713148\n",
      "Epoch 27/100: Loss: 0.09721670525614172\n",
      "Epoch 28/100: Loss: 0.15489746403181925\n",
      "Epoch 29/100: Loss: 0.028035989892669023\n",
      "Epoch 30/100: Loss: 0.10087833593788673\n",
      "Epoch 31/100: Loss: 0.02133239507675171\n",
      "Epoch 32/100: Loss: 0.13184977711061946\n",
      "Epoch 33/100: Loss: 0.0627863607602194\n",
      "Epoch 34/100: Loss: 0.16222709922585637\n",
      "Epoch 35/100: Loss: 0.11671607040916569\n",
      "Epoch 36/100: Loss: 0.19993592796381562\n",
      "Epoch 37/100: Loss: 0.06811791202053427\n",
      "Epoch 38/100: Loss: 0.05291905974736437\n",
      "Epoch 39/100: Loss: 0.15308921006508172\n",
      "Epoch 40/100: Loss: 0.12028699463699014\n",
      "Epoch 41/100: Loss: 0.027290384052321315\n",
      "Epoch 42/100: Loss: 0.07723403151030653\n",
      "Epoch 43/100: Loss: 0.028167942725121974\n",
      "Epoch 44/100: Loss: 0.019414881664852147\n",
      "Epoch 45/100: Loss: 0.1021906518144533\n",
      "Epoch 46/100: Loss: 0.041273741316399534\n",
      "Epoch 47/100: Loss: 0.08377737792834523\n",
      "Epoch 48/100: Loss: 0.09615007762040477\n",
      "Epoch 49/100: Loss: 0.16565012530772946\n",
      "Epoch 50/100: Loss: 0.11457567543257027\n",
      "Epoch 51/100: Loss: 0.04643716712016612\n",
      "Epoch 52/100: Loss: 0.06468226633733139\n",
      "Epoch 53/100: Loss: 0.09452290798071772\n",
      "Epoch 54/100: Loss: 0.18219810898881406\n",
      "Epoch 55/100: Loss: 0.06565065690665506\n",
      "Epoch 56/100: Loss: 0.048797917098272595\n",
      "Epoch 57/100: Loss: 0.10396402333135484\n",
      "Epoch 58/100: Loss: 0.0742402617703192\n",
      "Epoch 59/100: Loss: 0.08903584345243871\n",
      "Epoch 60/100: Loss: 0.008994920467375777\n",
      "Epoch 61/100: Loss: 0.014875398033473175\n",
      "Epoch 62/100: Loss: 0.06464068323693936\n",
      "Epoch 63/100: Loss: 0.03626437293714844\n",
      "Epoch 64/100: Loss: 0.11324300132109784\n",
      "Epoch 65/100: Loss: 0.08834394125733525\n",
      "Epoch 66/100: Loss: 0.019857894131564535\n",
      "Epoch 67/100: Loss: 0.05913144752848894\n",
      "Epoch 68/100: Loss: 0.059356252389261496\n",
      "Epoch 69/100: Loss: 0.09763169040670619\n",
      "Epoch 70/100: Loss: 0.01579557508812286\n",
      "Epoch 71/100: Loss: 0.040988021001976446\n",
      "Epoch 72/100: Loss: 0.2243222012912156\n",
      "Epoch 73/100: Loss: 0.16343419856275432\n",
      "Epoch 74/100: Loss: 0.12654776308336296\n",
      "Epoch 75/100: Loss: 0.20234423209913074\n",
      "Epoch 76/100: Loss: 0.20167420916259288\n",
      "Epoch 77/100: Loss: 0.10643012765794993\n",
      "Epoch 78/100: Loss: 0.05587333235889673\n",
      "Epoch 79/100: Loss: 0.05220306614064611\n",
      "Epoch 80/100: Loss: 0.04899753104255069\n",
      "Epoch 81/100: Loss: 0.032368185097584504\n",
      "Epoch 82/100: Loss: 0.06034056073985994\n",
      "Epoch 83/100: Loss: 0.0840757930163818\n",
      "Epoch 84/100: Loss: 0.012555047171190381\n",
      "Epoch 85/100: Loss: 0.04019085640320554\n",
      "Epoch 86/100: Loss: 0.04081870831651031\n",
      "Epoch 87/100: Loss: 0.07379026554699522\n",
      "Epoch 88/100: Loss: 0.04791953980820836\n",
      "Epoch 89/100: Loss: 0.030474706704262645\n",
      "Epoch 90/100: Loss: 0.03609178822953254\n",
      "Epoch 91/100: Loss: 0.02472533533582464\n",
      "Epoch 92/100: Loss: 0.03435526049579494\n",
      "Epoch 93/100: Loss: 0.116503594378446\n",
      "Epoch 94/100: Loss: 0.13272843354498037\n",
      "Epoch 95/100: Loss: 0.05986339545343071\n",
      "Epoch 96/100: Loss: 0.022519540414214133\n",
      "Epoch 97/100: Loss: 0.07353867271449417\n",
      "Epoch 98/100: Loss: 0.013973194069694727\n",
      "Epoch 99/100: Loss: 0.021282879204954953\n",
      "Epoch 100/100: Loss: 0.007359342442941852\n",
      "time costs: 1329.9843516349792\n",
      "[ 97.86286462  13.12010183 172.13707191  11.07770271   0.39640891]\n",
      "Epoch 1/100: Loss: 1.0082928717136384\n",
      "Epoch 2/100: Loss: 0.9816399872303009\n",
      "Epoch 3/100: Loss: 0.971302455663681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100: Loss: 0.9056682705879211\n",
      "Epoch 5/100: Loss: 0.8863035857677459\n",
      "Epoch 6/100: Loss: 0.8464916229248047\n",
      "Epoch 7/100: Loss: 0.7789923951029778\n",
      "Epoch 8/100: Loss: 0.6857108801603318\n",
      "Epoch 9/100: Loss: 0.6836940288543701\n",
      "Epoch 10/100: Loss: 0.5705516543239355\n",
      "Epoch 11/100: Loss: 0.5471975151449442\n",
      "Epoch 12/100: Loss: 0.5924207822419703\n",
      "Epoch 13/100: Loss: 0.4324499614536762\n",
      "Epoch 14/100: Loss: 0.2556714216712862\n",
      "Epoch 15/100: Loss: 0.2968056082725525\n",
      "Epoch 16/100: Loss: 0.2731173244770616\n",
      "Epoch 17/100: Loss: 0.2377430039923638\n",
      "Epoch 18/100: Loss: 0.11516046669567004\n",
      "Epoch 19/100: Loss: 0.1805846836650744\n",
      "Epoch 20/100: Loss: 0.11030008308589459\n",
      "Epoch 21/100: Loss: 0.08196521608624607\n",
      "Epoch 22/100: Loss: 0.29880462056025864\n",
      "Epoch 23/100: Loss: 0.09545226955087856\n",
      "Epoch 24/100: Loss: 0.12264188723638654\n",
      "Epoch 25/100: Loss: 0.23229479138972237\n",
      "Epoch 26/100: Loss: 0.10021362585830502\n",
      "Epoch 27/100: Loss: 0.029573723502107897\n",
      "Epoch 28/100: Loss: 0.040769976974115704\n",
      "Epoch 29/100: Loss: 0.026481838367180897\n",
      "Epoch 30/100: Loss: 0.0881613116711378\n",
      "Epoch 31/100: Loss: 0.21715331892482936\n",
      "Epoch 32/100: Loss: 0.08028807876398787\n",
      "Epoch 33/100: Loss: 0.08778188935248181\n",
      "Epoch 34/100: Loss: 0.09686824670643546\n",
      "Epoch 35/100: Loss: 0.08260743855207693\n",
      "Epoch 36/100: Loss: 0.1077580956974998\n",
      "Epoch 37/100: Loss: 0.10465755883487873\n",
      "Epoch 38/100: Loss: 0.07375032401178032\n",
      "Epoch 39/100: Loss: 0.10373657934833318\n",
      "Epoch 40/100: Loss: 0.17273860699497162\n",
      "Epoch 41/100: Loss: 0.15159676377661527\n",
      "Epoch 42/100: Loss: 0.03287863356526941\n",
      "Epoch 43/100: Loss: 0.06841196796158329\n",
      "Epoch 44/100: Loss: 0.16578067509108224\n",
      "Epoch 45/100: Loss: 0.2343844577204436\n",
      "Epoch 46/100: Loss: 0.04294309808174148\n",
      "Epoch 47/100: Loss: 0.09297344369115308\n",
      "Epoch 48/100: Loss: 0.15447428291663529\n",
      "Epoch 49/100: Loss: 0.13704953216947616\n",
      "Epoch 50/100: Loss: 0.06977862170897424\n",
      "Epoch 51/100: Loss: 0.05848584849154577\n",
      "Epoch 52/100: Loss: 0.16976050757803024\n",
      "Epoch 53/100: Loss: 0.07867486854083836\n",
      "Epoch 54/100: Loss: 0.022277072456199677\n",
      "Epoch 55/100: Loss: 0.2347741283942014\n",
      "Epoch 56/100: Loss: 0.11577973786043003\n",
      "Epoch 57/100: Loss: 0.03081696879817173\n",
      "Epoch 58/100: Loss: 0.13808957890141754\n",
      "Epoch 59/100: Loss: 0.16706316163763404\n",
      "Epoch 60/100: Loss: 0.07786787361837924\n",
      "Epoch 61/100: Loss: 0.1574327153910417\n",
      "Epoch 62/100: Loss: 0.10685765952803195\n",
      "Epoch 63/100: Loss: 0.09312120612012223\n",
      "Epoch 64/100: Loss: 0.19089982068398967\n",
      "Epoch 65/100: Loss: 0.13822068413719535\n",
      "Epoch 66/100: Loss: 0.15183960944996217\n",
      "Epoch 67/100: Loss: 0.10547232083044947\n",
      "Epoch 68/100: Loss: 0.1232951628160663\n",
      "Epoch 69/100: Loss: 0.08546347446972505\n",
      "Epoch 70/100: Loss: 0.06324534377781674\n",
      "Epoch 71/100: Loss: 0.08151507171569392\n",
      "Epoch 72/100: Loss: 0.1260317205102183\n",
      "Epoch 73/100: Loss: 0.1266604550386546\n",
      "Epoch 74/100: Loss: 0.043421815428882835\n",
      "Epoch 75/100: Loss: 0.056013750296551736\n",
      "Epoch 76/100: Loss: 0.04474735298426822\n",
      "Epoch 77/100: Loss: 0.10145301666634624\n",
      "Epoch 78/100: Loss: 0.04788174561399501\n",
      "Epoch 79/100: Loss: 0.009399319486692547\n",
      "Epoch 80/100: Loss: 0.05995832693879492\n",
      "Epoch 81/100: Loss: 0.02084879984613508\n",
      "Epoch 82/100: Loss: 0.12462019238446373\n",
      "Epoch 83/100: Loss: 0.08982498641707934\n",
      "Epoch 84/100: Loss: 0.3045679898932576\n",
      "Epoch 85/100: Loss: 0.08140004426240921\n",
      "Epoch 86/100: Loss: 0.04118833329121117\n",
      "Epoch 87/100: Loss: 0.014500778731598985\n",
      "Epoch 88/100: Loss: 0.019857598666567354\n",
      "Epoch 89/100: Loss: 0.14031966691836714\n",
      "Epoch 90/100: Loss: 0.15336402313550934\n",
      "Epoch 91/100: Loss: 0.07847648143069819\n",
      "Epoch 92/100: Loss: 0.03275034820544533\n",
      "Epoch 93/100: Loss: 0.060460034635616465\n",
      "Epoch 94/100: Loss: 0.05923407512018457\n",
      "Epoch 95/100: Loss: 0.09920393657521345\n",
      "Epoch 96/100: Loss: 0.06266514300368727\n",
      "Epoch 97/100: Loss: 0.07189310245594242\n",
      "Epoch 98/100: Loss: 0.04859519444289617\n",
      "Epoch 99/100: Loss: 0.07708742697141133\n",
      "Epoch 100/100: Loss: 0.2144506326992996\n",
      "time costs: 1296.7909989356995\n",
      "[8.97247855e+01 6.31870836e+01 3.99260753e+03 5.32609082e+01\n",
      " 1.75759976e+00]\n",
      "mean acc:  95.37499494383651\n",
      "mean rmse:  29.29120829744308\n",
      "mean mse:  1172.3251172961834\n",
      "mean mae:  23.973413899014222\n",
      "mean mape:  0.9457630412976311\n"
     ]
    }
   ],
   "source": [
    "epoch = 5\n",
    "acc, rmse, mse, mae, mape = 0, 0, 0, 0, 0\n",
    "for i in range(epoch):\n",
    "    dropout_lock = True\n",
    "    qmodel = QModel(input_size, hidden_size, num_output, \n",
    "                    num_layers = num_layers, ctx = ctx, mode='classical', dropout_rate = 0.01)\n",
    "    optimizer = torch.optim.Adam(qmodel.parameters(), lr = 0.0035)\n",
    "    loss_func = nn.MSELoss()\n",
    "\n",
    "    start = time.time()\n",
    "    losses = train_model(qmodel, train_data, batch_size=20,          \n",
    "                   loss_func = loss_func, optimizer = optimizer, epoch = 100, early_stop=True)\n",
    "    end = time.time()\n",
    "\n",
    "    print(f'time costs: {end - start}')\n",
    "\n",
    "    dropout_lock = False\n",
    "    results = calculate_accuarcy(qmodel, X_test, y_test)\n",
    "    acc += results[0]\n",
    "    rmse += results[1]\n",
    "    mse += results[2]\n",
    "    mae += results[3]\n",
    "    mape += results[4]\n",
    "\n",
    "    print(results)\n",
    "\n",
    "print('mean acc: ', acc / epoch)\n",
    "print('mean rmse: ', rmse / epoch)\n",
    "print('mean mse: ', mse / epoch)\n",
    "print('mean mae: ', mae / epoch)\n",
    "print('mean mape: ', mape / epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "73f92349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean acc:  95.37499494383651\n",
    "# mean rmse:  29.29120829744308\n",
    "# mean mse:  1172.3251172961834\n",
    "# mean mae:  23.973413899014222\n",
    "# mean mape:  0.9457630412976311"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fc12fd4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 98.17324359,  13.62561556, 185.65739932,   9.46887345,\n",
       "         0.43725422])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout_lock = False\n",
    "calculate_accuarcy(qmodel, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dda82d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([98.81048233,  8.41233403, 70.76736381,  6.16578772,  0.51296343])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout_lock = False\n",
    "calculate_accuarcy(qmodel, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "484be833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9821)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout_lock = False\n",
    "calculate_accuarcy(best_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90df3774",
   "metadata": {},
   "source": [
    "### - save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "5a334105",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('loss/bitphaseflip/loss3.pkl', 'wb') as pkl_file:\n",
    "    pickle.dump(losses, pkl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "03f73a74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97912"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_accuracy = np.mean([\n",
    "    0.9782, 0.9790, 0.9821, 0.9757, 0.9806\n",
    "])\n",
    "average_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f6c1ec",
   "metadata": {},
   "source": [
    "### - describe trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "29c8cdfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QModel(\n",
       "  (qlstm): StackedQLSTM(\n",
       "    (qlstms): Sequential(\n",
       "      (QGRU 1): QGRU(\n",
       "        (update_circuit): QuantumLayer(\n",
       "          (qin): Linear(in_features=44, out_features=5, bias=True)\n",
       "          (qout): Linear(in_features=5, out_features=32, bias=True)\n",
       "        )\n",
       "        (candidate_circuit): QuantumLayer(\n",
       "          (qin): Linear(in_features=44, out_features=4, bias=True)\n",
       "          (qout): Linear(in_features=4, out_features=32, bias=True)\n",
       "        )\n",
       "        (reset_circuit): QuantumLayer(\n",
       "          (qin): Linear(in_features=44, out_features=3, bias=True)\n",
       "          (qout): Linear(in_features=3, out_features=32, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (QGRU 2): QGRU(\n",
       "        (update_circuit): QuantumLayer(\n",
       "          (qin): Linear(in_features=64, out_features=5, bias=True)\n",
       "          (qout): Linear(in_features=5, out_features=32, bias=True)\n",
       "        )\n",
       "        (candidate_circuit): QuantumLayer(\n",
       "          (qin): Linear(in_features=64, out_features=4, bias=True)\n",
       "          (qout): Linear(in_features=4, out_features=32, bias=True)\n",
       "        )\n",
       "        (reset_circuit): QuantumLayer(\n",
       "          (qin): Linear(in_features=64, out_features=3, bias=True)\n",
       "          (qout): Linear(in_features=3, out_features=32, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (predict): Linear(in_features=32, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "3497e649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total parameters: 2544\n",
      "quantum paramers: 66\n"
     ]
    }
   ],
   "source": [
    "trainable = 0\n",
    "for p in qmodel.parameters():\n",
    "    if p.requires_grad:\n",
    "        trainable += p.numel()\n",
    "print(f'total parameters: {trainable}')\n",
    "\n",
    "qlstm = QLSTMMap.get(qmodel.mode)[1]\n",
    "print(f'quantum paramers: {qlstm(1, 1, ctx = ctx).qparameters_size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d33ae3",
   "metadata": {},
   "source": [
    "### - Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "22f1defd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "# 0.9821\n",
    "torch.save(best_model.state_dict(), \"model/bitphase_flip_adjusted.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e8d047",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
