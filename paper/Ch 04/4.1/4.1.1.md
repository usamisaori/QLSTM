### 4.1.1 结合先验知识调整 VQC 结构

注意到所用的四个量子层 QNN 事实上正对应于 QLSTM 中的不同门控机制（见 3.1 节）。而先前的研究已经表明在 LSTM 模型中不同门控结构的重要性是不同的，其中最重要的是遗忘门，其次是输入门，最后是输出门[94]。则在设计 QLSTM 模型时同样可以利用该先验知识，调整各个门结构对应的 VQC 结构的复杂度。例如遗忘门被认为是最重要的门控单元，则在设计遗忘门对应的 VQC 结构时应允许其尽可能“精细”地调整学习与调整参数。相反，对于可能并不是很重要的输出门，可以设计相对较简单的 VQC 结构。

3.2.2 节的实验表明，不同量子比特数对线路可表达性能力估计的影响较大，为此此处主要基于可训练参数总数来衡量不同结构间对于模型训练而言的复杂度。基于前述思路调整后的 QLSTM 模型的各个 VQC 结构如下表所示：

| 序号  | 对应门控机制 | 量子比特数n | 叠加层数L | 旋转门类型d | 参数总数 |
| ----- | ------------ | ----------- | --------- | ----------- | -------- |
| $VQC_1$ | 遗忘门       | 5           | 2         | 3           | 45       |
| $VQC_2$ | 输入门       | 4           | 2         | 3           | 36       |
| $VQC_3$ | 状态候选     | 4           | 1         | 3           | 24       |
| $VQC_4$ | 输出门       | 3           | 2         | 2           | 18       |

实验结果如表 4 所示（对应 AdjustedQLSTM，实验数据为 10 次重复实验均值），直观来看由于细调了各个 VQC 的结构，尤其是简化了其中一些层的复杂性使得调整后的 QLSTM 模型的总参数数量下降，对应的训练时间也得到了减少。并且经过细调后的 QLSTM 的性能也的确有一定的提升。

上述基于先验知识来优化 QLSTM 模型的可行性也表明了借鉴更多经典深度学习的经验应用到量子深度学习研究中的潜在可能。