### 1.2.1 时间序列预测

时间序列（Time Series）是指将同一统计指标（对应一定的现象）的数值依据其发生时间的先后顺序排列而成的动态序列，从而可用于描述对应现象随时间发生变化的特征[1]。时间序列预测（Time Series Prediction）则是通过构建预测模型从而利用历史时序数据进行统计与分析、挖掘事物变化规律进而预测其未来变化的方法，其广泛应用于数理统计、金融领域、气象预测等场景[2]。

根据具体时间序列预测问题中可观测变量的数量，可将时序预测问题分为单变量时序预测与多变量时序预测[3]。单变量时序预测借由单变量的历史观测数据预测未来的单变量取值情况，例如基于历史气温观测数据预测未来气温；相对而言多变量时间序列具有多个时间相关变量，且不同变量间往往具有一定的依赖性，借由多变量观测数据预测未来的多变量时序预测可以更加充分地利用已有信息，例如基于历史气温、风速、湿度等多个气象特征预测未来气象特征。较之单变量时序预测，多变量时序预测问题往往更具挑战性。

目前主流的时间序列预测方法主要包括以下三类：基于统计学的传统时间序列预测模型方法、机器学习模型方法以及深度学习模型方法。以下简要阐述这三类时序预测方法的研究现状。

（1）传统时间序列预测模型方法

传统的时间序列预测方法主要基于经典数理统计方法，用函数为时间序列中的数据关系进行建模。此类方法大体上基于一个假设：输出变量（预测值）与历史观测数据间存在一个线性表达式。通过合理的构建求解时间序列参数模型即可完成相应的预测工作。典型的即 Yule 等人[4]提出的基于历史观测值的线性组合所构建的自回归模型（Autoregressive，AR）。受此启发基于历史误差而不是历史观测值的线性组合所提出的移动平均模型（Moving Average，MA，Slutzky 等[5]）进一步减小了随机波动对预测的影响，在此基础上针对历史误差进行加权调整提出的指数平滑模型（Exponential Smoothing）[6]则使得在历史观测数据少的情况下也可获得较好的预测能力。Geary 等人[7]通过整合 AR 与 MA 设计出自回归移动平均模型（Autoregressive Moving Average, ARMA）以进一步提升预测的精确度。George Box[8]在 ARMA 基础上引入差分变换提出了差分自回归移动平均模型（Autoregressive Integrated Moving Average，ARIMA）以缓解非平稳的时间序列对建模及预测带来的影响。Box-Jenkins 方法[9]则为构建具体的 ARMA 或 ARIMA 模型以求解时序预测问题提供了详细的指导策略。基于统计学的传统时间序列预测方法复杂度低、计算速度较快但缺点也比较明显，主要在于要求输入的时间序列线性平稳（或差分后平稳），同时对高复杂性、非线性时间序列预测效果不佳。

（2）机器学习模型方法

在机器学习中，回归类问题旨在基于一系列已知数据输出一个连续值，通过将时序预测问题中的历史数据视作上述输入，目标的预测值视为回归的输出，则自然地可以将时序预测问题抽象为回归问题[10]。机器学习模型方法即通过将时序预测问题转化为有监督的回归问题从而借由机器学习方法来加以解决以实现时序预测。例如支持向量机（Support Vector Machine）已在股票价格预测[11]、气象指标预测[12]等方面证明了其应用于时序预测的可行性。同时借助核方法使得支持向量机可以更好地处理非线性时间序列预测问题；决策树（Decision Tree）也可被应用于解决时序预测问题，并在气象预测上展现了较好的预测效果[13]，由多个决策树随机组成的随机森林（Random Forest）方法在解决混沌时间序列预测问题上的可行性表明了其对非线性问题的建模能力与良好的抗过拟合能力[14]；基于概率推理的贝叶斯网络（Bayesian Network）经结构改进后也可适用于多变量时序预测问题，并成功应用于气象预测[15]；自身就基于时间序列的马尔科夫链（Markov chain）通过给定历史数据计算内部概率转移矩阵从而推测未来变化，同样可以应用于气象类的时序预测问题[16-17]。此外，机器学习中的一些相关技术也可应用于改进时序预测问题。例如矩阵分解（Matrix Factorization）技术可以应用于处理高维时间序列以提升针对高维时间序列的预测质量[18]。显然，基于机器学习的时序预测方法较之于传统模型方法在非线性、高维等复杂情境下表现更佳，但机器学习模型方法也存在一定的局限性，例如在面对复杂的真实数据下可能无法有效捕捉特征分布[19]，换言之特征工程的质量依旧决定了机器学习模型的性能上限。

（3）深度学习模型方法

作为机器学习的分支，深度学习数据驱动、自动学习特征等优良特性使其在越来越多的领域得到关注。本质上深度学习采用多层神经网络，可以经由一系列非线性中间层来自动构建特征表示以学习时序预测能力[20]。传统的卷积神经网络（Convolutional Neural Networks, CNN）在图像识别等领域得到了广泛研究，通过从时间序列中提取构建特征图从而发挥 CNN 的图像处理优势，使得传统 CNN 也可很好地应用于解决时序预测问题[21]。此外，经由引入因果卷积（Causal Convolution）等改良的 CNN 方案在时序预测上可以发挥更加出色的能力[22]。循环神经网络（Recurrent Neural Networks，RNN）[23]作为具有记忆能力的人工神经网络变体，可以在训练过程中利用历史信息，从而使其具备优秀的学习时间序列的能力，在时序预测领域得到广泛关注，基于 RNN 的时序预测已成功应用在金融、气象预测等领域[24-25]。然而随着处理的时间序列长度增加，RNN 模型的复杂度升高会引起梯度消失，导致 RNN 无法解决长期依赖问题[26-27]。为解决上述问题，长短期记忆（Long Short-term Memory，LSTM）模型[28]被提出，通过在 RNN 基础上引入门控单元等改造使其可以将长期记忆与短期记忆结合以一定程度上缓解梯度消失与长期依赖问题[29]，这使得 LSTM 在金融、气象等领域的长期预测上表现良好[30-32]。作为广泛研究的人工神经网络之一，LSTM 具有许多的变体[33-36]，其中门控循环单元（Gated Recurrent Unit，GRU）[36]进一步简化了 LSTM 的结构，使得训练所需参数更少、训练速度更快的同时也进一步缓解了梯度消失或梯度爆炸问题[37]。此外，Transformer[38] 在自然语言领域的序列处理能力使得基于 Transformer 的时序预测研究也受到关注，Zhou H[39] 等基于 Transformer 提出的 Informer 模型为长序列时序预测问题提供了新的解决方案。深度学习模型方法虽然为时序预测带来了强大工具，但不可否认其也存在一定的缺陷。例如深度学习模型的复杂性越来越高，相对的可解释性却不足。训练上依赖数据体量与质量，在少量数据情况下易发生过拟合。此外，鲁棒性上较之传统方法可能偏差，面对噪声多的真实时间序列数据，有效的泛化依旧是挑战。
