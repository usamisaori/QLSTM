### 3.3.2 损失函数与优化

混合量子-经典的变分量子算法的参数优化过程主要在经典计算机上进行，对时序预测类问题，本研究中选取均方误差（MSE）作为训练时的损失函数，且通常在大数据集下使用随机梯度下降法在随机抽取的批量数据集下进行训练，则损失函数如 2.3.4 节中所示为：

$$\mathcal{C}(\overrightarrow{\theta};\mathcal{B}) = \frac{1}{n}\sum|\mathbb{E}(\sigma_z)-y_i| ^2$$

其中 $\mathcal{B}$ 为批数据，$\mathbb{E}(\sigma_z)$ 为 QNN 的测量结果（对 Pauli 算子 $\sigma_z$ 测量的期望值）。记 $E(\overrightarrow{\theta},i)$ 为线路参数 $\overrightarrow{\theta}$ 下第 $i$ 个量子比特的测量输出期望值，则上述损失函数梯度可表示为测量期望值与测量期望值导数的函数集合：

$$
\frac{\partial 
\mathcal{C}(\overrightarrow{\theta};\mathcal{B})}{\partial \theta_j} = f\left ( E(\overrightarrow{\theta}, 1), \cdots, E(\overrightarrow{\theta}, n), \frac{\partial E(\overrightarrow{\theta}, 1)}{\partial \theta_j}, \cdots, \frac{\partial E(\overrightarrow{\theta}, n)}{\partial \theta_j} \right ) 
$$

如 2.3.4 节所述，其中期望的梯度可利用参数偏移表示为：

$$
\frac{\partial E(\overrightarrow{\theta}, i)}{\partial \theta_j}  = \frac{1}{2}[E(\theta_j + \frac{\pi}{2}, i) - E(\theta_j - \frac{\pi}{2}, i)]
$$

$E(\theta_j + \frac{\pi}{2}, i)$ 为对参数向量中的第 $j$ 个参数加 $\frac{\pi}{2}$ 后的期望测量结果。则基于传统的梯度下降过程可得参数更新过程：

$$\overrightarrow{\theta}^{(t)} = \overrightarrow{\theta}^{(t-1)} - \eta \frac{\partial 
\mathcal{C}}{\partial \overrightarrow{\theta}}$$

而实际情况下多会采用其他更有效的优化器来替代上述更新过程。本研究中训练 QLSTM 将使用常用的 Adam 优化器，则基于 Adam 优化器的参数更新过程如下：

$$
\begin{align*}
   m^{(t)} & = \frac{\beta_1m^{(t-1)} + (1 - \beta_1)\nabla \mathcal{C}(\overrightarrow{\theta};\mathcal{B})}{(1 - \beta_1^t)} \\

   v^{(t)} & = \frac{\beta_2v^{(t-1)} + (1 - \beta_2)\nabla \mathcal{C}(\overrightarrow{\theta};\mathcal{B})^{\odot 2}}{1 - \beta_2^t} \\
   
  \overrightarrow{\theta}^{(t)} & = \overrightarrow{\theta}^{(t-1)} - \eta^{(t)} \frac{m^{(t)}}{\sqrt{v^{(t)}}+\epsilon}\\
\end{align*}
$$
